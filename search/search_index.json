{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Apidae is the name of a large bee family. Bees have a mutualistic relationship with their context, live in communal hives with lots of social interaction but also have individual specific tasks related to their age. Beehives are formed in an instinctively optimized way, by creating the most efficient routes, adapting to wind orientation and other factors. Just like the bees, the building has a mutualistic relationship with its context, as the context is to benefit from the placement of the building and the building is a response to the context. The building is communal with the possibility of lots of social interaction, but also the possibility to seclude from the community. The people in our building help each other with specific tasks related to their age. Young people can help elderly with grocery shopping, and the elderly can help the young people with life advice. Just like the beehive, our building is formed in an optimized way. Other than the beehive, in this case it\u2019s done with the usage of scripts. This is a project repository of Minor Spatial Computing 2020-2021, project group 1. The mid-term and Final submission's process, final products and underlying code/input can be found in this repository. The design challenge We as Project Apidae are requested to design a housing complex incorporating severalcommunal/public facilities for a cooperative live-work-playassociation at location \"Rotterdam, The block between Vijverhofstraat, Zomerhofstraat, Schoterbosstraat, and Teilingerstraat\". The requested housing complex will be the new home of garduate students, young professionals and elderly who are in need of assisted living. The complex has to provide communal and public facilities to ensure collectivity. Starting point The following program of requirements has been given: Housing: * Student Housing 80 units * Assisted Living 30 units * Starter Housing 100 units * testing spaces Communal spaces: * Underground Parking (minimum of 0.5 parking lots per * apartment) * Vegetation (minimum 30% of the plot) * Workshops/Fab-Labs/Co-working Space and Start-up Offices * Library + Cinematheque + Caf\u00e9/Pub + (pinball) Arcade * Co-cooking/Restaurant * Community Centre * Shop (grocery, tools and crafts) * (electricity producing/odourless /geek-friendly) Gym Also, the following design goals have been given: * Maximum Multi-scale Modularity (Qualitative) * Excellent Ergonomics (Qualitative) * Keeping at least the same amount of housing units as before (Quantitative) * Not blocking direct light for neighbour buildings (Quantitative) * Max solar gain potential (optional, Quantitative) * Max greenery (Quantitative) * Min noise (Quantitative) * Social integration (Qualitative) * Rational spectra of privacy and community (Qualitative) Why Apidae? As architecture students we often do things for a reason, without even knowing whether it will actually work. We would design our building in a certain shape, to maximize the amount of sunlight coming into the building, but without any scientific evidence. Besides that, the architecture world is quite conservative. Change, no matter the improvement, takes a long time to be accepted. At the same time, the construction industry is worldwide responsible for 40% of the C02-emission [Source] . A change in the way we design and form our buildings is necessary. This is where the apidae method comes into play. The apidae method scientifically substantiates design choices, makes the process more efficient and modular, while still giving the designer enough room for subjective choices. Project Phasing The documentation is divided in 4 phases: * A1_Planning: Preliminary spatial analysis on the site and idea proposal regarding design goals. (KPI, Program of Requirements, Diagrams) with the starting point as described in this home page as input. * A2_Configuring: Setting up the plot, determining voxel size. In principle, formulating the spatial concept of the building. (Lattice contruction and determining voxelsize) * A3_Massing: Computing envelopes and using those in order to logically place functional spaces and form shafts and corridors. After this, allowing the spaces to grow with the given criterias. (Spatial Analysis, Corridors and Shafts, Designing the lattice with voxel removal and ABM growth) * A4_Forming: Finalizing the results with polygonization and designing the borders of the voxels. (Polygonization and renders)","title":"Home"},{"location":"#the-design-challenge","text":"We as Project Apidae are requested to design a housing complex incorporating severalcommunal/public facilities for a cooperative live-work-playassociation at location \"Rotterdam, The block between Vijverhofstraat, Zomerhofstraat, Schoterbosstraat, and Teilingerstraat\". The requested housing complex will be the new home of garduate students, young professionals and elderly who are in need of assisted living. The complex has to provide communal and public facilities to ensure collectivity.","title":"The design challenge"},{"location":"#starting-point","text":"The following program of requirements has been given: Housing: * Student Housing 80 units * Assisted Living 30 units * Starter Housing 100 units * testing spaces Communal spaces: * Underground Parking (minimum of 0.5 parking lots per * apartment) * Vegetation (minimum 30% of the plot) * Workshops/Fab-Labs/Co-working Space and Start-up Offices * Library + Cinematheque + Caf\u00e9/Pub + (pinball) Arcade * Co-cooking/Restaurant * Community Centre * Shop (grocery, tools and crafts) * (electricity producing/odourless /geek-friendly) Gym Also, the following design goals have been given: * Maximum Multi-scale Modularity (Qualitative) * Excellent Ergonomics (Qualitative) * Keeping at least the same amount of housing units as before (Quantitative) * Not blocking direct light for neighbour buildings (Quantitative) * Max solar gain potential (optional, Quantitative) * Max greenery (Quantitative) * Min noise (Quantitative) * Social integration (Qualitative) * Rational spectra of privacy and community (Qualitative)","title":"Starting point"},{"location":"#why-apidae","text":"As architecture students we often do things for a reason, without even knowing whether it will actually work. We would design our building in a certain shape, to maximize the amount of sunlight coming into the building, but without any scientific evidence. Besides that, the architecture world is quite conservative. Change, no matter the improvement, takes a long time to be accepted. At the same time, the construction industry is worldwide responsible for 40% of the C02-emission [Source] . A change in the way we design and form our buildings is necessary. This is where the apidae method comes into play. The apidae method scientifically substantiates design choices, makes the process more efficient and modular, while still giving the designer enough room for subjective choices.","title":"Why Apidae?"},{"location":"#project-phasing","text":"The documentation is divided in 4 phases: * A1_Planning: Preliminary spatial analysis on the site and idea proposal regarding design goals. (KPI, Program of Requirements, Diagrams) with the starting point as described in this home page as input. * A2_Configuring: Setting up the plot, determining voxel size. In principle, formulating the spatial concept of the building. (Lattice contruction and determining voxelsize) * A3_Massing: Computing envelopes and using those in order to logically place functional spaces and form shafts and corridors. After this, allowing the spaces to grow with the given criterias. (Spatial Analysis, Corridors and Shafts, Designing the lattice with voxel removal and ABM growth) * A4_Forming: Finalizing the results with polygonization and designing the borders of the voxels. (Polygonization and renders)","title":"Project Phasing"},{"location":"about/","text":"About Spatial Computing in Architectural Design This documentation is part of the final project of the minor Spatial Computing in Architectural Design, course: Computational Design Studio (BK7083). For more information regarding the minor see link below: Course Description Contact us! apidaemethod@gmail.com Project Apidae members Project group 1 consists of the following students: Student Role Maartje Damen Diagrammer Eda Akaltun Journalist Siebren Meines Puzzle solver Tutors Name Faculty Dr. Ir. P. Nourain TU Delft, Design Informatics Ir. H. Hoogeboom TU Delft, Design Informatics Ir. S. Azadi TU Delft, Design Informatics","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#spatial-computing-in-architectural-design","text":"This documentation is part of the final project of the minor Spatial Computing in Architectural Design, course: Computational Design Studio (BK7083). For more information regarding the minor see link below: Course Description","title":"Spatial Computing in Architectural Design"},{"location":"about/#contact-us","text":"apidaemethod@gmail.com","title":"Contact us!"},{"location":"about/#project-apidae-members","text":"Project group 1 consists of the following students: Student Role Maartje Damen Diagrammer Eda Akaltun Journalist Siebren Meines Puzzle solver","title":"Project Apidae members"},{"location":"about/#tutors","text":"Name Faculty Dr. Ir. P. Nourain TU Delft, Design Informatics Ir. H. Hoogeboom TU Delft, Design Informatics Ir. S. Azadi TU Delft, Design Informatics","title":"Tutors"},{"location":"quotes/","text":"The Preacher Quotes by Pirouz Nourian Our purpose is not to make people happy, our purpose is to learn people The easy things in life eventually make life more difficult In computer science we have a problem if we don\u2019t have a problem If you take a ball of dough and turn it into a duck, then leave if for an hour, it will have turned into a ball again. Imagine your neighbour is shooting to the sun with a gun, every time they hit your building it melts like a swiss cheese Who is supposed to shoot whom? Are you shooting at your neighbour or are your neighbours shooting at you? There is something divine about 6 It doesn't particularly have a brain, but it loves oats How on earth can a creature that doesn't even have a brain design something like that?","title":"Quotes"},{"location":"reflection/","text":"Reflection Result Even though our result may not be perfect, it is a good step in the right direction of a better design method. We realize that finishing our project would perhaps have taken a couple years, but we believe that using this method is a great improvement as apposed to the method we were used to. Group process Our different personalities and beliefs made us as a group very critical towards each other. This made us have long and deep arguments over certain choices that had to be made, which made us even more convinced of the decisions made. Our different personalities and roles in the group complemented each other really well. We discussed the things we wanted to do and achieve with the specific scripts and then someone became an \u201cexpert\u201d for that specific script. This gave each of us more time to dig deeper into the code of a certain script and ultimately made us more understanding of the code. Teachers We would like to express our thankfulness to Pirouz Nourian, Shervin Azadi and Hans Hoogenboom as they have guided as through this amazing adventure. They have brought us inspiration and knowledge we will carry with us through the rest of our life. They have showed us that architecture can be progressive, efficient, scientific in an extremely fun and exciting way. This course surely wasn't easy, but definitely worth it.","title":"Reflection"},{"location":"reflection/#result","text":"Even though our result may not be perfect, it is a good step in the right direction of a better design method. We realize that finishing our project would perhaps have taken a couple years, but we believe that using this method is a great improvement as apposed to the method we were used to.","title":"Result"},{"location":"reflection/#group-process","text":"Our different personalities and beliefs made us as a group very critical towards each other. This made us have long and deep arguments over certain choices that had to be made, which made us even more convinced of the decisions made. Our different personalities and roles in the group complemented each other really well. We discussed the things we wanted to do and achieve with the specific scripts and then someone became an \u201cexpert\u201d for that specific script. This gave each of us more time to dig deeper into the code of a certain script and ultimately made us more understanding of the code.","title":"Group process"},{"location":"reflection/#teachers","text":"We would like to express our thankfulness to Pirouz Nourian, Shervin Azadi and Hans Hoogenboom as they have guided as through this amazing adventure. They have brought us inspiration and knowledge we will carry with us through the rest of our life. They have showed us that architecture can be progressive, efficient, scientific in an extremely fun and exciting way. This course surely wasn't easy, but definitely worth it.","title":"Teachers"},{"location":"A1_Planning/a1_planning_process/","text":"Process of planning, forming the Program of Requirements Building identity The building exploits the benefits of collectivity as much as possible while limiting its disadvantages. With keeping privacy in mind, the collectivity will provide a better housing situation and a stronger social connection for every inhabitant. The green of the building and surroundings will contribute to a better and resilient neighbourhood. The energy-neutral building in combination with the green and sustainable design will be ready for the future and will form an example and a benchmark for other buildings. User Experience Students The live-work-play co\u00f6perative forms a home basis for the students, where they are not only living with other students, but where they find collective spaces with many extra possibilities. They can make use of the co-cooking kitchen to invite friends and family over and enjoy all the other facilities provided in this building, like the gym and the co-working spaces. The mix with other users gives the student the opportunity to get a discount on their rent by spending time with and helping the elderly and by babysitting the children of the starters. To make this work, a bulletin board is central in the community centre, where people can ask for and give help, products or even leftovers. The community centre forms a place to connect with other users, but also provides a lounge space where they can relax and enjoy a drink, read a book or have friends over. Elderly The elderly in the building will have all the privacy they need, and will not experience any nuisance from the students or starters. By grouping the elderly homes not only nuisance is battled, this is also efficient for elderly support, and to boost the interaction between elderly. This is done by providing coffee spaces near the apartments. Besides the privacy and tranquility in the area of the houses for elderly there are many options to stay active and be in touch with other user groups and externals. The community centre provides many entertainment options for them, and gives them a chance to interact with others. The students can help the elderly with daily tasks and do social activities. This way social isolation is being battled. Starters The starters in this building finished their education and started to work. After a hard day at work the inhabitants enter the building without going through the collective spaces, straight to their homes. If they are in a relationship and/or having kids they will most of the time cook their own dinner. When alone or sometimes do not want to cook they choose to make use of the co-cooking space in the collective area. The dwellings of the starters are big enough to expand the household and have room for teleworking. Therefore the dwellings are well sound isolated and contribute to the privacy of the inhabitants. The starters can do anything in their home with keeping their privacy, but when they need social contact or longing back to their student life they go to the community centre or the bar for seeing a movie or socializing with others. While the starters are busy with their career and family, they could still help in the buildings\u2019 household activities, like helping the elderly, cooking for people or doing activities. The building gives starters the opportunities to work near their home with office workspaces, fab labs and other working rooms. Therefore combining family-life and working will be a nice experience. Still, the majority of the people will work somewhere else. For them, students and elderly can help the starters by providing day care for the children they might have. Externals By adding this building to the neighbourhood, the area gets more lively and all the shops and restaurants will get an economic boost. Thereby, the overall quality of the area can improve and it gets more interesting to go there. A second improvement where externals profit from, is the addition of greenery in the scene. These greenspaces will make the place less rough and gives it even more the reason to go there and enjoy the lively neighbourhood. Key Performance Indicators Collectivity Connect all residents by creating collective (indoor and outdoor) spaces, providing an inclusive living environment. Give the different target groups the option to mix together, but also be able to seclude from each other to have the perks of living together, but not the disadvantages. Home quality Make sure every house has a view and a low proximity to green space Maintain privacy in every residence Ability to enter the building without going through the collective spaces Minimise noise disturbance (nuisance) within the building Diversity in audience Create a diverse offer of residences Spread target groups within the building Sustainability An opportunity for a green focussed design, where collectivity and sustainability can be connected optimize roof and orientation for solar panels Modularity Self-sufficient Energy-neutral (BENG) implement vegetable garden to actively involve residents in sustainability and connect with each other (> close to co-cooking) Improvements on the site Offering students of the nearby hospitality school the possibility to gain experience in the cocooking kitchens and pub. Linking the greenery of the surrounding are with the greenery on site to improve the green image of the neighbourhood. Connecting local amenities towards the public amenities on site so that the local amenities attract more business. Improving the overall ambiance of the neighbourhood Space sizes Estimation internal and external occupation/traffic Internal inhabitants: 30 elders, 80 students + 100 * (2.0) = 200 starters. This equals 310 internal tenants. External traffic: According to Rotterdam statistics the neighborhood Agniesbuurt in Rotterdam has =/- 4100 inhabitants. Estimation community: 70% of the people (18 and older) are members in a club/community. 310 * 0.7 = 217 members. 310*0.12 = +/- 40 members are in hobby clubs 310 * 0.12 = 37.2 = 38 internal people will engage in hobby like activities 310 * 0.15 = 64.5 = 65 internal will engage in voluntary work for elders/neighbors/disabled Space areas 0 Community centre cinema + co-cooking + library + workshop room + 15% 1 Cinematheque 35 m2 for 15 people 70 m2 for 30 people. There are big cinemas nearby, so therefore the community has a small cinematheque. 2 Co-cooking Cooking in pairs (or more?); if full time used: 160 = 80 pairs. Assuming cooking around 16:00-20:00, 1 hour each pair: 80/4 = 20cooking units needed. per co-cooking unit 6m2 * 20 = 120 m2 + storage space 40 m2 + 15% = 190 m2 3 Library 10 seats per 1k users. Community library: 217+4100 members = 43.17 seats. 2500 square feet = 232 m2 4 Workshop room 20 covid proof spaces for workshop, or 50 standing = 200 m2 (20 in 200m2 is possible too, but tighter) 5 Fab labs 8 m2 per fab lab tafel. 310*0.12 = +/- 40 members are in hobby clubs 15 tables * 8 = 120 m2 + 15% = 138 m2 6 entrance hall 100+80+30 = 210 / 6 = 35 35 * 1m2 = 35 m2 + +/- 310 people need to enter. Let's say 4 entrances (every four cardinal direction): 310/4 = 78 people need to enter. +/- 30m2 per entrance 7 parking +/- 22 m2 * amount of cars + entrance etc. 0.5 parking lot per apartment (80+30+100 * 0.5 = 210) = 105 spots 2310 m2 + 90 m2 entrance etc = 2400 m2 underground parking. 8 assisted living (Beschermd wonen \u2018s Heeren Loo: 225-230 m2 per group of 6-7) 30 units = 225*5 (30/6) = 1125 m2 9 starter housing (80m2 per unit) 100*80 = 8000 10 student housing (reference floor plan) +/- 30 m2 * 80 + 15% transport etc = 2400 m2 11 cafe pub restaurant 200 seats 3000+2000 = 465 m2 12 arcade 600 m2 13 shop 12000 sq ft = 1115 m2 14 Co working spaces \u201cThe ideal architectural module of office space is 1.20 meters, but could be between 1.20 and 1.40 meters\u201d 4 1.40 + 20% space between/routing = 6.8 m2 80 students/starters : 20 co working spaces. 20 6.8 m2 = 136 m2 15 Start up office Modular units rentable from 25m2 100 starters, 50 units (external rentable when empty) 1250 m2 16 Gym 310 internal, 20% = 62 tenants. 4100 externals, 20% = 820 tenants. Nearby (walking distance) gym amount: +/- 12 820/4 ours will be 4th big one ; there's actually more but assuming the are smaller in capacity) = +/- 205 62+205 = approx 267 people will use the gym = 10-12 square feet for each member (1.1m2). = 267*12 = 3204 square foot = +/= 300m2 18 coffee hub assisted living 10 m2 per hub, 3 hubs in between every unit group = 30 m2 19 coffee hub starters Every 20 units 10m2 hub = 50m2 20 coffee hub students Every 20 1 hub, 4 * 10m2 = 40 m2","title":"Process"},{"location":"A1_Planning/a1_planning_process/#process-of-planning-forming-the-program-of-requirements","text":"","title":"Process of planning, forming the Program of Requirements"},{"location":"A1_Planning/a1_planning_process/#building-identity","text":"The building exploits the benefits of collectivity as much as possible while limiting its disadvantages. With keeping privacy in mind, the collectivity will provide a better housing situation and a stronger social connection for every inhabitant. The green of the building and surroundings will contribute to a better and resilient neighbourhood. The energy-neutral building in combination with the green and sustainable design will be ready for the future and will form an example and a benchmark for other buildings.","title":"Building identity"},{"location":"A1_Planning/a1_planning_process/#user-experience","text":"","title":"User Experience"},{"location":"A1_Planning/a1_planning_process/#students","text":"The live-work-play co\u00f6perative forms a home basis for the students, where they are not only living with other students, but where they find collective spaces with many extra possibilities. They can make use of the co-cooking kitchen to invite friends and family over and enjoy all the other facilities provided in this building, like the gym and the co-working spaces. The mix with other users gives the student the opportunity to get a discount on their rent by spending time with and helping the elderly and by babysitting the children of the starters. To make this work, a bulletin board is central in the community centre, where people can ask for and give help, products or even leftovers. The community centre forms a place to connect with other users, but also provides a lounge space where they can relax and enjoy a drink, read a book or have friends over.","title":"Students"},{"location":"A1_Planning/a1_planning_process/#elderly","text":"The elderly in the building will have all the privacy they need, and will not experience any nuisance from the students or starters. By grouping the elderly homes not only nuisance is battled, this is also efficient for elderly support, and to boost the interaction between elderly. This is done by providing coffee spaces near the apartments. Besides the privacy and tranquility in the area of the houses for elderly there are many options to stay active and be in touch with other user groups and externals. The community centre provides many entertainment options for them, and gives them a chance to interact with others. The students can help the elderly with daily tasks and do social activities. This way social isolation is being battled.","title":"Elderly"},{"location":"A1_Planning/a1_planning_process/#starters","text":"The starters in this building finished their education and started to work. After a hard day at work the inhabitants enter the building without going through the collective spaces, straight to their homes. If they are in a relationship and/or having kids they will most of the time cook their own dinner. When alone or sometimes do not want to cook they choose to make use of the co-cooking space in the collective area. The dwellings of the starters are big enough to expand the household and have room for teleworking. Therefore the dwellings are well sound isolated and contribute to the privacy of the inhabitants. The starters can do anything in their home with keeping their privacy, but when they need social contact or longing back to their student life they go to the community centre or the bar for seeing a movie or socializing with others. While the starters are busy with their career and family, they could still help in the buildings\u2019 household activities, like helping the elderly, cooking for people or doing activities. The building gives starters the opportunities to work near their home with office workspaces, fab labs and other working rooms. Therefore combining family-life and working will be a nice experience. Still, the majority of the people will work somewhere else. For them, students and elderly can help the starters by providing day care for the children they might have.","title":"Starters"},{"location":"A1_Planning/a1_planning_process/#externals","text":"By adding this building to the neighbourhood, the area gets more lively and all the shops and restaurants will get an economic boost. Thereby, the overall quality of the area can improve and it gets more interesting to go there. A second improvement where externals profit from, is the addition of greenery in the scene. These greenspaces will make the place less rough and gives it even more the reason to go there and enjoy the lively neighbourhood.","title":"Externals"},{"location":"A1_Planning/a1_planning_process/#key-performance-indicators","text":"Collectivity Connect all residents by creating collective (indoor and outdoor) spaces, providing an inclusive living environment. Give the different target groups the option to mix together, but also be able to seclude from each other to have the perks of living together, but not the disadvantages. Home quality Make sure every house has a view and a low proximity to green space Maintain privacy in every residence Ability to enter the building without going through the collective spaces Minimise noise disturbance (nuisance) within the building Diversity in audience Create a diverse offer of residences Spread target groups within the building Sustainability An opportunity for a green focussed design, where collectivity and sustainability can be connected optimize roof and orientation for solar panels Modularity Self-sufficient Energy-neutral (BENG) implement vegetable garden to actively involve residents in sustainability and connect with each other (> close to co-cooking)","title":"Key Performance Indicators"},{"location":"A1_Planning/a1_planning_process/#improvements-on-the-site","text":"Offering students of the nearby hospitality school the possibility to gain experience in the cocooking kitchens and pub. Linking the greenery of the surrounding are with the greenery on site to improve the green image of the neighbourhood. Connecting local amenities towards the public amenities on site so that the local amenities attract more business. Improving the overall ambiance of the neighbourhood","title":"Improvements on the site"},{"location":"A1_Planning/a1_planning_process/#space-sizes","text":"","title":"Space sizes"},{"location":"A1_Planning/a1_planning_process/#estimation-internal-and-external-occupationtraffic","text":"Internal inhabitants: 30 elders, 80 students + 100 * (2.0) = 200 starters. This equals 310 internal tenants. External traffic: According to Rotterdam statistics the neighborhood Agniesbuurt in Rotterdam has =/- 4100 inhabitants. Estimation community: 70% of the people (18 and older) are members in a club/community. 310 * 0.7 = 217 members. 310*0.12 = +/- 40 members are in hobby clubs 310 * 0.12 = 37.2 = 38 internal people will engage in hobby like activities 310 * 0.15 = 64.5 = 65 internal will engage in voluntary work for elders/neighbors/disabled","title":"Estimation internal and external occupation/traffic"},{"location":"A1_Planning/a1_planning_process/#space-areas","text":"0 Community centre cinema + co-cooking + library + workshop room + 15% 1 Cinematheque 35 m2 for 15 people 70 m2 for 30 people. There are big cinemas nearby, so therefore the community has a small cinematheque. 2 Co-cooking Cooking in pairs (or more?); if full time used: 160 = 80 pairs. Assuming cooking around 16:00-20:00, 1 hour each pair: 80/4 = 20cooking units needed. per co-cooking unit 6m2 * 20 = 120 m2 + storage space 40 m2 + 15% = 190 m2 3 Library 10 seats per 1k users. Community library: 217+4100 members = 43.17 seats. 2500 square feet = 232 m2 4 Workshop room 20 covid proof spaces for workshop, or 50 standing = 200 m2 (20 in 200m2 is possible too, but tighter) 5 Fab labs 8 m2 per fab lab tafel. 310*0.12 = +/- 40 members are in hobby clubs 15 tables * 8 = 120 m2 + 15% = 138 m2 6 entrance hall 100+80+30 = 210 / 6 = 35 35 * 1m2 = 35 m2 + +/- 310 people need to enter. Let's say 4 entrances (every four cardinal direction): 310/4 = 78 people need to enter. +/- 30m2 per entrance 7 parking +/- 22 m2 * amount of cars + entrance etc. 0.5 parking lot per apartment (80+30+100 * 0.5 = 210) = 105 spots 2310 m2 + 90 m2 entrance etc = 2400 m2 underground parking. 8 assisted living (Beschermd wonen \u2018s Heeren Loo: 225-230 m2 per group of 6-7) 30 units = 225*5 (30/6) = 1125 m2 9 starter housing (80m2 per unit) 100*80 = 8000 10 student housing (reference floor plan) +/- 30 m2 * 80 + 15% transport etc = 2400 m2 11 cafe pub restaurant 200 seats 3000+2000 = 465 m2 12 arcade 600 m2 13 shop 12000 sq ft = 1115 m2 14 Co working spaces \u201cThe ideal architectural module of office space is 1.20 meters, but could be between 1.20 and 1.40 meters\u201d 4 1.40 + 20% space between/routing = 6.8 m2 80 students/starters : 20 co working spaces. 20 6.8 m2 = 136 m2 15 Start up office Modular units rentable from 25m2 100 starters, 50 units (external rentable when empty) 1250 m2 16 Gym 310 internal, 20% = 62 tenants. 4100 externals, 20% = 820 tenants. Nearby (walking distance) gym amount: +/- 12 820/4 ours will be 4th big one ; there's actually more but assuming the are smaller in capacity) = +/- 205 62+205 = approx 267 people will use the gym = 10-12 square feet for each member (1.1m2). = 267*12 = 3204 square foot = +/= 300m2 18 coffee hub assisted living 10 m2 per hub, 3 hubs in between every unit group = 30 m2 19 coffee hub starters Every 20 units 10m2 hub = 50m2 20 coffee hub students Every 20 1 hub, 4 * 10m2 = 40 m2","title":"Space areas"},{"location":"A1_Planning/a1_planning_product/","text":"Product of planning Metro network diagram & Bubble diagram Through the process, the following metro network diagram and bubble diagram is created in order to visualize the desired and necessary connectivity between spaces. you can zoom in on the flowchart with the bar below that appears when hovering over the diagram","title":"Product"},{"location":"A1_Planning/a1_planning_product/#product-of-planning","text":"","title":"Product of planning"},{"location":"A1_Planning/a1_planning_product/#metro-network-diagram-bubble-diagram","text":"Through the process, the following metro network diagram and bubble diagram is created in order to visualize the desired and necessary connectivity between spaces. you can zoom in on the flowchart with the bar below that appears when hovering over the diagram","title":"Metro network diagram &amp; Bubble diagram"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/","text":"Process of configuring Determining voxelsize In order to determine the voxelsize that our growth simulation will work with, a case study has been done. The voxel size has been based on stair sizing because ----------------------. Starting points Stairs Free space residences +/- 270 cm 270 cm= 1 height? 270/6= 45 270/9= 30 270/5= 54 270/3= 90 270/2= 135 Stair dimensions from \u2018\u2019menselijke maat\u2019\u2019 : stair angle between 30 and 41 degrees Stair width for moving in 2 directions, minimum 120 cm rise 14cm advised, minimum of 8cm tread with minimum 25 cm 38 degrees ideal size for stairs? Bouwbesluit minimum tread with 22cm maximum rise 0,188cm source Corridor Main hallways: at least 1,5 metre in width support hallways: at least 1,2 metre in width source Stair sizes Option Rise Tread width Length stairs Width staircase Option 1 Rise= 18cm (3x6) 270/18 = 15 steps 30cm (5x6) 15x30 = 450cm 120cm (20x6) Option 2 18cm (2x9) 270/18 = 15 steps 27cm (3x9) 15x27= 405 126 cm(14x9) Option 3 18cm (3x6): 306/18 = 17 steps 30cm (5x6) 17x30 = 510cm 120cm (20x6) Option 4 18cm (2x9) 306/18 = 17 steps 27cm (3x9) 18x27= 486cm 126 cm(14x9) Option 5 18cm (3x6) 306/18 = 17 steps 24cm (4x6) 17x24 = 408cm 120cm (20x6) For further research we will only use option 3,4 & 5. Since after discussion we decided to enlarge the floor height. First approach Y dimension Option Based on stair option x/y/z sizes Comment Option 1 Option 3 120 / 510 / 306 510 is quite a big size, but there\u2019s no division possible which leads to an integer multitude of 6. So this will not be a good voxel size. Option 2 Option 4 126 / 486 / 306 -> 126 / 162 / 306 To make it fitting for human dimensions let\u2019s divide the the y value by 3. The stairs which we calculated earlier will now be 3 voxels. Option 3 Option 5 120 / 408 / 306 -> 120 / 102 / 306 The previous voxels will be sufficient for a building with the same height everywhere, but the z value is too big to differ in height through the building. Z dimension Option Size Ratio Option 1: based on y dimension option 2 and stairs option 4 divisible by 9 126/162/306 divide the z value with 2-> 126/162/153 the staircase will now be 3x2 voxels ratio 1 to 1.3 Option 2: based on y dimension option 3 and stairs option 5 divisible by 6 120/204/102 divide the z value with 3->The staircase will now be 2x3 voxels ratio 1 to 1.7 Option 3: based on y dimension option 3 and stairs option 5 divisible by 6 120/102/306 divide the z value with 3-> the staircase will now be 4x3 ratio 1 to 0,85 Definitive approach Since a different x and y value affected the modularity of the building and spaces were otherwise forced into one particular direction. We have decided after consultation with our tutors to take the same dimension for the x and y value of the voxel. For the definitive approach towards the voxel size we will use the option for stair dimensions we previously used, since the size was thoroughly thought about in the first approach. Apart from this, as a project group we decided it would be a pragmatic approach to decide our tartan grid based on the thickness of the support structure the building will be made of, to make it fit into the tartan grid. For this, we made a rough estimation of the area of our building through the Program of Requirements, and how this relates to the available area for our building (obtained through measurements in ArcGIS), we came to a rough estimate of 3 stories, if the available area is maximised, in other words: if all the spaces are summed up. Since we have to take into account the varying height in the building, we decided to look at surrounding buildings in the area and the width of the streets and decided upon a maximum of 10 stories high. We estimated that we would need a SHS-HF-300 profile for this height. We chose this profile because it has the same x as y value and based our voxel grid on this. Although these dimensions (300x300) are workable, the size is really small and not really algorithm friendly because the building would consist of too many voxels because of the building site's size. So let\u2019s take the 300x300 voxels as our meso voxels for the tartan grid. If we go back to the stair dimensions which were previously researched and have chosen the following can be said: Rise= 18cm (3x6), 306/18 = 17 steps, tread width= 30cm (5x6), length stairs= 17x30 = 510cm, width staircase= 120cm (20x6) With a stair width of 120cm we could make our voxel size based on 120cm+ meso voxel. But to be on the safe side, and taken into account the railings of the stairs it\u2019s better to take an extra meso voxel for the voxel size. So the voxel size will be 150cm + mesovoxel = 180cm. The tartan grid is the place where the structural profiles or the walls can come. Space criteria In order to meet the desired quality as stated in A1_Planning and given through a Program of Requirements, criteria have been set for spaces. Criteria to spaces The following process has been implemented in order to moderate the input that is necessary in order to work with later on. Table/Matrix of relations The matrix table with connectivity between spaces has been made through the bubble diagram: Program of Requirements with integration of the voxelsize and layers of spaces The following definitive Program of Requirements has been formed through the chosen voxelsize and the given Program of Requirements beforehand. Voxelizing the lattice As the final voxelsize is determined, the location can be voxelized. The given 'compulsory envelope' is being filled with voxels sized 1.8m * 1.8m * 1.8m, which results in the full lattice. compulsory envelope voxelized envelope Because of the relatively small voxelsize, next to this a second lattice is being generated, with voxelsizes of 15m 15m 15m. This 'low-resolution' lattice could later be used to make the more heavy calculations, and by interpolation of these values a good estimate of the 'high-resolution' voxels is being generated. low-resolution voxelized envelope","title":"Process of configuring"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#process-of-configuring","text":"","title":"Process of configuring"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#determining-voxelsize","text":"In order to determine the voxelsize that our growth simulation will work with, a case study has been done. The voxel size has been based on stair sizing because ----------------------.","title":"Determining voxelsize"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#starting-points","text":"Stairs Free space residences +/- 270 cm 270 cm= 1 height? 270/6= 45 270/9= 30 270/5= 54 270/3= 90 270/2= 135 Stair dimensions from \u2018\u2019menselijke maat\u2019\u2019 : stair angle between 30 and 41 degrees Stair width for moving in 2 directions, minimum 120 cm rise 14cm advised, minimum of 8cm tread with minimum 25 cm 38 degrees ideal size for stairs? Bouwbesluit minimum tread with 22cm maximum rise 0,188cm source Corridor Main hallways: at least 1,5 metre in width support hallways: at least 1,2 metre in width source","title":"Starting points"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#stair-sizes","text":"Option Rise Tread width Length stairs Width staircase Option 1 Rise= 18cm (3x6) 270/18 = 15 steps 30cm (5x6) 15x30 = 450cm 120cm (20x6) Option 2 18cm (2x9) 270/18 = 15 steps 27cm (3x9) 15x27= 405 126 cm(14x9) Option 3 18cm (3x6): 306/18 = 17 steps 30cm (5x6) 17x30 = 510cm 120cm (20x6) Option 4 18cm (2x9) 306/18 = 17 steps 27cm (3x9) 18x27= 486cm 126 cm(14x9) Option 5 18cm (3x6) 306/18 = 17 steps 24cm (4x6) 17x24 = 408cm 120cm (20x6) For further research we will only use option 3,4 & 5. Since after discussion we decided to enlarge the floor height.","title":"Stair sizes"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#first-approach","text":"","title":"First approach"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#y-dimension","text":"Option Based on stair option x/y/z sizes Comment Option 1 Option 3 120 / 510 / 306 510 is quite a big size, but there\u2019s no division possible which leads to an integer multitude of 6. So this will not be a good voxel size. Option 2 Option 4 126 / 486 / 306 -> 126 / 162 / 306 To make it fitting for human dimensions let\u2019s divide the the y value by 3. The stairs which we calculated earlier will now be 3 voxels. Option 3 Option 5 120 / 408 / 306 -> 120 / 102 / 306 The previous voxels will be sufficient for a building with the same height everywhere, but the z value is too big to differ in height through the building.","title":"Y dimension"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#z-dimension","text":"Option Size Ratio Option 1: based on y dimension option 2 and stairs option 4 divisible by 9 126/162/306 divide the z value with 2-> 126/162/153 the staircase will now be 3x2 voxels ratio 1 to 1.3 Option 2: based on y dimension option 3 and stairs option 5 divisible by 6 120/204/102 divide the z value with 3->The staircase will now be 2x3 voxels ratio 1 to 1.7 Option 3: based on y dimension option 3 and stairs option 5 divisible by 6 120/102/306 divide the z value with 3-> the staircase will now be 4x3 ratio 1 to 0,85","title":"Z dimension"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#definitive-approach","text":"Since a different x and y value affected the modularity of the building and spaces were otherwise forced into one particular direction. We have decided after consultation with our tutors to take the same dimension for the x and y value of the voxel. For the definitive approach towards the voxel size we will use the option for stair dimensions we previously used, since the size was thoroughly thought about in the first approach. Apart from this, as a project group we decided it would be a pragmatic approach to decide our tartan grid based on the thickness of the support structure the building will be made of, to make it fit into the tartan grid. For this, we made a rough estimation of the area of our building through the Program of Requirements, and how this relates to the available area for our building (obtained through measurements in ArcGIS), we came to a rough estimate of 3 stories, if the available area is maximised, in other words: if all the spaces are summed up. Since we have to take into account the varying height in the building, we decided to look at surrounding buildings in the area and the width of the streets and decided upon a maximum of 10 stories high. We estimated that we would need a SHS-HF-300 profile for this height. We chose this profile because it has the same x as y value and based our voxel grid on this. Although these dimensions (300x300) are workable, the size is really small and not really algorithm friendly because the building would consist of too many voxels because of the building site's size. So let\u2019s take the 300x300 voxels as our meso voxels for the tartan grid. If we go back to the stair dimensions which were previously researched and have chosen the following can be said: Rise= 18cm (3x6), 306/18 = 17 steps, tread width= 30cm (5x6), length stairs= 17x30 = 510cm, width staircase= 120cm (20x6) With a stair width of 120cm we could make our voxel size based on 120cm+ meso voxel. But to be on the safe side, and taken into account the railings of the stairs it\u2019s better to take an extra meso voxel for the voxel size. So the voxel size will be 150cm + mesovoxel = 180cm. The tartan grid is the place where the structural profiles or the walls can come.","title":"Definitive approach"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#space-criteria","text":"In order to meet the desired quality as stated in A1_Planning and given through a Program of Requirements, criteria have been set for spaces.","title":"Space criteria"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#criteria-to-spaces","text":"The following process has been implemented in order to moderate the input that is necessary in order to work with later on.","title":"Criteria to spaces"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#tablematrix-of-relations","text":"The matrix table with connectivity between spaces has been made through the bubble diagram:","title":"Table/Matrix of relations"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#program-of-requirements-with-integration-of-the-voxelsize-and-layers-of-spaces","text":"The following definitive Program of Requirements has been formed through the chosen voxelsize and the given Program of Requirements beforehand.","title":"Program of Requirements with integration of the voxelsize and layers of spaces"},{"location":"A2_Configuring/%5BNOT%20USED%5D%20a2_configuring_process/#voxelizing-the-lattice","text":"As the final voxelsize is determined, the location can be voxelized. The given 'compulsory envelope' is being filled with voxels sized 1.8m * 1.8m * 1.8m, which results in the full lattice. compulsory envelope voxelized envelope Because of the relatively small voxelsize, next to this a second lattice is being generated, with voxelsizes of 15m 15m 15m. This 'low-resolution' lattice could later be used to make the more heavy calculations, and by interpolation of these values a good estimate of the 'high-resolution' voxels is being generated. low-resolution voxelized envelope","title":"Voxelizing the lattice"},{"location":"A2_Configuring/a2_configuring_Determiningvoxelsize/","text":"Determining voxelsize In order to determine the voxelsize that our growth simulation will work with, a case study has been done. The starting point to generate a workable voxel size is the sizing of the stairs. Because of the functionality and the limited flexibility this stairsize is fundamental in use of the building and therefore functions as the main guide towards a useful gridsize. Starting points Stairs Free space residences +/- 270 cm 270 cm= 1 height? 270/6= 45 270/9= 30 270/5= 54 270/3= 90 270/2= 135 Stair dimensions from \u2018\u2019menselijke maat\u2019\u2019 : stair angle between 30 and 41 degrees Stair width for moving in 2 directions, minimum 120 cm rise 14cm advised, minimum of 8cm tread with minimum 25 cm 38 degrees ideal size for stairs? Bouwbesluit minimum tread with 22cm maximum rise 0,188cm source Corridor Main hallways: at least 1,5 metre in width support hallways: at least 1,2 metre in width source Stair sizes Option Rise Tread width Length stairs Width staircase Option 1 Rise= 18cm (3x6) 270/18 = 15 steps 30cm (5x6) 15x30 = 450cm 120cm (20x6) Option 2 18cm (2x9) 270/18 = 15 steps 27cm (3x9) 15x27= 405 126 cm(14x9) Option 3 18cm (3x6): 306/18 = 17 steps 30cm (5x6) 17x30 = 510cm 120cm (20x6) Option 4 18cm (2x9) 306/18 = 17 steps 27cm (3x9) 18x27= 486cm 126 cm(14x9) Option 5 18cm (3x6) 306/18 = 17 steps 24cm (4x6) 17x24 = 408cm 120cm (20x6) For further research we will only use option 3,4 & 5. Since after discussion we decided to enlarge the floor height. First approach Y dimension Option Based on stair option x/y/z sizes Comment Option 1 Option 3 120 / 510 / 306 510 is quite a big size, but there\u2019s no division possible which leads to an integer multitude of 6. So this will not be a good voxel size. Option 2 Option 4 126 / 486 / 306 -> 126 / 162 / 306 To make it fitting for human dimensions let\u2019s divide the the y value by 3. The stairs which we calculated earlier will now be 3 voxels. Option 3 Option 5 120 / 408 / 306 -> 120 / 102 / 306 The previous voxels will be sufficient for a building with the same height everywhere, but the z value is too big to differ in height through the building. Z dimension Option Size Ratio Option 1: based on y dimension option 2 and stairs option 4 divisible by 9 126/162/306 divide the z value with 2-> 126/162/153 the staircase will now be 3x2 voxels ratio 1 to 1.3 Option 2: based on y dimension option 3 and stairs option 5 divisible by 6 120/204/102 divide the z value with 3->The staircase will now be 2x3 voxels ratio 1 to 1.7 Option 3: based on y dimension option 3 and stairs option 5 divisible by 6 120/102/306 divide the z value with 3-> the staircase will now be 4x3 ratio 1 to 0,85 Definitive approach Since a different x and y value affected the modularity of the building and spaces were otherwise forced into one particular direction. We have decided after consultation with our tutors to take the same dimension for the x and y value of the voxel. For the definitive approach towards the voxel size we will use the option for stair dimensions we previously used, since the size was thoroughly thought about in the first approach. Apart from this, as a project group we decided it would be a pragmatic approach to decide our tartan grid based on the thickness of the support structure the building will be made of, to make it fit into the tartan grid. For this, we made a rough estimation of the area of our building through the Program of Requirements, and how this relates to the available area for our building (obtained through measurements in ArcGIS), we came to a rough estimate of 3 stories, if the available area is maximised, in other words: if all the spaces are summed up. Since we have to take into account the varying height in the building, we decided to look at surrounding buildings in the area and the width of the streets and decided upon a maximum of 10 stories high. We estimated that we would need a SHS-HF-300 profile for this height. We chose this profile because it has the same x as y value and based our voxel grid on this. Although these dimensions (300x300) are workable, the size is really small and not really algorithm friendly because the building would consist of too many voxels because of the building site's size. So let\u2019s take the 300x300 voxels as our meso voxels for the tartan grid. If we go back to the stair dimensions which were previously researched and have chosen the following can be said: Rise= 18cm (3x6), 306/18 = 17 steps, tread width= 30cm (5x6), length stairs= 17x30 = 510cm, width staircase= 120cm (20x6) With a stair width of 120cm we could make our voxel size based on 120cm+ meso voxel. But to be on the safe side, and taken into account the railings of the stairs it\u2019s better to take an extra meso voxel for the voxel size. So the voxel size will be 150cm + mesovoxel = 180cm. The tartan grid is the place where the structural profiles or the walls can come.","title":"Voxelsize determination"},{"location":"A2_Configuring/a2_configuring_Determiningvoxelsize/#determining-voxelsize","text":"In order to determine the voxelsize that our growth simulation will work with, a case study has been done. The starting point to generate a workable voxel size is the sizing of the stairs. Because of the functionality and the limited flexibility this stairsize is fundamental in use of the building and therefore functions as the main guide towards a useful gridsize.","title":"Determining voxelsize"},{"location":"A2_Configuring/a2_configuring_Determiningvoxelsize/#starting-points","text":"Stairs Free space residences +/- 270 cm 270 cm= 1 height? 270/6= 45 270/9= 30 270/5= 54 270/3= 90 270/2= 135 Stair dimensions from \u2018\u2019menselijke maat\u2019\u2019 : stair angle between 30 and 41 degrees Stair width for moving in 2 directions, minimum 120 cm rise 14cm advised, minimum of 8cm tread with minimum 25 cm 38 degrees ideal size for stairs? Bouwbesluit minimum tread with 22cm maximum rise 0,188cm source Corridor Main hallways: at least 1,5 metre in width support hallways: at least 1,2 metre in width source","title":"Starting points"},{"location":"A2_Configuring/a2_configuring_Determiningvoxelsize/#stair-sizes","text":"Option Rise Tread width Length stairs Width staircase Option 1 Rise= 18cm (3x6) 270/18 = 15 steps 30cm (5x6) 15x30 = 450cm 120cm (20x6) Option 2 18cm (2x9) 270/18 = 15 steps 27cm (3x9) 15x27= 405 126 cm(14x9) Option 3 18cm (3x6): 306/18 = 17 steps 30cm (5x6) 17x30 = 510cm 120cm (20x6) Option 4 18cm (2x9) 306/18 = 17 steps 27cm (3x9) 18x27= 486cm 126 cm(14x9) Option 5 18cm (3x6) 306/18 = 17 steps 24cm (4x6) 17x24 = 408cm 120cm (20x6) For further research we will only use option 3,4 & 5. Since after discussion we decided to enlarge the floor height.","title":"Stair sizes"},{"location":"A2_Configuring/a2_configuring_Determiningvoxelsize/#first-approach","text":"","title":"First approach"},{"location":"A2_Configuring/a2_configuring_Determiningvoxelsize/#y-dimension","text":"Option Based on stair option x/y/z sizes Comment Option 1 Option 3 120 / 510 / 306 510 is quite a big size, but there\u2019s no division possible which leads to an integer multitude of 6. So this will not be a good voxel size. Option 2 Option 4 126 / 486 / 306 -> 126 / 162 / 306 To make it fitting for human dimensions let\u2019s divide the the y value by 3. The stairs which we calculated earlier will now be 3 voxels. Option 3 Option 5 120 / 408 / 306 -> 120 / 102 / 306 The previous voxels will be sufficient for a building with the same height everywhere, but the z value is too big to differ in height through the building.","title":"Y dimension"},{"location":"A2_Configuring/a2_configuring_Determiningvoxelsize/#z-dimension","text":"Option Size Ratio Option 1: based on y dimension option 2 and stairs option 4 divisible by 9 126/162/306 divide the z value with 2-> 126/162/153 the staircase will now be 3x2 voxels ratio 1 to 1.3 Option 2: based on y dimension option 3 and stairs option 5 divisible by 6 120/204/102 divide the z value with 3->The staircase will now be 2x3 voxels ratio 1 to 1.7 Option 3: based on y dimension option 3 and stairs option 5 divisible by 6 120/102/306 divide the z value with 3-> the staircase will now be 4x3 ratio 1 to 0,85","title":"Z dimension"},{"location":"A2_Configuring/a2_configuring_Determiningvoxelsize/#definitive-approach","text":"Since a different x and y value affected the modularity of the building and spaces were otherwise forced into one particular direction. We have decided after consultation with our tutors to take the same dimension for the x and y value of the voxel. For the definitive approach towards the voxel size we will use the option for stair dimensions we previously used, since the size was thoroughly thought about in the first approach. Apart from this, as a project group we decided it would be a pragmatic approach to decide our tartan grid based on the thickness of the support structure the building will be made of, to make it fit into the tartan grid. For this, we made a rough estimation of the area of our building through the Program of Requirements, and how this relates to the available area for our building (obtained through measurements in ArcGIS), we came to a rough estimate of 3 stories, if the available area is maximised, in other words: if all the spaces are summed up. Since we have to take into account the varying height in the building, we decided to look at surrounding buildings in the area and the width of the streets and decided upon a maximum of 10 stories high. We estimated that we would need a SHS-HF-300 profile for this height. We chose this profile because it has the same x as y value and based our voxel grid on this. Although these dimensions (300x300) are workable, the size is really small and not really algorithm friendly because the building would consist of too many voxels because of the building site's size. So let\u2019s take the 300x300 voxels as our meso voxels for the tartan grid. If we go back to the stair dimensions which were previously researched and have chosen the following can be said: Rise= 18cm (3x6), 306/18 = 17 steps, tread width= 30cm (5x6), length stairs= 17x30 = 510cm, width staircase= 120cm (20x6) With a stair width of 120cm we could make our voxel size based on 120cm+ meso voxel. But to be on the safe side, and taken into account the railings of the stairs it\u2019s better to take an extra meso voxel for the voxel size. So the voxel size will be 150cm + mesovoxel = 180cm. The tartan grid is the place where the structural profiles or the walls can come.","title":"Definitive approach"},{"location":"A2_Configuring/a2_configuring_Spacecriteria/","text":"Space criteria Table/Matrix of relations The matrix table with connectivity between spaces has been made through the bubble diagram: Program of Requirements with integration of the voxelsize and layers of spaces The following definitive Program of Requirements has been formed through the chosen voxelsize and the given Program of Requirements beforehand.","title":"Space criteria"},{"location":"A2_Configuring/a2_configuring_Spacecriteria/#space-criteria","text":"","title":"Space criteria"},{"location":"A2_Configuring/a2_configuring_Spacecriteria/#tablematrix-of-relations","text":"The matrix table with connectivity between spaces has been made through the bubble diagram:","title":"Table/Matrix of relations"},{"location":"A2_Configuring/a2_configuring_Spacecriteria/#program-of-requirements-with-integration-of-the-voxelsize-and-layers-of-spaces","text":"The following definitive Program of Requirements has been formed through the chosen voxelsize and the given Program of Requirements beforehand.","title":"Program of Requirements with integration of the voxelsize and layers of spaces"},{"location":"A2_Configuring/a2_configuring_Voxelizingthelot/","text":"Voxelizing the lattice As the final voxelsize is determined, the location can be voxelized. The given 'compulsory envelope' is being filled with voxels sized 1.8m * 1.8m * 1.8m, which results in the full lattice. compulsory envelope voxelized envelope Because of the relatively small voxelsize, next to this a second lattice is being generated, with voxelsizes of 15m 15m 15m. This 'low-resolution' lattice could later be used to make the more heavy calculations, and by interpolation of these values a good estimate of the 'high-resolution' voxels is being generated. low-resolution voxelized envelope","title":"Voxelizing the lattice"},{"location":"A2_Configuring/a2_configuring_Voxelizingthelot/#voxelizing-the-lattice","text":"As the final voxelsize is determined, the location can be voxelized. The given 'compulsory envelope' is being filled with voxels sized 1.8m * 1.8m * 1.8m, which results in the full lattice. compulsory envelope voxelized envelope Because of the relatively small voxelsize, next to this a second lattice is being generated, with voxelsizes of 15m 15m 15m. This 'low-resolution' lattice could later be used to make the more heavy calculations, and by interpolation of these values a good estimate of the 'high-resolution' voxels is being generated. low-resolution voxelized envelope","title":"Voxelizing the lattice"},{"location":"A2_Configuring/a2_configuring_product/","text":"Product of configuring Matrix relation table (between spaces) voxelized envelope","title":"Product"},{"location":"A2_Configuring/a2_configuring_product/#product-of-configuring","text":"Matrix relation table (between spaces) voxelized envelope","title":"Product of configuring"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/","text":"Process of massing For generating the building, a concatenation of code is needed. To visualize this, a flowchart is generated visualizing the final configuration process, showing all steps and connections. configuration flowchart This process has four main steps: 1. The calculation of the voxel values 2. The selection of the aailable envelope 3. The placement of all functions in the envelope with the growth model 4. The polygonization of the fa\u00e7ade The first three steps are being explained on this page, whereas the elaboration on the polygonization is written in the massing process page. The order of all explanations will follow the order in the flowchart. Removing voxels To not cause too much shadow or block too much skylight from the context, the voxels that cast too much shadow or block too much skylight from the context, are removed from the envelope based on a threshold. This results in a new envelope without the \u201cbad voxels\u201d Threshold New envelope Quietness To calculate the quietness noise in the building in relation to its context a path with noise points on it is loaded inside a script. Each voxel then calculates the distance from the voxel centroid towards the noise point. These distances are added together and converted into a ratio. This script is actually more about business on street level than about quietness, since it imports noise points and not actual decibels from areas. This does not matter too much, since noise could be filtered from a building by adding more insulation and the relative quietness matters more than the actual numbers in decibels Noise highres(quietness) Entrances and distance lattices to these entrances For this script, a design decision is needed in regards to the placement of the entrances. For this, the following site analysis has been made: As is shown, the accessibility from the city centre is highest on the south and westside of the plot. The main connection with the city centre is the route from the south, via the Luchtsingel and the Hofbogen. To expand the atmosphere of this vivid area, the public functions should have short distance to this place. By placing them across the old metroline along the westside of the plot, the street ambiance will get a new boost, the old metroline can be made in good use and an extension of the vivid street scenery from the city centre is then generated. To make this work, a distance lattice is being made. the distance is calculated from all streetlevel voxels that are along this street. This would attract all functions that care about having a public entrance; fablabs, caf\u00e9 pub restaurant, arcade, shop, co-working spaces and startup office. By not giving them a determined entrance, there stays room for these functions to not only grow towards this set location but it gives them a range of places where they can grow with consideration of other values. As the accessibility from the city centre is also high for the eastside of the building, this could function as a more private, yet highly used entrance side. All communal functions could be located here, as well as the main housing entrances and the gym. For these functions, a few different lattices are generated, as the housing access needs a number of set location on different sides of the building, and the community centre entrance is set next to this housing entrance to have a entrance that brings people together. For the parking entrance, the location that has been chosen is close to the housing entrance, yet it should minimize car traffic in the neighbourhood and is therefore determined on the very east side of the building, close to bigger streets. For each lattice, a distance graph is generated for all voxels within the envelope. To minimize these calculations it is done over a bigger voxelsize. After generating this graph, the specific entrance voxels are selected, and with these voxels of interest a distance lattice is generated. After normalizing, interpolation takes place to translate all values to the actual voxelsize that is being used. distance lattice public entrance distance lattice gym distance lattice parking entrance distance lattice housing entrances distance lattice community centre Improvements To make an even more accurate and generative design, the initial locations of the entrances should not be chosen by hand but determined in a calculation of accessibility of the plot. This would be done by making an extensive model of all surrounding streets: their bustle, their usability for different types of traffic and their potential. This extensive model could not only be used for generating entrances, but also for a noise calculation to value all voxels based on the traffic. This more detailed way of locating an entrance should be implemented during the growth model, so closeness of other entrances would be taken into account for generating the wished for street ambiance greenery For the plot, 30% should be dedicated to becoming a greenspace. The location of this greenspace could be generated in three different ways: By hardcoding where the park should be located, for example based on observations made in the surroundings. By checking which ground level voxels would be most suitable for greenery; checking for sun, noise and daylight, and also closeness to certain functions. By checking which ground level voxels are least useful for generating the building, and removing those from the growth model. The first one is a more classic architectural way of designing, and would therefore not fit in our ambitions to create a generative building. The second option would be very interesting. Only this calculation would be useless if the final form of the building would not be taken into account, so doing this the greenery should be part of the agent based model. Not only this, but the agent based model would need an iteration for the sun- and daylight blockage towards the greenery for every growth step, since the most hinder of sun- and daylight would be generated by buildings that are closest to the greenery, being the generative building itself. Next to that, also the voxel values that are above the selected greenery should be taken into account for each iteration. This because by placing a greenery voxel, all voxels above (or all voxels that do not leave a certain value of day-and sunlight available for the voxel) should be removed from the availability lattice. It would be a waste of good voxels if these voxels are very valuable, whilst the greenery voxel would be almost as satisfied with another voxel. There is need for a balance of value in voxels that are discarded because of the greenspace and voxels that are selected for greenspace. Because of the complexity of this system and the lack of worth if not done well, this is not the method that has been executed. For this design, the last method was chosen, finding the average worth of each voxel and removing all voxels that have a low value. This should be done in a two dimensional way, because the greenery will occupy the full height if it takes the ground level voxel. For each voxel, the multiplication of all values that are associated with that location are being taken. Then this value is being summed for all voxels in the z-direction, creating a two dimensional value for each location. After normalizing this value, it is copied to all z-voxels so if a value is lower than the threshold, all voxels in that z-direction are being removed. By then determining the minimum voxel value that is needed to clear 30% of the location, all values that are lower are being removed and all other voxels are being multiplied with the availability lattice that had been generated based on shadow. This results in the final availability lattice, and in the space dedicated for greenery. Evaluation of the location and the shape of the greenery Because of the many entrances that have been generated at the more accessible side of the plot, the distance values of these voxels are relatively impactful for the average value lattice, leaving a low-valued space at the north of the plot. This directly results in a greenspace that is not as open-oriented, but that is more encapsulated behind the building and oriented towards local users. This fits in with our concept of the greenery, that would be a place for retreat and also a place to have a food garden for the neighbourhood and the communal kitchen. Improvements As has been stated in the decision for this type of greenery selection, a much more complex way of determining the location of the greenery would be possible, but a self-evaluation loop for sun- and daylight would be needed, as well as the implementation of current voxel value evaluation with implementation of the greenery voxel values. This would be very useful, but was not manageable within the given timeframe. Shafts and Corridors The shafts and corridors have been generated in a way that each floor has a network of corridors without any dead ends. As is shown in the depth analysis (a translation of the topological map, with the focus on connections to the street) it can be seen that all public functions have their own entrance, all communal functions are connected to the community centre and all housing functions are connected to the housing entrance. For this corridor generation these two connection-groups are the connections that are being used. Other connections are considered secondary, and are therefore not taken into account. The division in functions (housing entrance and communal entrance) corresponds with the initial location of the functions, where all communal functions are located on the first two floors and the housing functions, along with the co-working spaces and the start-up offices, grow above this. This results in two types of corridor networks; one connecting all communal functions and all shafts to upper floors, and one connecting all functions that grow on the upper floors, along with the shafts. For the growth of the communal corridors, the initial seeds of these functions are being placed. Because the location of the shafts is more related to the location of the entrances than it is to the seeds of the voxels, the shafts are located based on these entrance locations. Instead of using the shafts as connections towards each seed, a list of each function seed is used. The shaft locations are then added to this list, and after generating a distance matrix the shortest path between each function in this list is then calculated. These shortest paths are calculated in a two-dimensional plane, and are then copied to all corresponding levels; voxels 1, 2 and 3 for the groundfloor level and voxels 4 and 5 for the second floor. The same steps are being taken for the higher level functions, but in addition the height of the corridors is limited by the length of the shaft that it is connected to. This because the length of the shaft determines whether or not the floor is accessible. Corridor evaluation Because the corridors are all connected, they limit the abm growth by enclosing voxel seeds and therefore we turned them off in this simulation. The location of the shafts led to the corridors growing along the border of the available voxels, occupying valuable space in the building. The shafts itself are also along the border, but this is a design question that does not have a straightforward answer, as shaft locations differ in each building design. For this situation, a placement along the border had been chosen to minimize walking distance within the building. Improvements The concept of these corridors is useful, but should be generated after the growth of the functions. Then it can find paths along the borders of each function, making sure no function gets limited in their growth. For some functions it might not be a problem if they were to be split up by these corridors and this could be determined in the agent preferences (housing functions, offices). This method would also make sure the most valuable voxels would not be occupied by the corridors, because the voxels that would now be occupied are the voxels that are placed later in the growth model and are therefore less ideal. Right now the corridor grows towards the most valuable voxel, occupying both this voxel and (at least) two of its direct neighbours. For the shafts, a stencil should be used to occupy all voxels that would be occupied when placing a shaft. KPI's to agent criteria The following criteria have been implemented in the agent based simulation: Matrix based relations between spaces (Collectivity) Sun access (Home quality) + (Sustainability) Entrance distance for public, housing, gym, parking and communal spaces (Diversity in audience) The heights of the spaces (Home quality) The desired area requirements per space (Program of requirements) Skyview (Home quality) Greenery (Sustainability) Noise (Home quality) + (Collectivity) + (Sustainability) Configuring spaces to workable values In order to implement the design criteria as mentioned before, those had to be converted to workable values. The values have been written for each space versus the criteria varying from 0 to 1. 0 indicates no connection, 1 indicates a strong connection (Referencing back to the matrix from A1_Configuring). This has been applied for the following criteria: matrix based relations between spaces, sun access, entrance distance for public, housing, gym, parking and communal spaces, skyview, greenery and noise. For the space heights and space areas a different approach had to be made since those are hardcoded criteria coming from the Program of Requirements. Hence, those explained in the next paragraph. Midterm ABM growth simulation Space heights to stencils In order to implement the height differences of spaces given from the Porgram of Requirements into the Apidae method, the initial given stencil for all agents (see left stencil in the picture below) has been expanded in the z axis. In the code, this has been done for 1, 2, 3, 4 and 5 voxels high. The highest stencil is 5 x 1.8m = 9 meters into the z axis and 1.8m on the x and y axis. The picture below shows, in the order of mention, the neighbors for a stencil that is 1.8m high, 3.6m high and 5.4m high. The creation of the new stencils can be created with the following piece of code: In this piece of code new neighbours have been defined for the stencils that need to be higher than 1.8m. For example, s_2 has it's z axis neighbor now set at 2 high. Beware that later in the growth model, the occupation has to be adjusted accordingly. # creating neighborhood definition for stencil that is 1.8m high s_1 = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_1 . set_index ([ 0 , 0 , 0 ], 0 ) ##################################################################### # skipping s_2, s_3, s_4 for this example because it's the same way ##################################################################### # creating neighborhood definition for stencil that is 9m high s_5 = tg . create_stencil ( \"von_neumann\" , 1 , 5 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) s_5 . set_index ([ 0 , 0 , 1 ], 0 ) s_5 . set_index ([ 0 , 0 , 5 ], 1 ) s_5 . set_index ([ 0 , 0 , - 1 ], 0 ) s_5 . set_index ([ 0 , 0 , - 5 ], 1 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) # listing the stencils in order to make them correspond later with the spaces and their height requirement stencils = [ s_1 , s_2 , s_3 , s_4 , s_5 ] Space areas to voxel amounts Based on the program of requirements, the required space sizes have been coverted to amount of necessary voxels to meet the area requirement and therefore fulfil it. This has been implemented in the script to maintain the desirded area per spaces, and has been used to limit the growth of the agents. From the Program of Requirements the room areas can be obtained, and by giving every space a stencil id according to the desired free height (as explained before how the desired height can be implemented) the total amount of voxel necessary for the space to grow towards can be determined. This can be done with the following piece of code: # max voxel count per space (here we do the stencil type + 1 #times the amount of area needed in order to obtain the total amount of voxels that need to be occupied by the script) # pick room area data a_room_vox = agn_prefs [ \"room_area\" ] # pick stencil id's and do +1 because we start with 0 instead of 1 (id 2 would have stencil 3 high otherwise) a_room_stencil = agn_prefs [ \"stencil_id\" ] + 1 # obtain the max amount of voxels needing to be occupied by doing the room area times the height of the space (stencil) a_room_voxels = a_room_stencil * a_room_vox # print in order to check below if you obtain correct values print ( a_room_voxels ) Which gives the following table that can be used later in the growth model: Definitive program table result (input for generative relations simulation) The following table has been made based on the agent/space criterias, this has been used in the definitive script for generating the agent based design. 4 kinds of values are included next to [white] the agent/space names and space id's: [blue] Desire to closeness to given entrance (0 to 1) [yellow] Desire for high values of the given analysis (0 to 1) [green] Necessary data from the program of requirements (imput specific values) [grey] Desire to be close to given agent/space (0 to 1) The given entrances for blue and given analysis for yellow are loaded in as csv files. For the making of those csv files, address their corresponding script. The Generative Relations Simulation After obtaining all the input necessary for the growth model (distance caltulations, solar simulations etc.) it is imporant to be able to make decisions based on that. For this, the script for the Multiple-criteria decision analysis for agents was used and further developed to our needs. With the method explained before, the stencils and area calculations were made. The final ABM (Agent Based Model) growth script can be found here (INSERT LINKKKKKKKKKKKKKKKKKKK)!!!!!!!!!!!!!!!!!!!!!!!!!!!! How it works The ABM (Agent Based Model) growth script runs over a given timeframe. This timeframe is set for it to grow a voxel/stencil per frame. Due to the implementation of stencils with different z axis, the script becomes more efficient (since it covers more voxels per frame). After intiializing the script over a given timeframe, it evaluates for every agent the voxels and stores the values of the free voxels in a list. This list is later used for the evaluation of the voxels. After having made this list, another for loop is initialized. This is the main agent loop, where all free neighbours are retrieved that are accessible. In the meantime the agents are assessed regarding their maximum given z coordinate value and the max area they're allowed to occupy. After all the free neighbours are known, for every agent, if there is a free neighbour is found; it checks the preferences of the agent and evaluates this with the fuzzy framework. When this is done, there are 2 options for the method of occupation: The max area limit has not been reached yet so it picks the highest value neighbouring voxel. Else, it checks if there are better voxels to be occupied (if the given evaluation limit is higher than the agent satisfaction; it departs that bad voxel and occupies the new one. After this is done for all time frames, the new lattice is constructed with the occupation lattice. This is done with stencils that are assigned per agent (for example the housing will use the stencil with an height of 3.6m, this would also occupy 2 (2x1.8)voxels for the agent per frame instead of 1 with the initial stencil). For this particular case the code has been ran through 2500 frames. Occupying with different stencils For making sure the agents with different kinds of stencils corresponding to their height preferences occupy the necessary amount of voxel in the z axis, a variable has been made and used in the occupation function. # making a variable that gives the height of the stencils in voxel (coincidentally +1 since all stencils grow with 1 voxel per id) a_height = a_stencil_id + 1 #checking if there is enough space for it to see it as available # Function for checking the availability (Since it is repeated several times in the main loop) def check_avail ( avail_lattice , ind , a_stencil_id ): condition = 1 ind_array = np . array ( ind ) for step in range ( a_stencil_id + 1 ): new_ind_array = ind_array + np . array ([ 0 , 0 , step ]) condition *= avail_lattice [ tuple ( new_ind_array )] return condition # if its available: # Function for the occupation (and departure but for this piece of demonstration that part isn't important) def mult_occupation ( selected_neigh_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = False ): # Doing this for x times in the z axis with x coming from a_height for step in range ( a_height ): #giving a step to the regular occupation in order to run this for every step in the z aces new_address = selected_neigh_3d_address + np . array ([ 0 , 0 , step ]) # check if there's enough space in the z axis if new_address [ 2 ] < occ_lattice . shape [ 2 ]: # make tuple of the address selected_neigh_3d_id = tuple ( new_address ) # find the location of the newly selected neighbour selected_neigh_loc = np . array ( selected_neigh_3d_id ) . flatten () if departure == False : # add the newly selected neighbour location to agent locations agn_locs [ a_id ] . append ( selected_neigh_loc ) if step == 0 : agn_src_locs [ a_id ] . append ( selected_neigh_loc ) # set the newly selected neighbour as UNavailable (0) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 0 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_neigh_3d_id ] = a_id Housing plan modularity with stencils A highly modular building needs to be adaptable and reusable for different functions over time. The standardised voxels are very suitable for generating this, but more importantly, they give freedom to generate many different housing plans. For the agent based model, an extra layer of information could be added by growing stencil-based for all housing, co-working spaces and start-up offices. Different housing tiles are generated, that together carry all needed functions. For each housing type, a tile library should be made to generate rooms and spaces that fulfil all requirements. These tiles each have markings along the sides, where closed walls, windows, openings to public functions or openings to indoor functions are determined. This way, each house will form based on the markings and their personal library. By generating the housing units like this, all houses will automatically be correctly connected to a corridor, the depth of the building will be limited to the depth of a house and each house will have sufficient daylight and have all their functions available. An extra layer to this would then be the implementation of placement of open and closed facades for each house, coherent with the sun orientation of the building, but also the view. For this the demand of sky visibility and sunlight availability could be calculated for each potential window, which would then also limit the occurrence of two houses growing opposite of each other with minimal free space between them. The concept of these stencil-based growth is visualised in the picture above. The timeframe of this course limited the elaboration on this complex growth model, but thoughts have been put into it. Instead, simpler housing plans are generated. Still based on the voxel-sized plan, but with a standardisation for each housing unit, where there are just a few fixed stencils for each building. This is also not implemented in the growth model due to time limitations. Evaluation The current evaluation part of the code measures if an agent is satisfied with the given evaluation value through the program table. If the agent is not satisfied, it allows the agent to grow towards better voxels, where less valuable voxels are swapped for better ones. If the agent is satisfied, it stays the same and stops growing once it reaches it's max area value. The agent satisfaction has been tracked over the final result (2500 frames). With this data Panda tables have been made and visualized through graphs. This way, the agent satisfaction can be tracked without constantly having to look at the visualization and voxel growth manually. See graphs below for the results. The agent names correspond to their agent id in the program. Evaluation over time for public spaces and entrances: Evaluation over time for Assisted living (11), Student housing (17) and Start-up office (19) Evaluation over time for starter housing (16): Final growth Improvement points Distance calculation and evaluation between spaces: We werent able to implement distance calculations between spaces, so spaces do not pull on each other, in fact they are next to each other only because they have the same preferences. Further development of the evaluation The current evaluation does not take into account whether a specific voxel would've been more valuable for another kind of agent, so it does not assess already occupied voxels by agents other than itself. It only assesses itself. This could be one of the further improvements on the evaluation. Less timeframes (calculations behind) It is better to find a way to do the frames code wise more efficiently since the current one has to be run the amount of voxels the biggest agent is. Which is kind of inefficient since maybe all others are already done halfway. Squareness (conditional neighbour or different stencil) We weren\u2019t able to implement squareness yet due to the time limit. This could have 2 ways: we could set conditions to the neighbours in order to do so or we could make bigger stencils in the x and y axes as cubes but that actually complicates things regarding neighbouring and occupying. Stencil assigning per floor Also we havent yet been able to implement specific stencils only for specific z coordinates, So the public spaces are now 5 z coordinate high stencils instead of one fo 3 that only grows 2 high stencils above itself. Shafts and corridors implementation It is important to combine shafts and corridors, but when we combined those 2, it made the agents get stuck between corridors and not grow further (this happened because we dont want public spaces to grow above a certain height).","title":"Process of massing"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#process-of-massing","text":"For generating the building, a concatenation of code is needed. To visualize this, a flowchart is generated visualizing the final configuration process, showing all steps and connections. configuration flowchart This process has four main steps: 1. The calculation of the voxel values 2. The selection of the aailable envelope 3. The placement of all functions in the envelope with the growth model 4. The polygonization of the fa\u00e7ade The first three steps are being explained on this page, whereas the elaboration on the polygonization is written in the massing process page. The order of all explanations will follow the order in the flowchart.","title":"Process of massing"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#removing-voxels","text":"To not cause too much shadow or block too much skylight from the context, the voxels that cast too much shadow or block too much skylight from the context, are removed from the envelope based on a threshold. This results in a new envelope without the \u201cbad voxels\u201d Threshold New envelope","title":"Removing voxels"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#quietness","text":"To calculate the quietness noise in the building in relation to its context a path with noise points on it is loaded inside a script. Each voxel then calculates the distance from the voxel centroid towards the noise point. These distances are added together and converted into a ratio. This script is actually more about business on street level than about quietness, since it imports noise points and not actual decibels from areas. This does not matter too much, since noise could be filtered from a building by adding more insulation and the relative quietness matters more than the actual numbers in decibels Noise highres(quietness)","title":"Quietness"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#entrances-and-distance-lattices-to-these-entrances","text":"For this script, a design decision is needed in regards to the placement of the entrances. For this, the following site analysis has been made: As is shown, the accessibility from the city centre is highest on the south and westside of the plot. The main connection with the city centre is the route from the south, via the Luchtsingel and the Hofbogen. To expand the atmosphere of this vivid area, the public functions should have short distance to this place. By placing them across the old metroline along the westside of the plot, the street ambiance will get a new boost, the old metroline can be made in good use and an extension of the vivid street scenery from the city centre is then generated. To make this work, a distance lattice is being made. the distance is calculated from all streetlevel voxels that are along this street. This would attract all functions that care about having a public entrance; fablabs, caf\u00e9 pub restaurant, arcade, shop, co-working spaces and startup office. By not giving them a determined entrance, there stays room for these functions to not only grow towards this set location but it gives them a range of places where they can grow with consideration of other values. As the accessibility from the city centre is also high for the eastside of the building, this could function as a more private, yet highly used entrance side. All communal functions could be located here, as well as the main housing entrances and the gym. For these functions, a few different lattices are generated, as the housing access needs a number of set location on different sides of the building, and the community centre entrance is set next to this housing entrance to have a entrance that brings people together. For the parking entrance, the location that has been chosen is close to the housing entrance, yet it should minimize car traffic in the neighbourhood and is therefore determined on the very east side of the building, close to bigger streets. For each lattice, a distance graph is generated for all voxels within the envelope. To minimize these calculations it is done over a bigger voxelsize. After generating this graph, the specific entrance voxels are selected, and with these voxels of interest a distance lattice is generated. After normalizing, interpolation takes place to translate all values to the actual voxelsize that is being used. distance lattice public entrance distance lattice gym distance lattice parking entrance distance lattice housing entrances distance lattice community centre","title":"Entrances and distance lattices to these entrances"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#improvements","text":"To make an even more accurate and generative design, the initial locations of the entrances should not be chosen by hand but determined in a calculation of accessibility of the plot. This would be done by making an extensive model of all surrounding streets: their bustle, their usability for different types of traffic and their potential. This extensive model could not only be used for generating entrances, but also for a noise calculation to value all voxels based on the traffic. This more detailed way of locating an entrance should be implemented during the growth model, so closeness of other entrances would be taken into account for generating the wished for street ambiance","title":"Improvements"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#greenery","text":"For the plot, 30% should be dedicated to becoming a greenspace. The location of this greenspace could be generated in three different ways: By hardcoding where the park should be located, for example based on observations made in the surroundings. By checking which ground level voxels would be most suitable for greenery; checking for sun, noise and daylight, and also closeness to certain functions. By checking which ground level voxels are least useful for generating the building, and removing those from the growth model. The first one is a more classic architectural way of designing, and would therefore not fit in our ambitions to create a generative building. The second option would be very interesting. Only this calculation would be useless if the final form of the building would not be taken into account, so doing this the greenery should be part of the agent based model. Not only this, but the agent based model would need an iteration for the sun- and daylight blockage towards the greenery for every growth step, since the most hinder of sun- and daylight would be generated by buildings that are closest to the greenery, being the generative building itself. Next to that, also the voxel values that are above the selected greenery should be taken into account for each iteration. This because by placing a greenery voxel, all voxels above (or all voxels that do not leave a certain value of day-and sunlight available for the voxel) should be removed from the availability lattice. It would be a waste of good voxels if these voxels are very valuable, whilst the greenery voxel would be almost as satisfied with another voxel. There is need for a balance of value in voxels that are discarded because of the greenspace and voxels that are selected for greenspace. Because of the complexity of this system and the lack of worth if not done well, this is not the method that has been executed. For this design, the last method was chosen, finding the average worth of each voxel and removing all voxels that have a low value. This should be done in a two dimensional way, because the greenery will occupy the full height if it takes the ground level voxel. For each voxel, the multiplication of all values that are associated with that location are being taken. Then this value is being summed for all voxels in the z-direction, creating a two dimensional value for each location. After normalizing this value, it is copied to all z-voxels so if a value is lower than the threshold, all voxels in that z-direction are being removed. By then determining the minimum voxel value that is needed to clear 30% of the location, all values that are lower are being removed and all other voxels are being multiplied with the availability lattice that had been generated based on shadow. This results in the final availability lattice, and in the space dedicated for greenery.","title":"greenery"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#evaluation-of-the-location-and-the-shape-of-the-greenery","text":"Because of the many entrances that have been generated at the more accessible side of the plot, the distance values of these voxels are relatively impactful for the average value lattice, leaving a low-valued space at the north of the plot. This directly results in a greenspace that is not as open-oriented, but that is more encapsulated behind the building and oriented towards local users. This fits in with our concept of the greenery, that would be a place for retreat and also a place to have a food garden for the neighbourhood and the communal kitchen.","title":"Evaluation of the location and the shape of the greenery"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#improvements_1","text":"As has been stated in the decision for this type of greenery selection, a much more complex way of determining the location of the greenery would be possible, but a self-evaluation loop for sun- and daylight would be needed, as well as the implementation of current voxel value evaluation with implementation of the greenery voxel values. This would be very useful, but was not manageable within the given timeframe.","title":"Improvements"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#shafts-and-corridors","text":"The shafts and corridors have been generated in a way that each floor has a network of corridors without any dead ends. As is shown in the depth analysis (a translation of the topological map, with the focus on connections to the street) it can be seen that all public functions have their own entrance, all communal functions are connected to the community centre and all housing functions are connected to the housing entrance. For this corridor generation these two connection-groups are the connections that are being used. Other connections are considered secondary, and are therefore not taken into account. The division in functions (housing entrance and communal entrance) corresponds with the initial location of the functions, where all communal functions are located on the first two floors and the housing functions, along with the co-working spaces and the start-up offices, grow above this. This results in two types of corridor networks; one connecting all communal functions and all shafts to upper floors, and one connecting all functions that grow on the upper floors, along with the shafts. For the growth of the communal corridors, the initial seeds of these functions are being placed. Because the location of the shafts is more related to the location of the entrances than it is to the seeds of the voxels, the shafts are located based on these entrance locations. Instead of using the shafts as connections towards each seed, a list of each function seed is used. The shaft locations are then added to this list, and after generating a distance matrix the shortest path between each function in this list is then calculated. These shortest paths are calculated in a two-dimensional plane, and are then copied to all corresponding levels; voxels 1, 2 and 3 for the groundfloor level and voxels 4 and 5 for the second floor. The same steps are being taken for the higher level functions, but in addition the height of the corridors is limited by the length of the shaft that it is connected to. This because the length of the shaft determines whether or not the floor is accessible.","title":"Shafts and Corridors"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#corridor-evaluation","text":"Because the corridors are all connected, they limit the abm growth by enclosing voxel seeds and therefore we turned them off in this simulation. The location of the shafts led to the corridors growing along the border of the available voxels, occupying valuable space in the building. The shafts itself are also along the border, but this is a design question that does not have a straightforward answer, as shaft locations differ in each building design. For this situation, a placement along the border had been chosen to minimize walking distance within the building.","title":"Corridor evaluation"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#improvements_2","text":"The concept of these corridors is useful, but should be generated after the growth of the functions. Then it can find paths along the borders of each function, making sure no function gets limited in their growth. For some functions it might not be a problem if they were to be split up by these corridors and this could be determined in the agent preferences (housing functions, offices). This method would also make sure the most valuable voxels would not be occupied by the corridors, because the voxels that would now be occupied are the voxels that are placed later in the growth model and are therefore less ideal. Right now the corridor grows towards the most valuable voxel, occupying both this voxel and (at least) two of its direct neighbours. For the shafts, a stencil should be used to occupy all voxels that would be occupied when placing a shaft.","title":"Improvements"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#kpis-to-agent-criteria","text":"The following criteria have been implemented in the agent based simulation: Matrix based relations between spaces (Collectivity) Sun access (Home quality) + (Sustainability) Entrance distance for public, housing, gym, parking and communal spaces (Diversity in audience) The heights of the spaces (Home quality) The desired area requirements per space (Program of requirements) Skyview (Home quality) Greenery (Sustainability) Noise (Home quality) + (Collectivity) + (Sustainability)","title":"KPI's to agent criteria"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#configuring-spaces-to-workable-values","text":"In order to implement the design criteria as mentioned before, those had to be converted to workable values. The values have been written for each space versus the criteria varying from 0 to 1. 0 indicates no connection, 1 indicates a strong connection (Referencing back to the matrix from A1_Configuring). This has been applied for the following criteria: matrix based relations between spaces, sun access, entrance distance for public, housing, gym, parking and communal spaces, skyview, greenery and noise. For the space heights and space areas a different approach had to be made since those are hardcoded criteria coming from the Program of Requirements. Hence, those explained in the next paragraph. Midterm ABM growth simulation","title":"Configuring spaces to workable values"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#space-heights-to-stencils","text":"In order to implement the height differences of spaces given from the Porgram of Requirements into the Apidae method, the initial given stencil for all agents (see left stencil in the picture below) has been expanded in the z axis. In the code, this has been done for 1, 2, 3, 4 and 5 voxels high. The highest stencil is 5 x 1.8m = 9 meters into the z axis and 1.8m on the x and y axis. The picture below shows, in the order of mention, the neighbors for a stencil that is 1.8m high, 3.6m high and 5.4m high. The creation of the new stencils can be created with the following piece of code: In this piece of code new neighbours have been defined for the stencils that need to be higher than 1.8m. For example, s_2 has it's z axis neighbor now set at 2 high. Beware that later in the growth model, the occupation has to be adjusted accordingly. # creating neighborhood definition for stencil that is 1.8m high s_1 = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_1 . set_index ([ 0 , 0 , 0 ], 0 ) ##################################################################### # skipping s_2, s_3, s_4 for this example because it's the same way ##################################################################### # creating neighborhood definition for stencil that is 9m high s_5 = tg . create_stencil ( \"von_neumann\" , 1 , 5 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) s_5 . set_index ([ 0 , 0 , 1 ], 0 ) s_5 . set_index ([ 0 , 0 , 5 ], 1 ) s_5 . set_index ([ 0 , 0 , - 1 ], 0 ) s_5 . set_index ([ 0 , 0 , - 5 ], 1 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) # listing the stencils in order to make them correspond later with the spaces and their height requirement stencils = [ s_1 , s_2 , s_3 , s_4 , s_5 ]","title":"Space heights to stencils"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#space-areas-to-voxel-amounts","text":"Based on the program of requirements, the required space sizes have been coverted to amount of necessary voxels to meet the area requirement and therefore fulfil it. This has been implemented in the script to maintain the desirded area per spaces, and has been used to limit the growth of the agents. From the Program of Requirements the room areas can be obtained, and by giving every space a stencil id according to the desired free height (as explained before how the desired height can be implemented) the total amount of voxel necessary for the space to grow towards can be determined. This can be done with the following piece of code: # max voxel count per space (here we do the stencil type + 1 #times the amount of area needed in order to obtain the total amount of voxels that need to be occupied by the script) # pick room area data a_room_vox = agn_prefs [ \"room_area\" ] # pick stencil id's and do +1 because we start with 0 instead of 1 (id 2 would have stencil 3 high otherwise) a_room_stencil = agn_prefs [ \"stencil_id\" ] + 1 # obtain the max amount of voxels needing to be occupied by doing the room area times the height of the space (stencil) a_room_voxels = a_room_stencil * a_room_vox # print in order to check below if you obtain correct values print ( a_room_voxels ) Which gives the following table that can be used later in the growth model:","title":"Space areas to voxel amounts"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#definitive-program-table-result-input-for-generative-relations-simulation","text":"The following table has been made based on the agent/space criterias, this has been used in the definitive script for generating the agent based design. 4 kinds of values are included next to [white] the agent/space names and space id's: [blue] Desire to closeness to given entrance (0 to 1) [yellow] Desire for high values of the given analysis (0 to 1) [green] Necessary data from the program of requirements (imput specific values) [grey] Desire to be close to given agent/space (0 to 1) The given entrances for blue and given analysis for yellow are loaded in as csv files. For the making of those csv files, address their corresponding script.","title":"Definitive program table result (input for generative relations simulation)"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#the-generative-relations-simulation","text":"After obtaining all the input necessary for the growth model (distance caltulations, solar simulations etc.) it is imporant to be able to make decisions based on that. For this, the script for the Multiple-criteria decision analysis for agents was used and further developed to our needs. With the method explained before, the stencils and area calculations were made. The final ABM (Agent Based Model) growth script can be found here (INSERT LINKKKKKKKKKKKKKKKKKKK)!!!!!!!!!!!!!!!!!!!!!!!!!!!!","title":"The Generative Relations Simulation"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#how-it-works","text":"The ABM (Agent Based Model) growth script runs over a given timeframe. This timeframe is set for it to grow a voxel/stencil per frame. Due to the implementation of stencils with different z axis, the script becomes more efficient (since it covers more voxels per frame). After intiializing the script over a given timeframe, it evaluates for every agent the voxels and stores the values of the free voxels in a list. This list is later used for the evaluation of the voxels. After having made this list, another for loop is initialized. This is the main agent loop, where all free neighbours are retrieved that are accessible. In the meantime the agents are assessed regarding their maximum given z coordinate value and the max area they're allowed to occupy. After all the free neighbours are known, for every agent, if there is a free neighbour is found; it checks the preferences of the agent and evaluates this with the fuzzy framework. When this is done, there are 2 options for the method of occupation: The max area limit has not been reached yet so it picks the highest value neighbouring voxel. Else, it checks if there are better voxels to be occupied (if the given evaluation limit is higher than the agent satisfaction; it departs that bad voxel and occupies the new one. After this is done for all time frames, the new lattice is constructed with the occupation lattice. This is done with stencils that are assigned per agent (for example the housing will use the stencil with an height of 3.6m, this would also occupy 2 (2x1.8)voxels for the agent per frame instead of 1 with the initial stencil). For this particular case the code has been ran through 2500 frames.","title":"How it works"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#occupying-with-different-stencils","text":"For making sure the agents with different kinds of stencils corresponding to their height preferences occupy the necessary amount of voxel in the z axis, a variable has been made and used in the occupation function. # making a variable that gives the height of the stencils in voxel (coincidentally +1 since all stencils grow with 1 voxel per id) a_height = a_stencil_id + 1 #checking if there is enough space for it to see it as available # Function for checking the availability (Since it is repeated several times in the main loop) def check_avail ( avail_lattice , ind , a_stencil_id ): condition = 1 ind_array = np . array ( ind ) for step in range ( a_stencil_id + 1 ): new_ind_array = ind_array + np . array ([ 0 , 0 , step ]) condition *= avail_lattice [ tuple ( new_ind_array )] return condition # if its available: # Function for the occupation (and departure but for this piece of demonstration that part isn't important) def mult_occupation ( selected_neigh_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = False ): # Doing this for x times in the z axis with x coming from a_height for step in range ( a_height ): #giving a step to the regular occupation in order to run this for every step in the z aces new_address = selected_neigh_3d_address + np . array ([ 0 , 0 , step ]) # check if there's enough space in the z axis if new_address [ 2 ] < occ_lattice . shape [ 2 ]: # make tuple of the address selected_neigh_3d_id = tuple ( new_address ) # find the location of the newly selected neighbour selected_neigh_loc = np . array ( selected_neigh_3d_id ) . flatten () if departure == False : # add the newly selected neighbour location to agent locations agn_locs [ a_id ] . append ( selected_neigh_loc ) if step == 0 : agn_src_locs [ a_id ] . append ( selected_neigh_loc ) # set the newly selected neighbour as UNavailable (0) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 0 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_neigh_3d_id ] = a_id","title":"Occupying with different stencils"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#housing-plan-modularity-with-stencils","text":"A highly modular building needs to be adaptable and reusable for different functions over time. The standardised voxels are very suitable for generating this, but more importantly, they give freedom to generate many different housing plans. For the agent based model, an extra layer of information could be added by growing stencil-based for all housing, co-working spaces and start-up offices. Different housing tiles are generated, that together carry all needed functions. For each housing type, a tile library should be made to generate rooms and spaces that fulfil all requirements. These tiles each have markings along the sides, where closed walls, windows, openings to public functions or openings to indoor functions are determined. This way, each house will form based on the markings and their personal library. By generating the housing units like this, all houses will automatically be correctly connected to a corridor, the depth of the building will be limited to the depth of a house and each house will have sufficient daylight and have all their functions available. An extra layer to this would then be the implementation of placement of open and closed facades for each house, coherent with the sun orientation of the building, but also the view. For this the demand of sky visibility and sunlight availability could be calculated for each potential window, which would then also limit the occurrence of two houses growing opposite of each other with minimal free space between them. The concept of these stencil-based growth is visualised in the picture above. The timeframe of this course limited the elaboration on this complex growth model, but thoughts have been put into it. Instead, simpler housing plans are generated. Still based on the voxel-sized plan, but with a standardisation for each housing unit, where there are just a few fixed stencils for each building. This is also not implemented in the growth model due to time limitations.","title":"Housing plan modularity with stencils"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#evaluation","text":"The current evaluation part of the code measures if an agent is satisfied with the given evaluation value through the program table. If the agent is not satisfied, it allows the agent to grow towards better voxels, where less valuable voxels are swapped for better ones. If the agent is satisfied, it stays the same and stops growing once it reaches it's max area value. The agent satisfaction has been tracked over the final result (2500 frames). With this data Panda tables have been made and visualized through graphs. This way, the agent satisfaction can be tracked without constantly having to look at the visualization and voxel growth manually. See graphs below for the results. The agent names correspond to their agent id in the program. Evaluation over time for public spaces and entrances: Evaluation over time for Assisted living (11), Student housing (17) and Start-up office (19) Evaluation over time for starter housing (16):","title":"Evaluation"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#final-growth","text":"","title":"Final growth"},{"location":"A3_Massing/%5BNOT%20USED%5D%20a3_massing_process/#improvement-points","text":"Distance calculation and evaluation between spaces: We werent able to implement distance calculations between spaces, so spaces do not pull on each other, in fact they are next to each other only because they have the same preferences. Further development of the evaluation The current evaluation does not take into account whether a specific voxel would've been more valuable for another kind of agent, so it does not assess already occupied voxels by agents other than itself. It only assesses itself. This could be one of the further improvements on the evaluation. Less timeframes (calculations behind) It is better to find a way to do the frames code wise more efficiently since the current one has to be run the amount of voxels the biggest agent is. Which is kind of inefficient since maybe all others are already done halfway. Squareness (conditional neighbour or different stencil) We weren\u2019t able to implement squareness yet due to the time limit. This could have 2 ways: we could set conditions to the neighbours in order to do so or we could make bigger stencils in the x and y axes as cubes but that actually complicates things regarding neighbouring and occupying. Stencil assigning per floor Also we havent yet been able to implement specific stencils only for specific z coordinates, So the public spaces are now 5 z coordinate high stencils instead of one fo 3 that only grows 2 high stencils above itself. Shafts and corridors implementation It is important to combine shafts and corridors, but when we combined those 2, it made the agents get stuck between corridors and not grow further (this happened because we dont want public spaces to grow above a certain height).","title":"Improvement points"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/","text":"Agent Based Model KPI's to agent criteria The following criteria have been implemented in the agent based simulation: Matrix based relations between spaces (Collectivity) Sun access (Home quality) + (Sustainability) Entrance distance for public, housing, gym, parking and communal spaces (Diversity in audience) The heights of the spaces (Home quality) The desired area requirements per space (Program of requirements) Skyview (Home quality) Greenery (Sustainability) Noise (Home quality) + (Collectivity) + (Sustainability) Configuring spaces to workable values In order to implement the design criteria as mentioned before, those had to be converted to workable values. The values have been written for each space versus the criteria varying from 0 to 1. 0 indicates no connection, 1 indicates a strong connection (Referencing back to the matrix from A1_Configuring). This has been applied for the following criteria: matrix based relations between spaces, sun access, entrance distance for public, housing, gym, parking and communal spaces, skyview, greenery and noise. For the space heights and space areas a different approach had to be made since those are hardcoded criteria coming from the Program of Requirements. Hence, those explained in the next paragraph. Midterm ABM growth simulation Space heights to stencils In order to implement the height differences of spaces given from the Porgram of Requirements into the Apidae method, the initial given stencil for all agents (see left stencil in the picture below) has been expanded in the z axis. In the code, this has been done for 1, 2, 3, 4 and 5 voxels high. The highest stencil is 5 x 1.8m = 9 meters into the z axis and 1.8m on the x and y axis. The picture below shows, in the order of mention, the neighbors for a stencil that is 1.8m high, 3.6m high and 5.4m high. height stencils The creation of the new stencils can be created with the following piece of code: In this piece of code new neighbours have been defined for the stencils that need to be higher than 1.8m. For example, s_2 has it's z axis neighbor now set at 2 high. Beware that later in the growth model, the occupation has to be adjusted accordingly. # creating neighborhood definition for stencil that is 1.8m high s_1 = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_1 . set_index ([ 0 , 0 , 0 ], 0 ) ##################################################################### # skipping s_2, s_3, s_4 for this example because it's the same way ##################################################################### # creating neighborhood definition for stencil that is 9m high s_5 = tg . create_stencil ( \"von_neumann\" , 1 , 5 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) s_5 . set_index ([ 0 , 0 , 1 ], 0 ) s_5 . set_index ([ 0 , 0 , 5 ], 1 ) s_5 . set_index ([ 0 , 0 , - 1 ], 0 ) s_5 . set_index ([ 0 , 0 , - 5 ], 1 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) # listing the stencils in order to make them correspond later with the spaces and their height requirement stencils = [ s_1 , s_2 , s_3 , s_4 , s_5 ] Space areas to voxel amounts Based on the program of requirements, the required space sizes have been coverted to amount of necessary voxels to meet the area requirement and therefore fulfil it. This has been implemented in the script to maintain the desirded area per spaces, and has been used to limit the growth of the agents. From the Program of Requirements the room areas can be obtained, and by giving every space a stencil id according to the desired free height (as explained before how the desired height can be implemented) the total amount of voxel necessary for the space to grow towards can be determined. This can be done with the following piece of code: # max voxel count per space (here we do the stencil type + 1 #times the amount of area needed in order to obtain the total amount of voxels that need to be occupied by the script) # pick room area data a_room_vox = agn_prefs [ \"room_area\" ] # pick stencil id's and do +1 because we start with 0 instead of 1 (id 2 would have stencil 3 high otherwise) a_room_stencil = agn_prefs [ \"stencil_id\" ] + 1 # obtain the max amount of voxels needing to be occupied by doing the room area times the height of the space (stencil) a_room_voxels = a_room_stencil * a_room_vox # print in order to check below if you obtain correct values print ( a_room_voxels ) Which gives the following table that can be used later in the growth model: Definitive program table result (input for generative relations simulation) The following table has been made based on the agent/space criterias, this has been used in the definitive script for generating the agent based design. 4 kinds of values are included next to [white] the agent/space names and space id's: [blue] Desire to closeness to given entrance (0 to 1) [yellow] Desire for high values of the given analysis (0 to 1) [green] Necessary data from the program of requirements (imput specific values) [grey] Desire to be close to given agent/space (0 to 1) The given entrances for blue and given analysis for yellow are loaded in as csv files. For the making of those csv files, address their corresponding script. Housing plan modularity with stencils A highly modular building needs to be adaptable and reusable for different functions over time. The standardised voxels are very suitable for generating this, but more importantly, they give freedom to generate many different housing plans. For the agent based model, an extra layer of information could be added by growing stencil-based for all housing, co-working spaces and start-up offices. Different housing tiles are generated, that together carry all needed functions. For each housing type, a tile library should be made to generate rooms and spaces that fulfil all requirements. These tiles each have markings along the sides, where closed walls, windows, openings to public functions or openings to indoor functions are determined. This way, each house will form based on the markings and their personal library. By generating the housing units like this, all houses will automatically be correctly connected to a corridor, the depth of the building will be limited to the depth of a house and each house will have sufficient daylight and have all their functions available. An extra layer to this would then be the implementation of placement of open and closed facades for each house, coherent with the sun orientation of the building, but also the view. For this the demand of sky visibility and sunlight availability could be calculated for each potential window, which would then also limit the occurrence of two houses growing opposite of each other with minimal free space between them. function stencil concepts: student housing and corridor conceptual configuration of the growth of housing units The concept of these stencil-based growth is visualised in the picture above. The timeframe of this course limited the elaboration on this complex growth model, but thoughts have been put into it. simplified housing plan stencils Instead, simpler housing plans are generated. Still based on the voxel-sized plan, but with a standardisation for each housing unit, where there are just a few fixed stencils for each building. This is also not implemented in the growth model due to time limitations. The Generative Relations Simulation After obtaining all the input necessary for the growth model (distance caltulations, solar simulations etc.) it is imporant to be able to make decisions based on that. For this, the script for the Multiple-criteria decision analysis for agents was used and further developed to our needs. With the method explained before, the stencils and area calculations were made. The final ABM (Agent Based Model) growth script can be found here . How it works The ABM (Agent Based Model) growth script runs over a given timeframe. This timeframe is set for it to grow a voxel/stencil per frame. Due to the implementation of stencils with different z axis, the script becomes more efficient (since it covers more voxels per frame). After intiializing the script over a given timeframe, it evaluates for every agent the voxels and stores the values of the free voxels in a list. This list is later used for the evaluation of the voxels. After having made this list, another for loop is initialized. This is the main agent loop, where all free neighbours are retrieved that are accessible. In the meantime the agents are assessed regarding their maximum given z coordinate value and the max area they're allowed to occupy. After all the free neighbours are known, for every agent, if there is a free neighbour is found; it checks the preferences of the agent and evaluates this with the fuzzy framework. When this is done, there are 2 options for the method of occupation: The max area limit has not been reached yet so it picks the highest value neighbouring voxel. Else, it checks if there are better voxels to be occupied (if the given evaluation limit is higher than the agent satisfaction; it departs that bad voxel and occupies the new one. After this is done for all time frames, the new lattice is constructed with the occupation lattice. This is done with stencils that are assigned per agent (for example the housing will use the stencil with an height of 3.6m, this would also occupy 2 (2x1.8)voxels for the agent per frame instead of 1 with the initial stencil). For this particular case the code has been ran through 2500 frames. Occupying with different stencils For making sure the agents with different kinds of stencils corresponding to their height preferences occupy the necessary amount of voxel in the z axis, a variable has been made and used in the occupation function. # making a variable that gives the height of the stencils in voxel (coincidentally +1 since all stencils grow with 1 voxel per id) a_height = a_stencil_id + 1 #checking if there is enough space for it to see it as available # Function for checking the availability (Since it is repeated several times in the main loop) def check_avail ( avail_lattice , ind , a_stencil_id ): condition = 1 ind_array = np . array ( ind ) for step in range ( a_stencil_id + 1 ): new_ind_array = ind_array + np . array ([ 0 , 0 , step ]) condition *= avail_lattice [ tuple ( new_ind_array )] return condition # if its available: # Function for the occupation (and departure but for this piece of demonstration that part isn't important) def mult_occupation ( selected_neigh_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = False ): # Doing this for x times in the z axis with x coming from a_height for step in range ( a_height ): #giving a step to the regular occupation in order to run this for every step in the z aces new_address = selected_neigh_3d_address + np . array ([ 0 , 0 , step ]) # check if there's enough space in the z axis if new_address [ 2 ] < occ_lattice . shape [ 2 ]: # make tuple of the address selected_neigh_3d_id = tuple ( new_address ) # find the location of the newly selected neighbour selected_neigh_loc = np . array ( selected_neigh_3d_id ) . flatten () if departure == False : # add the newly selected neighbour location to agent locations agn_locs [ a_id ] . append ( selected_neigh_loc ) if step == 0 : agn_src_locs [ a_id ] . append ( selected_neigh_loc ) # set the newly selected neighbour as UNavailable (0) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 0 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_neigh_3d_id ] = a_id Evaluation The current evaluation part of the code measures if an agent is satisfied with the given evaluation value through the program table. If the agent is not satisfied, it allows the agent to grow towards better voxels, where less valuable voxels are swapped for better ones. If the agent is satisfied, it stays the same and stops growing once it reaches it's max area value. The agent satisfaction has been tracked over the final result (2500 frames). With this data Panda tables have been made and visualized through graphs. This way, the agent satisfaction can be tracked without constantly having to look at the visualization and voxel growth manually. See graphs below for the results. The agent names correspond to their agent id in the program. Evaluation over time for public spaces and entrances: Evaluation over time for Assisted living (11), Student housing (17) and Start-up office (19) Evaluation over time for starter housing (16): Final growth Improvement points Distance calculation and evaluation between spaces: We werent able to implement distance calculations between spaces, so spaces do not pull on each other, in fact they are next to each other only because they have the same preferences. Further development of the evaluation The current evaluation does not take into account whether a specific voxel would've been more valuable for another kind of agent, so it does not assess already occupied voxels by agents other than itself. It only assesses itself. This could be one of the further improvements on the evaluation. Less timeframes (calculations behind) It is better to find a way to do the frames code wise more efficiently since the current one has to be run the amount of voxels the biggest agent is. Which is kind of inefficient since maybe all others are already done halfway. Squareness (conditional neighbour or different stencil) We weren\u2019t able to implement squareness yet due to the time limit. This could have 2 ways: we could set conditions to the neighbours in order to do so or we could make bigger stencils in the x and y axes as cubes but that actually complicates things regarding neighbouring and occupying. Stencil assigning per floor Also we havent yet been able to implement specific stencils only for specific z coordinates, So the public spaces are now 5 z coordinate high stencils instead of one fo 3 that only grows 2 high stencils above itself. Shafts and corridors implementation It is important to combine shafts and corridors, but when we combined those 2, it made the agents get stuck between corridors and not grow further (this happened because we dont want public spaces to grow above a certain height).","title":"ABM Growth"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#agent-based-model","text":"","title":"Agent Based Model"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#kpis-to-agent-criteria","text":"The following criteria have been implemented in the agent based simulation: Matrix based relations between spaces (Collectivity) Sun access (Home quality) + (Sustainability) Entrance distance for public, housing, gym, parking and communal spaces (Diversity in audience) The heights of the spaces (Home quality) The desired area requirements per space (Program of requirements) Skyview (Home quality) Greenery (Sustainability) Noise (Home quality) + (Collectivity) + (Sustainability)","title":"KPI's to agent criteria"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#configuring-spaces-to-workable-values","text":"In order to implement the design criteria as mentioned before, those had to be converted to workable values. The values have been written for each space versus the criteria varying from 0 to 1. 0 indicates no connection, 1 indicates a strong connection (Referencing back to the matrix from A1_Configuring). This has been applied for the following criteria: matrix based relations between spaces, sun access, entrance distance for public, housing, gym, parking and communal spaces, skyview, greenery and noise. For the space heights and space areas a different approach had to be made since those are hardcoded criteria coming from the Program of Requirements. Hence, those explained in the next paragraph. Midterm ABM growth simulation","title":"Configuring spaces to workable values"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#space-heights-to-stencils","text":"In order to implement the height differences of spaces given from the Porgram of Requirements into the Apidae method, the initial given stencil for all agents (see left stencil in the picture below) has been expanded in the z axis. In the code, this has been done for 1, 2, 3, 4 and 5 voxels high. The highest stencil is 5 x 1.8m = 9 meters into the z axis and 1.8m on the x and y axis. The picture below shows, in the order of mention, the neighbors for a stencil that is 1.8m high, 3.6m high and 5.4m high. height stencils The creation of the new stencils can be created with the following piece of code: In this piece of code new neighbours have been defined for the stencils that need to be higher than 1.8m. For example, s_2 has it's z axis neighbor now set at 2 high. Beware that later in the growth model, the occupation has to be adjusted accordingly. # creating neighborhood definition for stencil that is 1.8m high s_1 = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_1 . set_index ([ 0 , 0 , 0 ], 0 ) ##################################################################### # skipping s_2, s_3, s_4 for this example because it's the same way ##################################################################### # creating neighborhood definition for stencil that is 9m high s_5 = tg . create_stencil ( \"von_neumann\" , 1 , 5 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) s_5 . set_index ([ 0 , 0 , 1 ], 0 ) s_5 . set_index ([ 0 , 0 , 5 ], 1 ) s_5 . set_index ([ 0 , 0 , - 1 ], 0 ) s_5 . set_index ([ 0 , 0 , - 5 ], 1 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) # listing the stencils in order to make them correspond later with the spaces and their height requirement stencils = [ s_1 , s_2 , s_3 , s_4 , s_5 ]","title":"Space heights to stencils"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#space-areas-to-voxel-amounts","text":"Based on the program of requirements, the required space sizes have been coverted to amount of necessary voxels to meet the area requirement and therefore fulfil it. This has been implemented in the script to maintain the desirded area per spaces, and has been used to limit the growth of the agents. From the Program of Requirements the room areas can be obtained, and by giving every space a stencil id according to the desired free height (as explained before how the desired height can be implemented) the total amount of voxel necessary for the space to grow towards can be determined. This can be done with the following piece of code: # max voxel count per space (here we do the stencil type + 1 #times the amount of area needed in order to obtain the total amount of voxels that need to be occupied by the script) # pick room area data a_room_vox = agn_prefs [ \"room_area\" ] # pick stencil id's and do +1 because we start with 0 instead of 1 (id 2 would have stencil 3 high otherwise) a_room_stencil = agn_prefs [ \"stencil_id\" ] + 1 # obtain the max amount of voxels needing to be occupied by doing the room area times the height of the space (stencil) a_room_voxels = a_room_stencil * a_room_vox # print in order to check below if you obtain correct values print ( a_room_voxels ) Which gives the following table that can be used later in the growth model:","title":"Space areas to voxel amounts"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#definitive-program-table-result-input-for-generative-relations-simulation","text":"The following table has been made based on the agent/space criterias, this has been used in the definitive script for generating the agent based design. 4 kinds of values are included next to [white] the agent/space names and space id's: [blue] Desire to closeness to given entrance (0 to 1) [yellow] Desire for high values of the given analysis (0 to 1) [green] Necessary data from the program of requirements (imput specific values) [grey] Desire to be close to given agent/space (0 to 1) The given entrances for blue and given analysis for yellow are loaded in as csv files. For the making of those csv files, address their corresponding script.","title":"Definitive program table result (input for generative relations simulation)"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#housing-plan-modularity-with-stencils","text":"A highly modular building needs to be adaptable and reusable for different functions over time. The standardised voxels are very suitable for generating this, but more importantly, they give freedom to generate many different housing plans. For the agent based model, an extra layer of information could be added by growing stencil-based for all housing, co-working spaces and start-up offices. Different housing tiles are generated, that together carry all needed functions. For each housing type, a tile library should be made to generate rooms and spaces that fulfil all requirements. These tiles each have markings along the sides, where closed walls, windows, openings to public functions or openings to indoor functions are determined. This way, each house will form based on the markings and their personal library. By generating the housing units like this, all houses will automatically be correctly connected to a corridor, the depth of the building will be limited to the depth of a house and each house will have sufficient daylight and have all their functions available. An extra layer to this would then be the implementation of placement of open and closed facades for each house, coherent with the sun orientation of the building, but also the view. For this the demand of sky visibility and sunlight availability could be calculated for each potential window, which would then also limit the occurrence of two houses growing opposite of each other with minimal free space between them. function stencil concepts: student housing and corridor conceptual configuration of the growth of housing units The concept of these stencil-based growth is visualised in the picture above. The timeframe of this course limited the elaboration on this complex growth model, but thoughts have been put into it. simplified housing plan stencils Instead, simpler housing plans are generated. Still based on the voxel-sized plan, but with a standardisation for each housing unit, where there are just a few fixed stencils for each building. This is also not implemented in the growth model due to time limitations.","title":"Housing plan modularity with stencils"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#the-generative-relations-simulation","text":"After obtaining all the input necessary for the growth model (distance caltulations, solar simulations etc.) it is imporant to be able to make decisions based on that. For this, the script for the Multiple-criteria decision analysis for agents was used and further developed to our needs. With the method explained before, the stencils and area calculations were made. The final ABM (Agent Based Model) growth script can be found here .","title":"The Generative Relations Simulation"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#how-it-works","text":"The ABM (Agent Based Model) growth script runs over a given timeframe. This timeframe is set for it to grow a voxel/stencil per frame. Due to the implementation of stencils with different z axis, the script becomes more efficient (since it covers more voxels per frame). After intiializing the script over a given timeframe, it evaluates for every agent the voxels and stores the values of the free voxels in a list. This list is later used for the evaluation of the voxels. After having made this list, another for loop is initialized. This is the main agent loop, where all free neighbours are retrieved that are accessible. In the meantime the agents are assessed regarding their maximum given z coordinate value and the max area they're allowed to occupy. After all the free neighbours are known, for every agent, if there is a free neighbour is found; it checks the preferences of the agent and evaluates this with the fuzzy framework. When this is done, there are 2 options for the method of occupation: The max area limit has not been reached yet so it picks the highest value neighbouring voxel. Else, it checks if there are better voxels to be occupied (if the given evaluation limit is higher than the agent satisfaction; it departs that bad voxel and occupies the new one. After this is done for all time frames, the new lattice is constructed with the occupation lattice. This is done with stencils that are assigned per agent (for example the housing will use the stencil with an height of 3.6m, this would also occupy 2 (2x1.8)voxels for the agent per frame instead of 1 with the initial stencil). For this particular case the code has been ran through 2500 frames.","title":"How it works"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#occupying-with-different-stencils","text":"For making sure the agents with different kinds of stencils corresponding to their height preferences occupy the necessary amount of voxel in the z axis, a variable has been made and used in the occupation function. # making a variable that gives the height of the stencils in voxel (coincidentally +1 since all stencils grow with 1 voxel per id) a_height = a_stencil_id + 1 #checking if there is enough space for it to see it as available # Function for checking the availability (Since it is repeated several times in the main loop) def check_avail ( avail_lattice , ind , a_stencil_id ): condition = 1 ind_array = np . array ( ind ) for step in range ( a_stencil_id + 1 ): new_ind_array = ind_array + np . array ([ 0 , 0 , step ]) condition *= avail_lattice [ tuple ( new_ind_array )] return condition # if its available: # Function for the occupation (and departure but for this piece of demonstration that part isn't important) def mult_occupation ( selected_neigh_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = False ): # Doing this for x times in the z axis with x coming from a_height for step in range ( a_height ): #giving a step to the regular occupation in order to run this for every step in the z aces new_address = selected_neigh_3d_address + np . array ([ 0 , 0 , step ]) # check if there's enough space in the z axis if new_address [ 2 ] < occ_lattice . shape [ 2 ]: # make tuple of the address selected_neigh_3d_id = tuple ( new_address ) # find the location of the newly selected neighbour selected_neigh_loc = np . array ( selected_neigh_3d_id ) . flatten () if departure == False : # add the newly selected neighbour location to agent locations agn_locs [ a_id ] . append ( selected_neigh_loc ) if step == 0 : agn_src_locs [ a_id ] . append ( selected_neigh_loc ) # set the newly selected neighbour as UNavailable (0) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 0 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_neigh_3d_id ] = a_id","title":"Occupying with different stencils"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#evaluation","text":"The current evaluation part of the code measures if an agent is satisfied with the given evaluation value through the program table. If the agent is not satisfied, it allows the agent to grow towards better voxels, where less valuable voxels are swapped for better ones. If the agent is satisfied, it stays the same and stops growing once it reaches it's max area value. The agent satisfaction has been tracked over the final result (2500 frames). With this data Panda tables have been made and visualized through graphs. This way, the agent satisfaction can be tracked without constantly having to look at the visualization and voxel growth manually. See graphs below for the results. The agent names correspond to their agent id in the program. Evaluation over time for public spaces and entrances: Evaluation over time for Assisted living (11), Student housing (17) and Start-up office (19) Evaluation over time for starter housing (16):","title":"Evaluation"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#final-growth","text":"","title":"Final growth"},{"location":"A3_Massing/a3_configuring_ABM_Simulation/#improvement-points","text":"Distance calculation and evaluation between spaces: We werent able to implement distance calculations between spaces, so spaces do not pull on each other, in fact they are next to each other only because they have the same preferences. Further development of the evaluation The current evaluation does not take into account whether a specific voxel would've been more valuable for another kind of agent, so it does not assess already occupied voxels by agents other than itself. It only assesses itself. This could be one of the further improvements on the evaluation. Less timeframes (calculations behind) It is better to find a way to do the frames code wise more efficiently since the current one has to be run the amount of voxels the biggest agent is. Which is kind of inefficient since maybe all others are already done halfway. Squareness (conditional neighbour or different stencil) We weren\u2019t able to implement squareness yet due to the time limit. This could have 2 ways: we could set conditions to the neighbours in order to do so or we could make bigger stencils in the x and y axes as cubes but that actually complicates things regarding neighbouring and occupying. Stencil assigning per floor Also we havent yet been able to implement specific stencils only for specific z coordinates, So the public spaces are now 5 z coordinate high stencils instead of one fo 3 that only grows 2 high stencils above itself. Shafts and corridors implementation It is important to combine shafts and corridors, but when we combined those 2, it made the agents get stuck between corridors and not grow further (this happened because we dont want public spaces to grow above a certain height).","title":"Improvement points"},{"location":"A3_Massing/a3_configuring_Designing_The_Lattice/","text":"designing the growth lattice For generating the final building, not all voxels are appropriate to use. In this simulation, the growth lattice is being limited by two factors. With generating the building the surroundings are taken into account, and decided is that the building may not cast too much shadow to buildings in the surrounding. Next to that, a limit on the used ground floor space is asked, as 30% of the plot should be reserved for greenery. Sun and Skylight Based on the ladybug sunpath the shadow envelope is calculated. To do so a ray is cast from the centroids of all the voxel that have received sun, towards the context. If the ray does not intersect the context, then the voxel does not cast a shadow. The shadow envelope is then interpolated to a highres value. For Skylight blocking all these steps are repeated, but instead of loading a sunpath, a sphere is created to represent the sky. Instead of shooting rays towards the sunpoints, the rays are being shot to the skypoints. method of skylight and sun blocking Fundamentally our building should be of least disturbance for the surrounding area, so it would not make sense to keep voxels that cast too much shadow or block too much skylight. Therefore, the voxels that cast too much shadow and block too much skylight from the context are removed. Sun blocking calculation skylight blocking calculation Threshold New envelope greenery For the plot, 30% should be dedicated to becoming a greenspace. The location of this greenspace could be generated in three different ways: By hardcoding where the park should be located, for example based on observations made in the surroundings. By checking which ground level voxels would be most suitable for greenery; checking for sun, noise and daylight, and also closeness to certain functions. By checking which ground level voxels are least useful for generating the building, and removing those from the growth model. The first one is a more classic architectural way of designing, and would therefore not fit in our ambitions to create a generative building. The second option would be very interesting. Only this calculation would be useless if the final form of the building would not be taken into account, so doing this the greenery should be part of the agent based model. Not only this, but the agent based model would need an iteration for the sun- and daylight blockage towards the greenery for every growth step, since the most hinder of sun- and daylight would be generated by buildings that are closest to the greenery, being the generative building itself. Next to that, also the voxel values that are above the selected greenery should be taken into account for each iteration. This because by placing a greenery voxel, all voxels above (or all voxels that do not leave a certain value of day-and sunlight available for the voxel) should be removed from the availability lattice. It would be a waste of good voxels if these voxels are very valuable, whilst the greenery voxel would be almost as satisfied with another voxel. There is need for a balance of value in voxels that are discarded because of the greenspace and voxels that are selected for greenspace. Because of the complexity of this system and the lack of worth if not done well, this is not the method that has been executed. For this design, the last method was chosen, finding the average worth of each voxel and removing all voxels that have a low value. This should be done in a two dimensional way, because the greenery will occupy the full height if it takes the ground level voxel. For each voxel, the multiplication of all values that are associated with that location are being taken. Then this value is being summed for all voxels in the z-direction, creating a two dimensional value for each location. After normalizing this value, it is copied to all z-voxels so if a value is lower than the threshold, all voxels in that z-direction are being removed. average voxel value By then determining the minimum voxel value that is needed to clear 30% of the location, all values that are lower are being removed and all other voxels are being multiplied with the availability lattice that had been generated based on shadow. This results in the final availability lattice, and in the space dedicated for greenery. final availability lattice Evaluation of the location and the shape of the greenery Because of the many entrances that have been generated at the more accessible side of the plot, the distance values of these voxels are relatively impactful for the average value lattice, leaving a low-valued space at the north of the plot. This directly results in a greenspace that is not as open-oriented, but that is more encapsulated behind the building and oriented towards local users. This fits in with our concept of the greenery, that would be a place for retreat and also a place to have a food garden for the neighbourhood and the communal kitchen. Improvements As has been stated in the decision for this type of greenery selection, a much more complex way of determining the location of the greenery would be possible, but a self-evaluation loop for sun- and daylight would be needed, as well as the implementation of current voxel value evaluation with implementation of the greenery voxel values. This would be very useful, but was not manageable within the given timeframe.","title":"Designing the Lattice"},{"location":"A3_Massing/a3_configuring_Designing_The_Lattice/#designing-the-growth-lattice","text":"For generating the final building, not all voxels are appropriate to use. In this simulation, the growth lattice is being limited by two factors. With generating the building the surroundings are taken into account, and decided is that the building may not cast too much shadow to buildings in the surrounding. Next to that, a limit on the used ground floor space is asked, as 30% of the plot should be reserved for greenery.","title":"designing the growth lattice"},{"location":"A3_Massing/a3_configuring_Designing_The_Lattice/#sun-and-skylight","text":"Based on the ladybug sunpath the shadow envelope is calculated. To do so a ray is cast from the centroids of all the voxel that have received sun, towards the context. If the ray does not intersect the context, then the voxel does not cast a shadow. The shadow envelope is then interpolated to a highres value. For Skylight blocking all these steps are repeated, but instead of loading a sunpath, a sphere is created to represent the sky. Instead of shooting rays towards the sunpoints, the rays are being shot to the skypoints. method of skylight and sun blocking Fundamentally our building should be of least disturbance for the surrounding area, so it would not make sense to keep voxels that cast too much shadow or block too much skylight. Therefore, the voxels that cast too much shadow and block too much skylight from the context are removed. Sun blocking calculation skylight blocking calculation Threshold New envelope","title":"Sun and Skylight"},{"location":"A3_Massing/a3_configuring_Designing_The_Lattice/#greenery","text":"For the plot, 30% should be dedicated to becoming a greenspace. The location of this greenspace could be generated in three different ways: By hardcoding where the park should be located, for example based on observations made in the surroundings. By checking which ground level voxels would be most suitable for greenery; checking for sun, noise and daylight, and also closeness to certain functions. By checking which ground level voxels are least useful for generating the building, and removing those from the growth model. The first one is a more classic architectural way of designing, and would therefore not fit in our ambitions to create a generative building. The second option would be very interesting. Only this calculation would be useless if the final form of the building would not be taken into account, so doing this the greenery should be part of the agent based model. Not only this, but the agent based model would need an iteration for the sun- and daylight blockage towards the greenery for every growth step, since the most hinder of sun- and daylight would be generated by buildings that are closest to the greenery, being the generative building itself. Next to that, also the voxel values that are above the selected greenery should be taken into account for each iteration. This because by placing a greenery voxel, all voxels above (or all voxels that do not leave a certain value of day-and sunlight available for the voxel) should be removed from the availability lattice. It would be a waste of good voxels if these voxels are very valuable, whilst the greenery voxel would be almost as satisfied with another voxel. There is need for a balance of value in voxels that are discarded because of the greenspace and voxels that are selected for greenspace. Because of the complexity of this system and the lack of worth if not done well, this is not the method that has been executed. For this design, the last method was chosen, finding the average worth of each voxel and removing all voxels that have a low value. This should be done in a two dimensional way, because the greenery will occupy the full height if it takes the ground level voxel. For each voxel, the multiplication of all values that are associated with that location are being taken. Then this value is being summed for all voxels in the z-direction, creating a two dimensional value for each location. After normalizing this value, it is copied to all z-voxels so if a value is lower than the threshold, all voxels in that z-direction are being removed. average voxel value By then determining the minimum voxel value that is needed to clear 30% of the location, all values that are lower are being removed and all other voxels are being multiplied with the availability lattice that had been generated based on shadow. This results in the final availability lattice, and in the space dedicated for greenery. final availability lattice","title":"greenery"},{"location":"A3_Massing/a3_configuring_Designing_The_Lattice/#evaluation-of-the-location-and-the-shape-of-the-greenery","text":"Because of the many entrances that have been generated at the more accessible side of the plot, the distance values of these voxels are relatively impactful for the average value lattice, leaving a low-valued space at the north of the plot. This directly results in a greenspace that is not as open-oriented, but that is more encapsulated behind the building and oriented towards local users. This fits in with our concept of the greenery, that would be a place for retreat and also a place to have a food garden for the neighbourhood and the communal kitchen.","title":"Evaluation of the location and the shape of the greenery"},{"location":"A3_Massing/a3_configuring_Designing_The_Lattice/#improvements","text":"As has been stated in the decision for this type of greenery selection, a much more complex way of determining the location of the greenery would be possible, but a self-evaluation loop for sun- and daylight would be needed, as well as the implementation of current voxel value evaluation with implementation of the greenery voxel values. This would be very useful, but was not manageable within the given timeframe.","title":"Improvements"},{"location":"A3_Massing/a3_configuring_Spatial_Analysis/","text":"Spatial analysis: generating all voxel values To be able to locate all functions at their optimal location in the lattice, value lattices are to be generated. This to determine which voxels are where each voxel of the lattice needs values for: 1. Skyview 2. Sunlight availability 3. Quietness 4. Closeness to an entrance To generate these values, different computations are being made, and are being explained on this page. For each computation, the calculations are first being executed over the low-resolution lattice, after which they are interpolated to the final lattice with the voxel size of 1.8m * 1.8m * 1.8m. Sun and skylight Analysis Based on the ladybug sunpath the solar envelope is calculated. To do so a ray is cast from all the centroids of the voxels towards all the points on the sunpath. If a ray is not intersected by the context, then this voxel receives sunlight from this point. If the ray is intersected by the context, then the voxel does not receive sunlight from this point. This envelope is then interpolated to a highres value. For Skylight all these steps are repeated, but instead of loading a sunpath, a sphere is created to represent the sky. Instead of shooting rays towards the sunpoints, the rays are being shot to the skypoints. Sun availability calculation skylight availability calculation Sun and Skylight improvements Although these scripts are functional, there are still some improvements that could be made. - Factoring the influence of voxels inside the envelope on the sun/skylight and shadow/ skylight blocking. o For the initial stage of storing data and removing voxels, solely using the influence of the context on the voxels to be blocking sun or skylight is sufficient. But for later stages when the building is generated (link to growth model), it would be an improvement to take the influence of light and shadow of voxels on each other. This would make that script even heavier, because it will have to calculate a light and shadow value each time it adds voxels. Besides that, a distinction should made with the outer voxels and inner voxels, to have some depth in the building. This depth should also be specified. To solve this, the growth model could be normally ran at first, and then after it has finished going through an evaluation loop to check the shadow and skylight blocking on the context. - Removing bad voxels based on the shadow the context receives instead of the percentage of the time voxels cause shadow. o As of now a threshold is specified to remove voxels from the envelope based on the percentage of time these voxels cast shadow and block skylight from the context. However, it would be an improvement if the voxels are removed based on the effect they have on the context. If a voxel casts a shadow on the context 50% of the time, this could mean that it causes it on a different building each time, meaning that although the voxel looks \u201cbad\u201d, the net result on the context is negligible. This calculation should also be taken into the growth model (link to growth model). This does mean this script will become even more heavy as it now must calculate the shadow and skylight blocking each time it grows as well. To solve this, the growth model could be normally ran at first, and then after it has finished going through an evaluation loop to check the shadow and skylight blocking on the context. Quietness To calculate the quietness noise in the building in relation to its context a path with noise points on it is loaded inside a script. Each voxel then calculates the distance from the voxel centroid towards the noise point. These distances are added together and converted into a ratio. This script is actually more about business on street level than about quietness, since it imports noise points and not actual decibels from areas. This does not matter too much, since noise could be filtered from a building by adding more insulation and the relative quietness matters more than the actual numbers in decibels Noise highres(quietness) Entrances and distance lattices to these entrances For this script, a design decision is needed in regards to the placement of the entrances. For this, the following site analysis has been made: As is shown, the accessibility from the city centre is highest on the south and westside of the plot. The main connection with the city centre is the route from the south, via the Luchtsingel and the Hofbogen. To expand the atmosphere of this vivid area, the public functions should have short distance to this place. By placing them across the old metroline along the westside of the plot, the street ambiance will get a new boost, the old metroline can be made in good use and an extension of the vivid street scenery from the city centre is then generated. To make this work, a distance lattice is being made. the distance is calculated from all streetlevel voxels that are along this street. This would attract all functions that care about having a public entrance; fablabs, caf\u00e9 pub restaurant, arcade, shop, co-working spaces and startup office. By not giving them a determined entrance, there stays room for these functions to not only grow towards this set location but it gives them a range of places where they can grow with consideration of other values. As the accessibility from the city centre is also high for the eastside of the building, this could function as a more private, yet highly used entrance side. All communal functions could be located here, as well as the main housing entrances and the gym. For these functions, a few different lattices are generated, as the housing access needs a number of set location on different sides of the building, and the community centre entrance is set next to this housing entrance to have a entrance that brings people together. For the parking entrance, the location that has been chosen is close to the housing entrance, yet it should minimize car traffic in the neighbourhood and is therefore determined on the very east side of the building, close to bigger streets. For each lattice, a distance graph is generated for all voxels within the envelope. To minimize these calculations it is done over a bigger voxelsize. After generating this graph, the specific entrance voxels are selected, and with these voxels of interest a distance lattice is generated. After normalizing, interpolation takes place to translate all values to the actual voxelsize that is being used. distance lattice public entrance distance lattice gym distance lattice parking entrance distance lattice housing entrances distance lattice community centre Improvements To make an even more accurate and generative design, the initial locations of the entrances should not be chosen by hand but determined in a calculation of accessibility of the plot. This would be done by making an extensive model of all surrounding streets: their bustle, their usability for different types of traffic and their potential. This extensive model could not only be used for generating entrances, but also for a noise calculation to value all voxels based on the traffic. This more detailed way of locating an entrance should be implemented during the growth model, so closeness of other entrances would be taken into account for generating the wished for street ambiance","title":"Spatial Analysis"},{"location":"A3_Massing/a3_configuring_Spatial_Analysis/#spatial-analysis-generating-all-voxel-values","text":"To be able to locate all functions at their optimal location in the lattice, value lattices are to be generated. This to determine which voxels are where each voxel of the lattice needs values for: 1. Skyview 2. Sunlight availability 3. Quietness 4. Closeness to an entrance To generate these values, different computations are being made, and are being explained on this page. For each computation, the calculations are first being executed over the low-resolution lattice, after which they are interpolated to the final lattice with the voxel size of 1.8m * 1.8m * 1.8m.","title":"Spatial analysis: generating all voxel values"},{"location":"A3_Massing/a3_configuring_Spatial_Analysis/#sun-and-skylight-analysis","text":"Based on the ladybug sunpath the solar envelope is calculated. To do so a ray is cast from all the centroids of the voxels towards all the points on the sunpath. If a ray is not intersected by the context, then this voxel receives sunlight from this point. If the ray is intersected by the context, then the voxel does not receive sunlight from this point. This envelope is then interpolated to a highres value. For Skylight all these steps are repeated, but instead of loading a sunpath, a sphere is created to represent the sky. Instead of shooting rays towards the sunpoints, the rays are being shot to the skypoints. Sun availability calculation skylight availability calculation","title":"Sun and skylight Analysis"},{"location":"A3_Massing/a3_configuring_Spatial_Analysis/#sun-and-skylight-improvements","text":"Although these scripts are functional, there are still some improvements that could be made. - Factoring the influence of voxels inside the envelope on the sun/skylight and shadow/ skylight blocking. o For the initial stage of storing data and removing voxels, solely using the influence of the context on the voxels to be blocking sun or skylight is sufficient. But for later stages when the building is generated (link to growth model), it would be an improvement to take the influence of light and shadow of voxels on each other. This would make that script even heavier, because it will have to calculate a light and shadow value each time it adds voxels. Besides that, a distinction should made with the outer voxels and inner voxels, to have some depth in the building. This depth should also be specified. To solve this, the growth model could be normally ran at first, and then after it has finished going through an evaluation loop to check the shadow and skylight blocking on the context. - Removing bad voxels based on the shadow the context receives instead of the percentage of the time voxels cause shadow. o As of now a threshold is specified to remove voxels from the envelope based on the percentage of time these voxels cast shadow and block skylight from the context. However, it would be an improvement if the voxels are removed based on the effect they have on the context. If a voxel casts a shadow on the context 50% of the time, this could mean that it causes it on a different building each time, meaning that although the voxel looks \u201cbad\u201d, the net result on the context is negligible. This calculation should also be taken into the growth model (link to growth model). This does mean this script will become even more heavy as it now must calculate the shadow and skylight blocking each time it grows as well. To solve this, the growth model could be normally ran at first, and then after it has finished going through an evaluation loop to check the shadow and skylight blocking on the context.","title":"Sun and Skylight improvements"},{"location":"A3_Massing/a3_configuring_Spatial_Analysis/#quietness","text":"To calculate the quietness noise in the building in relation to its context a path with noise points on it is loaded inside a script. Each voxel then calculates the distance from the voxel centroid towards the noise point. These distances are added together and converted into a ratio. This script is actually more about business on street level than about quietness, since it imports noise points and not actual decibels from areas. This does not matter too much, since noise could be filtered from a building by adding more insulation and the relative quietness matters more than the actual numbers in decibels Noise highres(quietness)","title":"Quietness"},{"location":"A3_Massing/a3_configuring_Spatial_Analysis/#entrances-and-distance-lattices-to-these-entrances","text":"For this script, a design decision is needed in regards to the placement of the entrances. For this, the following site analysis has been made: As is shown, the accessibility from the city centre is highest on the south and westside of the plot. The main connection with the city centre is the route from the south, via the Luchtsingel and the Hofbogen. To expand the atmosphere of this vivid area, the public functions should have short distance to this place. By placing them across the old metroline along the westside of the plot, the street ambiance will get a new boost, the old metroline can be made in good use and an extension of the vivid street scenery from the city centre is then generated. To make this work, a distance lattice is being made. the distance is calculated from all streetlevel voxels that are along this street. This would attract all functions that care about having a public entrance; fablabs, caf\u00e9 pub restaurant, arcade, shop, co-working spaces and startup office. By not giving them a determined entrance, there stays room for these functions to not only grow towards this set location but it gives them a range of places where they can grow with consideration of other values. As the accessibility from the city centre is also high for the eastside of the building, this could function as a more private, yet highly used entrance side. All communal functions could be located here, as well as the main housing entrances and the gym. For these functions, a few different lattices are generated, as the housing access needs a number of set location on different sides of the building, and the community centre entrance is set next to this housing entrance to have a entrance that brings people together. For the parking entrance, the location that has been chosen is close to the housing entrance, yet it should minimize car traffic in the neighbourhood and is therefore determined on the very east side of the building, close to bigger streets. For each lattice, a distance graph is generated for all voxels within the envelope. To minimize these calculations it is done over a bigger voxelsize. After generating this graph, the specific entrance voxels are selected, and with these voxels of interest a distance lattice is generated. After normalizing, interpolation takes place to translate all values to the actual voxelsize that is being used. distance lattice public entrance distance lattice gym distance lattice parking entrance distance lattice housing entrances distance lattice community centre","title":"Entrances and distance lattices to these entrances"},{"location":"A3_Massing/a3_configuring_Spatial_Analysis/#improvements","text":"To make an even more accurate and generative design, the initial locations of the entrances should not be chosen by hand but determined in a calculation of accessibility of the plot. This would be done by making an extensive model of all surrounding streets: their bustle, their usability for different types of traffic and their potential. This extensive model could not only be used for generating entrances, but also for a noise calculation to value all voxels based on the traffic. This more detailed way of locating an entrance should be implemented during the growth model, so closeness of other entrances would be taken into account for generating the wished for street ambiance","title":"Improvements"},{"location":"A3_Massing/a3_configuring_intro/","text":"Process of massing For generating the building, a concatenation of code is needed. To visualize this, a flowchart is generated visualizing the final configuration process, showing all steps and connections. you can zoom in on the flowchart with the bar below that appears when hovering over the diagram configuration flowchart This process has four main steps: 1. The calculation of the voxel values 2. The selection of the aailable envelope 3. The placement of all functions in the envelope with the growth model 4. The polygonization of the fa\u00e7ade The first three steps are being explained on this page, whereas the elaboration on the polygonization is written in the massing process page. The order of all explanations will follow the order in the flowchart.","title":"Intro"},{"location":"A3_Massing/a3_configuring_intro/#process-of-massing","text":"For generating the building, a concatenation of code is needed. To visualize this, a flowchart is generated visualizing the final configuration process, showing all steps and connections. you can zoom in on the flowchart with the bar below that appears when hovering over the diagram configuration flowchart This process has four main steps: 1. The calculation of the voxel values 2. The selection of the aailable envelope 3. The placement of all functions in the envelope with the growth model 4. The polygonization of the fa\u00e7ade The first three steps are being explained on this page, whereas the elaboration on the polygonization is written in the massing process page. The order of all explanations will follow the order in the flowchart.","title":"Process of massing"},{"location":"A3_Massing/a3_configuring_shafts/","text":"Shaft and Corridor placement The shafts and corridors have been generated in a way that each floor has a network of corridors without any dead ends. depth analysis As is shown in the depth analysis (a translation of the topological map, with the focus on connections to the street) it can be seen that all public functions have their own entrance, all communal functions are connected to the community centre and all housing functions are connected to the housing entrance. For this corridor generation these two connection-groups are the connections that are being used. Other connections are considered secondary, and are therefore not taken into account. The division in functions (housing entrance and communal entrance) corresponds with the initial location of the functions, where all communal functions are located on the first two floors and the housing functions, along with the co-working spaces and the start-up offices, grow above this. This results in two types of corridor networks; one connecting all communal functions and all shafts to upper floors, and one connecting all functions that grow on the upper floors, along with the shafts. For the growth of the communal corridors, the initial seeds of these functions are being placed. Because the location of the shafts is more related to the location of the entrances than it is to the seeds of the voxels, the shafts are located based on these entrance locations. shaft locations based on entrances Instead of using the shafts as connections towards each seed, a list of each function seed is used. The shaft locations are then added to this list, and after generating a distance matrix the shortest path between each function in this list is then calculated. These shortest paths are calculated in a two-dimensional plane, and are then copied to all corresponding levels; voxels 1, 2 and 3 for the groundfloor level and voxels 4 and 5 for the second floor. corridors communal functions The same steps are being taken for the higher level functions, but in addition the height of the corridors is limited by the length of the shaft that it is connected to. This because the length of the shaft determines whether or not the floor is accessible. corridors upper floors Corridor evaluation Because the corridors are all connected, they limit the abm growth by enclosing voxel seeds and therefore we turned them off in this simulation. The location of the shafts led to the corridors growing along the border of the available voxels, occupying valuable space in the building. The shafts itself are also along the border, but this is a design question that does not have a straightforward answer, as shaft locations differ in each building design. For this situation, a placement along the border had been chosen to minimize walking distance within the building. Improvements The concept of these corridors is useful, but should be generated after the growth of the functions. Then it can find paths along the borders of each function, making sure no function gets limited in their growth. For some functions it might not be a problem if they were to be split up by these corridors and this could be determined in the agent preferences (housing functions, offices). This method would also make sure the most valuable voxels would not be occupied by the corridors, because the voxels that would now be occupied are the voxels that are placed later in the growth model and are therefore less ideal. Right now the corridor grows towards the most valuable voxel, occupying both this voxel and (at least) two of its direct neighbours. For the shafts, a stencil should be used to occupy all voxels that would be occupied when placing a shaft.","title":"Shafts and Corridors"},{"location":"A3_Massing/a3_configuring_shafts/#shaft-and-corridor-placement","text":"The shafts and corridors have been generated in a way that each floor has a network of corridors without any dead ends. depth analysis As is shown in the depth analysis (a translation of the topological map, with the focus on connections to the street) it can be seen that all public functions have their own entrance, all communal functions are connected to the community centre and all housing functions are connected to the housing entrance. For this corridor generation these two connection-groups are the connections that are being used. Other connections are considered secondary, and are therefore not taken into account. The division in functions (housing entrance and communal entrance) corresponds with the initial location of the functions, where all communal functions are located on the first two floors and the housing functions, along with the co-working spaces and the start-up offices, grow above this. This results in two types of corridor networks; one connecting all communal functions and all shafts to upper floors, and one connecting all functions that grow on the upper floors, along with the shafts. For the growth of the communal corridors, the initial seeds of these functions are being placed. Because the location of the shafts is more related to the location of the entrances than it is to the seeds of the voxels, the shafts are located based on these entrance locations. shaft locations based on entrances Instead of using the shafts as connections towards each seed, a list of each function seed is used. The shaft locations are then added to this list, and after generating a distance matrix the shortest path between each function in this list is then calculated. These shortest paths are calculated in a two-dimensional plane, and are then copied to all corresponding levels; voxels 1, 2 and 3 for the groundfloor level and voxels 4 and 5 for the second floor. corridors communal functions The same steps are being taken for the higher level functions, but in addition the height of the corridors is limited by the length of the shaft that it is connected to. This because the length of the shaft determines whether or not the floor is accessible. corridors upper floors","title":"Shaft and Corridor placement"},{"location":"A3_Massing/a3_configuring_shafts/#corridor-evaluation","text":"Because the corridors are all connected, they limit the abm growth by enclosing voxel seeds and therefore we turned them off in this simulation. The location of the shafts led to the corridors growing along the border of the available voxels, occupying valuable space in the building. The shafts itself are also along the border, but this is a design question that does not have a straightforward answer, as shaft locations differ in each building design. For this situation, a placement along the border had been chosen to minimize walking distance within the building.","title":"Corridor evaluation"},{"location":"A3_Massing/a3_configuring_shafts/#improvements","text":"The concept of these corridors is useful, but should be generated after the growth of the functions. Then it can find paths along the borders of each function, making sure no function gets limited in their growth. For some functions it might not be a problem if they were to be split up by these corridors and this could be determined in the agent preferences (housing functions, offices). This method would also make sure the most valuable voxels would not be occupied by the corridors, because the voxels that would now be occupied are the voxels that are placed later in the growth model and are therefore less ideal. Right now the corridor grows towards the most valuable voxel, occupying both this voxel and (at least) two of its direct neighbours. For the shafts, a stencil should be used to occupy all voxels that would be occupied when placing a shaft.","title":"Improvements"},{"location":"A3_Massing/a3_massing_product/","text":"Product of massing lattice values configuration steps ABM growth","title":"Product"},{"location":"A3_Massing/a3_massing_product/#product-of-massing","text":"","title":"Product of massing"},{"location":"A3_Massing/a3_massing_product/#lattice-values","text":"","title":"lattice values"},{"location":"A3_Massing/a3_massing_product/#configuration-steps","text":"","title":"configuration steps"},{"location":"A3_Massing/a3_massing_product/#abm-growth","text":"","title":"ABM growth"},{"location":"A3_Massing/images/","text":"A B C 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38","title":"Images"},{"location":"A4_Forming/a4_forming_process/","text":"Polygonization Perfect shape grasshopper script Everything thus far in this process has been modular and efficient. When it came to polygonization, which consists of a lot of manual labour, it did not feel like it was conformed to the ideology of this course. That\u2019s why we decided to make this process more modular and efficient. This originated the beginning of the \u2018\u2019perfect shape\u2019\u2019 grasshopper script. The script takes a perfect shape (cube) and cuts it into 152 pieces. It then sorts these pieces based on a distance from a point to the centroid of a piece. With the usage of slider, a selection can be made for a specific piece and a specific name. After this a directory is selected to save all the files to, by pressing a button. There is also the option to bake every object to their correct layer by pressing a button, as a backup check, as well as the option and delete all objects. For altering the building, the desired geometry should be added onto the \u201cperfect shape\u201d, creating a \u201cnew geometry\u201d. This shaped will then also be cut into 152 pieces, and sort based on a distance from the same point to the centroid of the pieces. The \u201cperfect shape\u201d pieces will form a cutting box by which the \u201cnew geometry\u201d pieces are cut up. In theory the \u201cnew geometry\u201d pieces should be in the same position as the \u201cperfect shape\u201d bounding box for a specific number. For this \u201cnew geometry\u201d the only change that must be made to the rest of the script, is to select a new directory to save the pieces to. This makes the process of generating multiple tilesets extremely efficient. This is the theory behind the script. Unfortunately, in practice, there are some challenges to work around. Firstly the \u201cnew geometry\u201d should be somewhat cube like. This means that although the added geometry can be asymmetrical, adding/extruding the geometry on an edge can only be done in a symmetrical way, otherwise the box will be cut up into more than 152 pieces. The way the 152 pieces are sorted is done by a distance from the piece towards a point. By altering the geometry, these distances do not always stay completely the same though. In 5 \u201cnew geometries\u201d tests, in 2 to 5 pieces out of 152 pieces, the order had changed. This can be solved by manually changing the slider to the correct position. In the 5 test runs the change of the slider was a maximum of 5 up or down. Pseudocode Perfect shape grasshopper script you can zoom in on the flowchart with the bar below that appears when hovering over the diagram symmetry = 152 pieces assymetry = more pieces Polygonization script Out of the possible 24 subtiles, it is only necessary to use 10 of them, the rest could be used for exceptions or when shapes are more complicated. In the 10 subtiles, there are 2 subtiles missing. There is no distinction between floor and roof and no distinction between roof corner and floor corner. As of now if when adding a railing to the roof of the building, this railing will also appear on the bottom of the building. different facade types polygonization model In the polygonization script itself, there are also still some challenges. Loading in textures and giving it to objects without making a mesh out of it works fine. But when the object file is made a mesh, it loses its texture coordinates. Our group managed to extract texture coordinates from an OBJ and give them to the object that is made a mesh in the jupyter notebook, but the link between textures + texture coordinates and the generated tiles from the subset is missing when exporting the final results or running everything through the poligonization script. Perhaps in the future another group can solve and implement this. To give the building a varying appearance, instead of having the same look everywhere throughout the building, stencils were implemented. Due to our floors being 2 voxels high, this brought a challenge. To vary a floor from down to top, it was necessary to design a tileset for the top as well as the bottom of the floor. While selecting these singular voxels as a stencil, another problem appeared. When separating 1 voxel from a bigger number of voxels, it will change from being a wall, to being a corner. The design of the singular voxel will have to be placed on the corner now. Since there is no distinction in the subtiles between a top or a bottom corner, this singular voxel will be symmetrical in both directions. This process is yet to be perfect, but the solutions seems to be not to far away. If the linkage between the textures+ texture coordinates and the generated tiles, the 2 extra subtiles are added, the usage of stencils is improved, this should be a good way to design the exterior of the building in a quick and modular way.","title":"Process"},{"location":"A4_Forming/a4_forming_process/#polygonization","text":"","title":"Polygonization"},{"location":"A4_Forming/a4_forming_process/#perfect-shape-grasshopper-script","text":"Everything thus far in this process has been modular and efficient. When it came to polygonization, which consists of a lot of manual labour, it did not feel like it was conformed to the ideology of this course. That\u2019s why we decided to make this process more modular and efficient. This originated the beginning of the \u2018\u2019perfect shape\u2019\u2019 grasshopper script. The script takes a perfect shape (cube) and cuts it into 152 pieces. It then sorts these pieces based on a distance from a point to the centroid of a piece. With the usage of slider, a selection can be made for a specific piece and a specific name. After this a directory is selected to save all the files to, by pressing a button. There is also the option to bake every object to their correct layer by pressing a button, as a backup check, as well as the option and delete all objects. For altering the building, the desired geometry should be added onto the \u201cperfect shape\u201d, creating a \u201cnew geometry\u201d. This shaped will then also be cut into 152 pieces, and sort based on a distance from the same point to the centroid of the pieces. The \u201cperfect shape\u201d pieces will form a cutting box by which the \u201cnew geometry\u201d pieces are cut up. In theory the \u201cnew geometry\u201d pieces should be in the same position as the \u201cperfect shape\u201d bounding box for a specific number. For this \u201cnew geometry\u201d the only change that must be made to the rest of the script, is to select a new directory to save the pieces to. This makes the process of generating multiple tilesets extremely efficient. This is the theory behind the script. Unfortunately, in practice, there are some challenges to work around. Firstly the \u201cnew geometry\u201d should be somewhat cube like. This means that although the added geometry can be asymmetrical, adding/extruding the geometry on an edge can only be done in a symmetrical way, otherwise the box will be cut up into more than 152 pieces. The way the 152 pieces are sorted is done by a distance from the piece towards a point. By altering the geometry, these distances do not always stay completely the same though. In 5 \u201cnew geometries\u201d tests, in 2 to 5 pieces out of 152 pieces, the order had changed. This can be solved by manually changing the slider to the correct position. In the 5 test runs the change of the slider was a maximum of 5 up or down.","title":"Perfect shape grasshopper script"},{"location":"A4_Forming/a4_forming_process/#pseudocode-perfect-shape-grasshopper-script","text":"you can zoom in on the flowchart with the bar below that appears when hovering over the diagram","title":"Pseudocode Perfect shape grasshopper script"},{"location":"A4_Forming/a4_forming_process/#symmetry-152-pieces","text":"","title":"symmetry = 152 pieces"},{"location":"A4_Forming/a4_forming_process/#assymetry-more-pieces","text":"","title":"assymetry = more pieces"},{"location":"A4_Forming/a4_forming_process/#polygonization-script","text":"Out of the possible 24 subtiles, it is only necessary to use 10 of them, the rest could be used for exceptions or when shapes are more complicated. In the 10 subtiles, there are 2 subtiles missing. There is no distinction between floor and roof and no distinction between roof corner and floor corner. As of now if when adding a railing to the roof of the building, this railing will also appear on the bottom of the building. different facade types polygonization model In the polygonization script itself, there are also still some challenges. Loading in textures and giving it to objects without making a mesh out of it works fine. But when the object file is made a mesh, it loses its texture coordinates. Our group managed to extract texture coordinates from an OBJ and give them to the object that is made a mesh in the jupyter notebook, but the link between textures + texture coordinates and the generated tiles from the subset is missing when exporting the final results or running everything through the poligonization script. Perhaps in the future another group can solve and implement this. To give the building a varying appearance, instead of having the same look everywhere throughout the building, stencils were implemented. Due to our floors being 2 voxels high, this brought a challenge. To vary a floor from down to top, it was necessary to design a tileset for the top as well as the bottom of the floor. While selecting these singular voxels as a stencil, another problem appeared. When separating 1 voxel from a bigger number of voxels, it will change from being a wall, to being a corner. The design of the singular voxel will have to be placed on the corner now. Since there is no distinction in the subtiles between a top or a bottom corner, this singular voxel will be symmetrical in both directions. This process is yet to be perfect, but the solutions seems to be not to far away. If the linkage between the textures+ texture coordinates and the generated tiles, the 2 extra subtiles are added, the usage of stencils is improved, this should be a good way to design the exterior of the building in a quick and modular way.","title":"Polygonization script"},{"location":"A4_Forming/a4_forming_product/","text":"Finalized renders","title":"Product"},{"location":"A4_Forming/a4_forming_product/#finalized-renders","text":"","title":"Finalized renders"},{"location":"Final_Deliverables/finalstuff/","text":"All scripts and input zipped Download link final poster Download & view link final presentation Download & view link final 3dm model Download link","title":"Final_Deliverables"},{"location":"Final_Deliverables/finalstuff/#all-scripts-and-input-zipped","text":"Download link","title":"All scripts and input zipped"},{"location":"Final_Deliverables/finalstuff/#final-poster","text":"Download & view link","title":"final poster"},{"location":"Final_Deliverables/finalstuff/#final-presentation","text":"Download & view link","title":"final presentation"},{"location":"Final_Deliverables/finalstuff/#final-3dm-model","text":"Download link","title":"final 3dm model"},{"location":"index/bibliography/","text":"Bibliography Title source Bouwbesluit Online source Scientias source Maarec source Wikipedia source acoustic frontiers source Wognai source American Planning Association source Spacebase source Wikimedia source appartement & eigenaar source Building for everyone source Dimensions source 's Heerenloo source Total Food Service source Game Estate source GE current source European Comission source Tauro source Heartline Fitness source pinimg source","title":"Bibliography"},{"location":"index/bibliography/#bibliography","text":"Title source Bouwbesluit Online source Scientias source Maarec source Wikipedia source acoustic frontiers source Wognai source American Planning Association source Spacebase source Wikimedia source appartement & eigenaar source Building for everyone source Dimensions source 's Heerenloo source Total Food Service source Game Estate source GE current source European Comission source Tauro source Heartline Fitness source pinimg source","title":"Bibliography"},{"location":"index/figures/","text":"Figures Figures from A1_Planning_process Figures from A1_Planning_product Figures from A2_Planning_process: Voxelsize determination Figures from A2_Planning_process: Space criteria Figures from A2_Planning_process: Voxelization Figures from A3_Massing_process: ABM Figures from A3_Massing_process: Designing the lattice Figures from A3_Massing_process: Intro Figures from A3_Massing_process: shafts and corridors Figures from A3_Massing_process: spatial analysis Figures from A3_Massing_process: product Figures from A4_Forming_process Figures from A4_Forming_product","title":"Figures"},{"location":"index/figures/#figures","text":"Figures from A1_Planning_process Figures from A1_Planning_product Figures from A2_Planning_process: Voxelsize determination Figures from A2_Planning_process: Space criteria Figures from A2_Planning_process: Voxelization Figures from A3_Massing_process: ABM Figures from A3_Massing_process: Designing the lattice Figures from A3_Massing_process: Intro Figures from A3_Massing_process: shafts and corridors Figures from A3_Massing_process: spatial analysis Figures from A3_Massing_process: product Figures from A4_Forming_process Figures from A4_Forming_product","title":"Figures"},{"location":"index/presentations/","text":"Presentations Midterm presentation (17 December 2020): Final presentation (21 January 2021):","title":"Presentations"},{"location":"index/presentations/#presentations","text":"Midterm presentation (17 December 2020): Final presentation (21 January 2021):","title":"Presentations"},{"location":"index/scripts/","text":"Scripts Here you should include all of your scripts whether they are text, python notebook or procedural scripts. You should also include link to the link to relevant location in the main pages, description, explanatory materials such as pseudo code or flowcharts, and visualizations if it is applicable. If necessary this page can be broken down to multiple pages. Here is an example of how to include your scripts: edges = [] for cell_neigh in cell_neighbors : cell = cell_neigh [ 0 ] for neigh in cell_neigh [ 1 :]: if neigh != - 1 and neigh > cell : edges . append (( cell , neigh )) - Voxelization highres and lowres: \"insert\" - Solar enveloppe + interpolation: \"insert\" - Shadow analysis + interpolation: \"insert\" - Skyview: \"insert\" - Noise: \"insert\" - Pathfinding + interpolation: \"insert\" - Agent based generation: \"insert\" - Shaping: \"insert\"","title":"Scripts"},{"location":"index/scripts/#scripts","text":"Here you should include all of your scripts whether they are text, python notebook or procedural scripts. You should also include link to the link to relevant location in the main pages, description, explanatory materials such as pseudo code or flowcharts, and visualizations if it is applicable. If necessary this page can be broken down to multiple pages. Here is an example of how to include your scripts: edges = [] for cell_neigh in cell_neighbors : cell = cell_neigh [ 0 ] for neigh in cell_neigh [ 1 :]: if neigh != - 1 and neigh > cell : edges . append (( cell , neigh )) - Voxelization highres and lowres: \"insert\" - Solar enveloppe + interpolation: \"insert\" - Shadow analysis + interpolation: \"insert\" - Skyview: \"insert\" - Noise: \"insert\" - Pathfinding + interpolation: \"insert\" - Agent based generation: \"insert\" - Shaping: \"insert\"","title":"Scripts"},{"location":"notebooks/1_voxelization/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Voxelization Workshop In this workshop we will learn how to voxelize a geometry and construct a lattice from it. 0. Initialization Importing all necessary libraries and specifying the inputs import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np vs = 1.8 unit = [ vs , vs , vs ] mesh_path = os . path . relpath ( '../data/compulsory_envelope.obj' ) 1. Input Mesh # load the mesh from file mesh = tm . load ( mesh_path ) # Check if the mesh is watertight print ( mesh . is_watertight ) # convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # Visualize the mesh using pyvista plotter ####### # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the base mesh: light blue p . add_mesh ( tri_to_pv ( mesh ), color = 'white' ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/mesh.png' ) p . show ( screenshot = png_path ) #start point array mesh . vertices += np . array ([ 0 , 0 , - 0.01 ]) 2. Voxelize the Mesh # initialize the base lattice base_lattice = tg . lattice ( mesh . bounds , unit = unit , default_value = 1 , dtype = int ) # check which voxel centroids is inside the mesh interior_condition = mesh . contains ( base_lattice . centroids ) # reshape the interior condition to the shape of the base_lattice interior_array = interior_condition . reshape ( base_lattice . shape ) # convert the interior array into a lattice interior_lattice = tg . to_lattice ( interior_array , base_lattice . minbound , base_lattice . unit ) print ( enumerate ( interior_lattice )) # convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # Visualize the voxelization using pyvista plotter ##### # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice interior_lattice . fast_vis ( p ) # adding the base mesh: light blue p . add_mesh ( tri_to_pv ( mesh ), color = '#abd8ff' , opacity = 0.1 ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/ful_lattice.png' ) p . show ( screenshot = png_path ) 3. Saving the lattice to CSV csv_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) interior_lattice . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi\" _editor_ = \"PROJECT APIDAE\" _editor_mentor_ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Voxelization\"","title":"Voxelization highres and lowres"},{"location":"notebooks/1_voxelization/#voxelization-workshop","text":"In this workshop we will learn how to voxelize a geometry and construct a lattice from it.","title":"Voxelization Workshop"},{"location":"notebooks/1_voxelization/#0-initialization","text":"Importing all necessary libraries and specifying the inputs import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np vs = 1.8 unit = [ vs , vs , vs ] mesh_path = os . path . relpath ( '../data/compulsory_envelope.obj' )","title":"0. Initialization"},{"location":"notebooks/1_voxelization/#1-input-mesh","text":"# load the mesh from file mesh = tm . load ( mesh_path ) # Check if the mesh is watertight print ( mesh . is_watertight ) # convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # Visualize the mesh using pyvista plotter ####### # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the base mesh: light blue p . add_mesh ( tri_to_pv ( mesh ), color = 'white' ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/mesh.png' ) p . show ( screenshot = png_path ) #start point array mesh . vertices += np . array ([ 0 , 0 , - 0.01 ])","title":"1. Input Mesh"},{"location":"notebooks/1_voxelization/#2-voxelize-the-mesh","text":"# initialize the base lattice base_lattice = tg . lattice ( mesh . bounds , unit = unit , default_value = 1 , dtype = int ) # check which voxel centroids is inside the mesh interior_condition = mesh . contains ( base_lattice . centroids ) # reshape the interior condition to the shape of the base_lattice interior_array = interior_condition . reshape ( base_lattice . shape ) # convert the interior array into a lattice interior_lattice = tg . to_lattice ( interior_array , base_lattice . minbound , base_lattice . unit ) print ( enumerate ( interior_lattice )) # convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # Visualize the voxelization using pyvista plotter ##### # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice interior_lattice . fast_vis ( p ) # adding the base mesh: light blue p . add_mesh ( tri_to_pv ( mesh ), color = '#abd8ff' , opacity = 0.1 ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/ful_lattice.png' ) p . show ( screenshot = png_path )","title":"2. Voxelize the Mesh"},{"location":"notebooks/1_voxelization/#3-saving-the-lattice-to-csv","text":"csv_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) interior_lattice . to_csv ( csv_path )","title":"3. Saving the lattice to CSV"},{"location":"notebooks/1_voxelization/#credits","text":"__author__ = \"Shervin Azadi\" _editor_ = \"PROJECT APIDAE\" _editor_mentor_ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Voxelization\"","title":"Credits"},{"location":"notebooks/2.1_lattice_sun_and_shadow/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Lattice Sun and Shadow This script generates an interpolated sun and shadow lattice. To do this the script imports a sunpath from ladybug. This Sunpath takes as input a longtitude and latitude over which to take the sun information. Based on the capacity of your hardware, or the size of the lattice over which to calculate For each voxel it casts a ray towards the sunpath. Because of the context arround the building, this ray could be blocked- the voxel does not receive light from this sunray. For all the voxels that have received light, it then casts the ray from the voxel to the sun backwards, to check whether it blocks sun (casts a shadow) from the context. As an input it takes a low_res and highres_lattice and a Sunpath and as output it generates a high_res and low_res lightvalue 0. Initialization Importing all necessary libraries and specifying the inputs import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator 1. Import Meshes (context + envelope) 1.1. Load Meshes #loading envelope and context from obj envelope_path = os . path . relpath ( '../data/compulsory_envelope.obj' ) context_path = os . path . relpath ( '../data/immediate_context.obj' ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) print ( context_mesh . is_watertight ) 1.2. Visualize Meshes (with pyvista) # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the meshes p . add_mesh ( tri_to_pv ( envelope_mesh ), color = '#abd8ff' ) p . add_mesh ( tri_to_pv ( context_mesh ), color = '#aaaaaa' ) # plotting p . show ( use_ipyvtk = True ) 2. Import Lattice (envelope) 2.1. Load the Envelope Lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) #setting the full lattice full_lattice = envelope_lattice * 0 + 1 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) 2.2. Visualize the Context Mesh + Envelope Lattice # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice envelope_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), color = '#aaaaaa' ) # plotting p . show ( use_ipyvtk = True ) 3. Sun Vectors 3.1. Compute Sun Vectors # initiate sunpath sp = Sunpath ( longitude = 4.3571 , latitude = 52.0116 ) # defening sun hours hoys = [] sun_vectors = [] day_multiples = 90 for d in range ( 365 ): if d % day_multiples == 0 : for h in range ( 24 ): i = d * 24 + h # compute the sun object sun = sp . calculate_sun_from_hoy ( i ) # extract the sun vector sun_vector = sun . sun_vector . to_array () # Removing the sun vectors under the horizon if sun_vector [ 2 ] < 0.0 : hoys . append ( i ) sun_vectors . append ( sun_vector ) sun_vectors = np . array ( sun_vectors ) # compute the rotation matrix Rz = tm . transformations . rotation_matrix ( np . radians ( 36.324 ), [ 0 , 0 , 1 ]) # Rotate the sun vectors to match the site rotation sun_vectors = tm . transform_points ( sun_vectors , Rz ) print ( sun_vectors . shape ) # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice envelope_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), color = '#aaaaaa' ) # add the sun locations, color orange p . add_points ( - sun_vectors * 300 , color = '#ffa500' ) # plotting p . show ( use_ipyvtk = True ) 4. Compute Intersection of Sun Rays with Context Mesh 4.1. Preparing the List of Ray Directions and Origins # constructing the sun direction from the sun vectors in a numpy array sun_dirs = - np . array ( sun_vectors ) # exract the centroids of the envelope voxels full_lattice = envelope_lattice * 0 + 1 vox_cens = full_lattice . centroids # shoot towards all sun vectors from all voxel centroids ray_dir = [] ray_src = [] for v_cen in vox_cens : for s_dir in sun_dirs : ray_dir . append ( s_dir ) ray_src . append ( v_cen ) # converting the list of directions and sources to numpy array ray_dir = np . array ( ray_dir ) ray_src = np . array ( ray_src ) print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , sun_dirs . shape ) print ( \"number of rays to be shooted :\" , ray_src . shape ) 4.2. Computing the Intersection # computing the intersections of rays with the context mesh from voxel centroid towards sun f_tri_id , f_ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions = ray_dir , multiple_hits = False ) # computing the intersections of rays with the context mesh from voxel centroid backwards to context b_tri_id , b_ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions =- ray_dir , multiple_hits = False ) 5. Aggregate Simulation Result in the Sun Access Lattice and shadow access lattice # initializing the hits list full of zeros f_hits = [ 0 ] * len ( ray_dir ) b_hits = [ 0 ] * len ( ray_dir ) for id in f_ray_id : f_hits [ id ] = 1 for id in b_ray_id : if not f_hits [ id ]: b_hits [ id ] = 1 calculating the sun_access and shadow # initiating the sun and vox list sun_count = len ( sun_dirs ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_sun_acc = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( sun_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * sun_count # summing the intersections int_count += f_hits [ r_id ] # computing the percentage of the rays that DID NOT have an intersection sun_access = 1 - int_count / sun_count # add the ratio to list vox_sun_acc . append ( sun_access ) # hits = np.array(hits) vox_sun_acc = np . array ( vox_sun_acc ) # initiating the list of ratio vox_shadowing = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( sun_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * sun_count # summing the intersections int_count += b_hits [ r_id ] # computing the percentage of the rays that DID NOT have an intersection shadowing = int_count / sun_count # add the ratio to list vox_shadowing . append ( shadowing ) vox_shadowing = np . array ( vox_shadowing ) 5.2. Store shadow access information in a Lattice # getting the condition of all voxels: are they inside the envelope or not env_all_vox = full_lattice . flatten () # all voxels cast shadow access all_vox_shad_cast = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_shad_cast . append ( vox_shadowing [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 else : # add 0.0 for its sun access all_vox_shad_cast . append ( 0.0 ) # convert to array shadcast_array = np . array ( all_vox_shad_cast ) # reshape to lattice shape shadcast_array = shadcast_array . reshape ( envelope_lattice . shape ) # convert to lattice shadcast_lattice = tg . to_lattice ( shadcast_array , envelope_lattice ) print ( shadcast_lattice . shape ) 5.2.1 Store sun access information in a Lattice # getting the condition of all voxels: are they inside the envelop or not env_all_vox = full_lattice . flatten () # all voxels sun access all_vox_sunacc = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_sunacc . append ( vox_sun_acc [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 else : # add 0.0 for its sun access all_vox_sunacc . append ( 0.0 ) # convert to array sunacc_array = np . array ( all_vox_sunacc ) # reshape to lattice shape sunacc_array = sunacc_array . reshape ( envelope_lattice . shape ) # convert to lattice sunacc_lattice = tg . to_lattice ( sunacc_array , envelope_lattice ) print ( sunacc_lattice . shape ) 5.2. shadow lattice information # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = shadcast_lattice # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Shadow Casting\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) 5.2.1 sun lattice information # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sunacc_lattice # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Sun Access\" ] = vis_lattice . flatten ( order = \"F\" ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) 5.3. Interpolation def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice envelope_lattice = base_highres + 1 # sample points sample_points = envelope_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres #interpolation the shadow_access to highres shad_acc_highres = interpolate ( shadcast_lattice , avail_lattice_highres ) #interpolation the sun_access to highres sun_acc_highres = interpolate ( sunacc_lattice , avail_lattice_highres ) 5.3. Visualize the sun and shadow access lattice # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = shad_acc_highres # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Shadow Casting\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sun_acc_highres # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Sun Access\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) 6. Save Sun Access Lattice into a CSV # save the shadow access latice to csv csv_path = os . path . relpath ( '../data/shadow_access_highres.csv' ) shad_acc_highres . to_csv ( csv_path ) # save the sun access latice to csv csv_path = os . path . relpath ( '../data/sun_access_highres.csv' ) sun_acc_highres . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = 'Siebren Meines' __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Interpolation of sun and shadow\"","title":"Sun and shadow analysis"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#lattice-sun-and-shadow","text":"This script generates an interpolated sun and shadow lattice. To do this the script imports a sunpath from ladybug. This Sunpath takes as input a longtitude and latitude over which to take the sun information. Based on the capacity of your hardware, or the size of the lattice over which to calculate For each voxel it casts a ray towards the sunpath. Because of the context arround the building, this ray could be blocked- the voxel does not receive light from this sunray. For all the voxels that have received light, it then casts the ray from the voxel to the sun backwards, to check whether it blocks sun (casts a shadow) from the context. As an input it takes a low_res and highres_lattice and a Sunpath and as output it generates a high_res and low_res lightvalue","title":"Lattice Sun and Shadow"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#0-initialization","text":"Importing all necessary libraries and specifying the inputs import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator","title":"0. Initialization"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#1-import-meshes-context-envelope","text":"","title":"1. Import Meshes (context + envelope)"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#11-load-meshes","text":"#loading envelope and context from obj envelope_path = os . path . relpath ( '../data/compulsory_envelope.obj' ) context_path = os . path . relpath ( '../data/immediate_context.obj' ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) print ( context_mesh . is_watertight )","title":"1.1. Load Meshes"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#12-visualize-meshes-with-pyvista","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the meshes p . add_mesh ( tri_to_pv ( envelope_mesh ), color = '#abd8ff' ) p . add_mesh ( tri_to_pv ( context_mesh ), color = '#aaaaaa' ) # plotting p . show ( use_ipyvtk = True )","title":"1.2. Visualize Meshes (with pyvista)"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#2-import-lattice-envelope","text":"","title":"2. Import Lattice (envelope)"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#21-load-the-envelope-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) #setting the full lattice full_lattice = envelope_lattice * 0 + 1 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path )","title":"2.1. Load the Envelope Lattice"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#22-visualize-the-context-mesh-envelope-lattice","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice envelope_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), color = '#aaaaaa' ) # plotting p . show ( use_ipyvtk = True )","title":"2.2. Visualize the Context Mesh + Envelope Lattice"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#3-sun-vectors","text":"","title":"3. Sun Vectors"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#31-compute-sun-vectors","text":"# initiate sunpath sp = Sunpath ( longitude = 4.3571 , latitude = 52.0116 ) # defening sun hours hoys = [] sun_vectors = [] day_multiples = 90 for d in range ( 365 ): if d % day_multiples == 0 : for h in range ( 24 ): i = d * 24 + h # compute the sun object sun = sp . calculate_sun_from_hoy ( i ) # extract the sun vector sun_vector = sun . sun_vector . to_array () # Removing the sun vectors under the horizon if sun_vector [ 2 ] < 0.0 : hoys . append ( i ) sun_vectors . append ( sun_vector ) sun_vectors = np . array ( sun_vectors ) # compute the rotation matrix Rz = tm . transformations . rotation_matrix ( np . radians ( 36.324 ), [ 0 , 0 , 1 ]) # Rotate the sun vectors to match the site rotation sun_vectors = tm . transform_points ( sun_vectors , Rz ) print ( sun_vectors . shape ) # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice envelope_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), color = '#aaaaaa' ) # add the sun locations, color orange p . add_points ( - sun_vectors * 300 , color = '#ffa500' ) # plotting p . show ( use_ipyvtk = True )","title":"3.1. Compute Sun Vectors"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#4-compute-intersection-of-sun-rays-with-context-mesh","text":"","title":"4. Compute Intersection of Sun Rays with Context Mesh"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#41-preparing-the-list-of-ray-directions-and-origins","text":"# constructing the sun direction from the sun vectors in a numpy array sun_dirs = - np . array ( sun_vectors ) # exract the centroids of the envelope voxels full_lattice = envelope_lattice * 0 + 1 vox_cens = full_lattice . centroids # shoot towards all sun vectors from all voxel centroids ray_dir = [] ray_src = [] for v_cen in vox_cens : for s_dir in sun_dirs : ray_dir . append ( s_dir ) ray_src . append ( v_cen ) # converting the list of directions and sources to numpy array ray_dir = np . array ( ray_dir ) ray_src = np . array ( ray_src ) print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , sun_dirs . shape ) print ( \"number of rays to be shooted :\" , ray_src . shape )","title":"4.1. Preparing the List of Ray Directions and Origins"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#42-computing-the-intersection","text":"# computing the intersections of rays with the context mesh from voxel centroid towards sun f_tri_id , f_ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions = ray_dir , multiple_hits = False ) # computing the intersections of rays with the context mesh from voxel centroid backwards to context b_tri_id , b_ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions =- ray_dir , multiple_hits = False )","title":"4.2. Computing the Intersection"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#5-aggregate-simulation-result-in-the-sun-access-lattice-and-shadow-access-lattice","text":"# initializing the hits list full of zeros f_hits = [ 0 ] * len ( ray_dir ) b_hits = [ 0 ] * len ( ray_dir ) for id in f_ray_id : f_hits [ id ] = 1 for id in b_ray_id : if not f_hits [ id ]: b_hits [ id ] = 1","title":"5. Aggregate Simulation Result in the Sun Access Lattice and shadow access lattice"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#calculating-the-sun_access-and-shadow","text":"# initiating the sun and vox list sun_count = len ( sun_dirs ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_sun_acc = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( sun_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * sun_count # summing the intersections int_count += f_hits [ r_id ] # computing the percentage of the rays that DID NOT have an intersection sun_access = 1 - int_count / sun_count # add the ratio to list vox_sun_acc . append ( sun_access ) # hits = np.array(hits) vox_sun_acc = np . array ( vox_sun_acc ) # initiating the list of ratio vox_shadowing = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( sun_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * sun_count # summing the intersections int_count += b_hits [ r_id ] # computing the percentage of the rays that DID NOT have an intersection shadowing = int_count / sun_count # add the ratio to list vox_shadowing . append ( shadowing ) vox_shadowing = np . array ( vox_shadowing )","title":"calculating the sun_access and shadow"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#52-store-shadow-access-information-in-a-lattice","text":"# getting the condition of all voxels: are they inside the envelope or not env_all_vox = full_lattice . flatten () # all voxels cast shadow access all_vox_shad_cast = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_shad_cast . append ( vox_shadowing [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 else : # add 0.0 for its sun access all_vox_shad_cast . append ( 0.0 ) # convert to array shadcast_array = np . array ( all_vox_shad_cast ) # reshape to lattice shape shadcast_array = shadcast_array . reshape ( envelope_lattice . shape ) # convert to lattice shadcast_lattice = tg . to_lattice ( shadcast_array , envelope_lattice ) print ( shadcast_lattice . shape )","title":"5.2. Store shadow access information in a Lattice"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#521-store-sun-access-information-in-a-lattice","text":"# getting the condition of all voxels: are they inside the envelop or not env_all_vox = full_lattice . flatten () # all voxels sun access all_vox_sunacc = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_sunacc . append ( vox_sun_acc [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 else : # add 0.0 for its sun access all_vox_sunacc . append ( 0.0 ) # convert to array sunacc_array = np . array ( all_vox_sunacc ) # reshape to lattice shape sunacc_array = sunacc_array . reshape ( envelope_lattice . shape ) # convert to lattice sunacc_lattice = tg . to_lattice ( sunacc_array , envelope_lattice ) print ( sunacc_lattice . shape )","title":"5.2.1 Store sun access information in a Lattice"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#52-shadow-lattice-information","text":"# initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = shadcast_lattice # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Shadow Casting\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True )","title":"5.2.  shadow lattice information"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#521-sun-lattice-information","text":"# initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sunacc_lattice # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Sun Access\" ] = vis_lattice . flatten ( order = \"F\" ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True )","title":"5.2.1  sun lattice information"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#53-interpolation","text":"def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice envelope_lattice = base_highres + 1 # sample points sample_points = envelope_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres #interpolation the shadow_access to highres shad_acc_highres = interpolate ( shadcast_lattice , avail_lattice_highres ) #interpolation the sun_access to highres sun_acc_highres = interpolate ( sunacc_lattice , avail_lattice_highres )","title":"5.3. Interpolation"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#53-visualize-the-sun-and-shadow-access-lattice","text":"# initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = shad_acc_highres # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Shadow Casting\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sun_acc_highres # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Sun Access\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True )","title":"5.3. Visualize the sun and shadow access lattice"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#6-save-sun-access-lattice-into-a-csv","text":"# save the shadow access latice to csv csv_path = os . path . relpath ( '../data/shadow_access_highres.csv' ) shad_acc_highres . to_csv ( csv_path ) # save the sun access latice to csv csv_path = os . path . relpath ( '../data/sun_access_highres.csv' ) sun_acc_highres . to_csv ( csv_path )","title":"6. Save Sun Access Lattice into a CSV"},{"location":"notebooks/2.1_lattice_sun_and_shadow/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = 'Siebren Meines' __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Interpolation of sun and shadow\"","title":"Credits"},{"location":"notebooks/2.2_full_lattice_sun_sky_blocking/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Envelope Selection This script deletes voxels from the lattice based on a treshold. As inputs it takes 1 or multiple lattices based on which you want to remove the voxels. In this case it removes voxels based on the blockage of sun and of daylight. The output is the resulted output after the deletion of the treshold of both the sun and daylight. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import numpy as np import pandas as pd # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l 0.2. Load Sun Access Lattice # loading lattice from csv shaft_path = os . path . relpath ( '../data/shadow_access_highres.csv' ) shad_cast_lattice = lattice_from_csv ( shad_cast_path ) # loading lattice from csv sky_shad_cast_path = os . path . relpath ( '../data/sky_shadowcasting_highres.csv' ) sky_shad_cast_lattice = lattice_from_csv ( sky_shad_cast_path ) 1. Envelope Selection 1.1. Visualizing the selection p = pv . Plotter ( notebook = True ) base_lattice = shad_cast_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): lattice = np . copy ( shad_cast_lattice ) lattice [ shad_cast_lattice > value ] *= - 0.0 # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.001 , 1.0 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False , clim = [ 0.0 , 1.0 ]) return p . add_slider_widget ( create_mesh , [ 0 , 1 ], title = 'Time' , value = 1.0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) p = pv . Plotter ( notebook = True ) base_lattice = sky_shad_cast_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): lattice = np . copy ( shad_cast_lattice ) lattice [ shad_cast_lattice > value ] *= - 0.0 # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.001 , 1.0 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False , clim = [ 0.0 , 1.0 ]) return p . add_slider_widget ( create_mesh , [ 0 , 1 ], title = 'Time' , value = 1.0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) 1.2. Generating an envelope based on the selection #setting the threshold high_threshold = 0.33 low_threshold = 0.0001 #calculating the threshold over the lattices new_avail_lattice = (( shad_cast_lattice < high_threshold ) * ( shad_cast_lattice > low_threshold )) * (( sky_shad_cast_lattice < high_threshold ) * ( sky_shad_cast_lattice > low_threshold )) 1.3. Visualize the new available lattice p = pv . Plotter ( notebook = True ) # adding the avilability lattice new_avail_lattice . fast_vis ( p ) p . show ( use_ipyvtk = True ) 1.4. Save new envelope to CSV #saving lattices on a desired location csv csv_path = os . path . relpath ( '../data/new_shadremove_envelope_lattice.csv' ) new_avail_lattice . to_csv ( csv_path ) __author__ = \"Shervin Azadi\" __editor__ = \"Siebren Meines\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Removing voxels based on a treshold\"","title":"Sun block analysis"},{"location":"notebooks/2.2_full_lattice_sun_sky_blocking/#envelope-selection","text":"This script deletes voxels from the lattice based on a treshold. As inputs it takes 1 or multiple lattices based on which you want to remove the voxels. In this case it removes voxels based on the blockage of sun and of daylight. The output is the resulted output after the deletion of the treshold of both the sun and daylight.","title":"Envelope Selection"},{"location":"notebooks/2.2_full_lattice_sun_sky_blocking/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/2.2_full_lattice_sun_sky_blocking/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import numpy as np import pandas as pd # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l","title":"0.1. Load required libraries"},{"location":"notebooks/2.2_full_lattice_sun_sky_blocking/#02-load-sun-access-lattice","text":"# loading lattice from csv shaft_path = os . path . relpath ( '../data/shadow_access_highres.csv' ) shad_cast_lattice = lattice_from_csv ( shad_cast_path ) # loading lattice from csv sky_shad_cast_path = os . path . relpath ( '../data/sky_shadowcasting_highres.csv' ) sky_shad_cast_lattice = lattice_from_csv ( sky_shad_cast_path )","title":"0.2. Load Sun Access Lattice"},{"location":"notebooks/2.2_full_lattice_sun_sky_blocking/#1-envelope-selection","text":"","title":"1. Envelope Selection"},{"location":"notebooks/2.2_full_lattice_sun_sky_blocking/#11-visualizing-the-selection","text":"p = pv . Plotter ( notebook = True ) base_lattice = shad_cast_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): lattice = np . copy ( shad_cast_lattice ) lattice [ shad_cast_lattice > value ] *= - 0.0 # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.001 , 1.0 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False , clim = [ 0.0 , 1.0 ]) return p . add_slider_widget ( create_mesh , [ 0 , 1 ], title = 'Time' , value = 1.0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) p = pv . Plotter ( notebook = True ) base_lattice = sky_shad_cast_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): lattice = np . copy ( shad_cast_lattice ) lattice [ shad_cast_lattice > value ] *= - 0.0 # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.001 , 1.0 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False , clim = [ 0.0 , 1.0 ]) return p . add_slider_widget ( create_mesh , [ 0 , 1 ], title = 'Time' , value = 1.0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True )","title":"1.1. Visualizing the selection"},{"location":"notebooks/2.2_full_lattice_sun_sky_blocking/#12-generating-an-envelope-based-on-the-selection","text":"#setting the threshold high_threshold = 0.33 low_threshold = 0.0001 #calculating the threshold over the lattices new_avail_lattice = (( shad_cast_lattice < high_threshold ) * ( shad_cast_lattice > low_threshold )) * (( sky_shad_cast_lattice < high_threshold ) * ( sky_shad_cast_lattice > low_threshold ))","title":"1.2. Generating an envelope based on the selection"},{"location":"notebooks/2.2_full_lattice_sun_sky_blocking/#13-visualize-the-new-available-lattice","text":"p = pv . Plotter ( notebook = True ) # adding the avilability lattice new_avail_lattice . fast_vis ( p ) p . show ( use_ipyvtk = True )","title":"1.3. Visualize the new available lattice"},{"location":"notebooks/2.2_full_lattice_sun_sky_blocking/#14-save-new-envelope-to-csv","text":"#saving lattices on a desired location csv csv_path = os . path . relpath ( '../data/new_shadremove_envelope_lattice.csv' ) new_avail_lattice . to_csv ( csv_path ) __author__ = \"Shervin Azadi\" __editor__ = \"Siebren Meines\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Removing voxels based on a treshold\"","title":"1.4. Save new envelope to CSV"},{"location":"notebooks/3.1_lattices_skylight/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Skylight This script calculates the skylight acces and the skylight blocking on the context of an envelope. It creates a sphere around the envelope and then castst a ray from each voxel to each of the points on the sphere. This ray could be blocked by the context. If the ray is not blocked by the context, it then also casts an inverse ray from the voxel towards. If this intersects the context, then the particular voxel blocks skylight from the context. As an iput this script takes a envelope_highres and envelope_lowres. As an output it gives a sky_shadowcasting_highres and sky_access highres lattice. 0. Initialization Importing all necessary libraries and specifying the inputs import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator 1. Import Meshes (context + envelope) 1.1. Load Meshes envelope_path = os . path . relpath ( \"../data/compulsory_envelope.obj\" ) context_path = os . path . relpath ( \"../data/immediate_context.obj\" ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) 1.2. Visualize Meshes (with pyvista) # convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the meshes p . add_mesh ( tri_to_pv ( envelope_mesh ), color = '#abd8ff' ) p . add_mesh ( tri_to_pv ( context_mesh ), color = '#aaaaaa' ) # plotting p . show ( use_ipyvtk = True ) 2. Import Lattice (envelope) 2.1. Load the Envelope Lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) full_lattice = envelope_lattice * 0 + 1 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) 2.2. Visualize the Context Mesh + Envelope Lattice # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice envelope_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), color = '#aaaaaa' ) # plotting p . show ( use_ipyvtk = True ) 3. Skylight factors 3.1. Compute Skylight Vectors #Create a sphere to put points on that represent the sky sphere_mesh = tm . creation . icosphere ( subdivisions = 3 , radius = 300.0 , color = None ) sphere_vectors = np . copy ( sphere_mesh . vertices ) sky_vectors = [] for v in sphere_vectors : if v [ 2 ] > 0.0 : sky_vectors . append ( v ) sky_vectors = np . array ( sky_vectors ) # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice envelope_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( sphere_mesh ), color = '#aaaaaa' ) # add the sun locations, color orange p . add_points ( sky_vectors * 300 , color = '#0033ff' ) # plotting p . show ( use_ipyvtk = True ) 4. Compute Intersection of Sun Rays with Context Mesh 4.1. Preparing the List of Ray Directions and Origins # constructing the sky direction from the sky vectors in a numpy array sky_dirs = np . array ( sky_vectors ) # exract the centroids of the envelope voxels full_lattice = envelope_lattice * 0 + 1 vox_cens = full_lattice . centroids # next step we need to shoot in all of the sky directions from all of the voxels ray_dir = [] ray_src = [] for v_cen in vox_cens : for s_dir in sky_dirs : #if s_dir = envelope_mesh ray_src . append ( v_cen ) ray_dir . append ( s_dir ) # converting the list of directions and sources to numpy array ray_dir = np . array ( ray_dir ) ray_src = np . array ( ray_src ) print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , sky_dirs . shape ) print ( \"number of rays to be shot :\" , ray_src . shape ) 4.2. Computing the Intersection # computing the intersections of rays with the context from voxel to sky f_tri_id , f_ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions = ray_dir , multiple_hits = False ) # computing the intersections of rays with the context backwards from voxel to context b_tri_id , b_ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions =- ray_dir , multiple_hits = False ) 5. Aggregate Simulation Result in the Sun Access Lattice 5.1. Compute the percentage of time that each voxel sees the sun # initializing the hits list full of zeros f_hits = [ 0 ] * len ( ray_dir ) b_hits = [ 0 ] * len ( ray_dir ) for id in f_ray_id : f_hits [ id ] = 1 for id in b_ray_id : if not f_hits [ id ]: b_hits [ id ] = 1 sky_count = len ( sky_dirs ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_sky_acc = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( sky_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * sky_count # summing the intersections int_count += f_hits [ r_id ] # computing the percentage of the rays that DID NOT have # an intersection (aka could see the sun) sky_access = 1 - int_count / sky_count # add the ratio to list vox_sky_acc . append ( sky_access ) # hits = np.array(hits) vox_sky_acc = np . array ( vox_sky_acc ) 5.1. Compute the shadow casting # initiating the list of ratio vox_sky_shadowing = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( sky_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * sky_count # summing the intersections int_count += b_hits [ r_id ] # computing the percentage of the rays that DID NOT have an intersection shadowing = int_count / sky_count # add the ratio to list vox_sky_shadowing . append ( shadowing ) vox_sky_shadowing = np . array ( vox_sky_shadowing ) 5.2. Store sun access information in a Lattice # getting the condition of all voxels: are they inside the envelop or not env_all_vox = full_lattice . flatten () # all voxels sun access all_vox_sky_acc = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_sky_acc . append ( vox_sky_acc [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 else : # add 0.0 for its sun access all_vox_sky_acc . append ( 0.0 ) # convert to array sky_acc_array = np . array ( all_vox_sky_acc ) # reshape to lattice shape sky_acc_array = sky_acc_array . reshape ( envelope_lattice . shape ) # convert to lattice sky_acc_lattice = tg . to_lattice ( sky_acc_array , envelope_lattice ) 5.2. Store shadow casting information in a Lattice # getting the condition of all voxels: are they inside the envelop or not env_all_vox = full_lattice . flatten () # all voxels sun access all_vox_sky_shad_cast = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_sky_shad_cast . append ( vox_sky_shadowing [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 else : # add 0.0 for its sun access all_vox_sky_shad_cast . append ( 0.0 ) # convert to array sky_shadcast_array = np . array ( all_vox_sky_shad_cast ) # reshape to lattice shape sky_shadcast_array = sky_shadcast_array . reshape ( envelope_lattice . shape ) # convert to lattice sky_shadcast_lattice = tg . to_lattice ( sky_shadcast_array , envelope_lattice ) 5.3. Visualize the sun access lattice # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sky_acc_lattice # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Sky Access\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0.0 , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) Visualize the shadow casting lattice # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sky_shadcast_lattice # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Skylight Blocking\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) 5.4 interpolation interpolation sky factor def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice envelope_lattice = base_highres + 1 # sample points sample_points = envelope_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres #interpolate the lattice over highres sky_acc_highres = interpolate ( sky_acc_lattice , avail_lattice_highres ) interpolation sky blocking factor def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice envelope_lattice = base_highres + 1 # sample points sample_points = envelope_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres #interpolate the lattice over highres sky_shadcast_highres = interpolate ( sky_shadcast_lattice , avail_lattice_highres ) 5.5 visualize interpolation Sky access interpolation # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sky_acc_highres # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Sky access Highres\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) sky view blocking interpolation # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sky_shadcast_highres # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"SkyBlocking highres\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) 6. Save Sun Access Lattice into a CSV #save the sky access latice to csv csv_path = os . path . relpath ( '../data/sky_access_highres.csv' ) sky_acc_highres . to_csv ( csv_path ) #save the skyblocking latice to csv csv_path = os . path . relpath ( '../data/sky_shadowcasting_highres.csv' ) sky_shadcast_highres . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Siebren Meines\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Skylight and skylight blocking calculation\"","title":"Skyview"},{"location":"notebooks/3.1_lattices_skylight/#skylight","text":"This script calculates the skylight acces and the skylight blocking on the context of an envelope. It creates a sphere around the envelope and then castst a ray from each voxel to each of the points on the sphere. This ray could be blocked by the context. If the ray is not blocked by the context, it then also casts an inverse ray from the voxel towards. If this intersects the context, then the particular voxel blocks skylight from the context. As an iput this script takes a envelope_highres and envelope_lowres. As an output it gives a sky_shadowcasting_highres and sky_access highres lattice.","title":"Skylight"},{"location":"notebooks/3.1_lattices_skylight/#0-initialization","text":"Importing all necessary libraries and specifying the inputs import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator","title":"0. Initialization"},{"location":"notebooks/3.1_lattices_skylight/#1-import-meshes-context-envelope","text":"","title":"1. Import Meshes (context + envelope)"},{"location":"notebooks/3.1_lattices_skylight/#11-load-meshes","text":"envelope_path = os . path . relpath ( \"../data/compulsory_envelope.obj\" ) context_path = os . path . relpath ( \"../data/immediate_context.obj\" ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight )","title":"1.1. Load Meshes"},{"location":"notebooks/3.1_lattices_skylight/#12-visualize-meshes-with-pyvista","text":"# convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the meshes p . add_mesh ( tri_to_pv ( envelope_mesh ), color = '#abd8ff' ) p . add_mesh ( tri_to_pv ( context_mesh ), color = '#aaaaaa' ) # plotting p . show ( use_ipyvtk = True )","title":"1.2. Visualize Meshes (with pyvista)"},{"location":"notebooks/3.1_lattices_skylight/#2-import-lattice-envelope","text":"","title":"2. Import Lattice (envelope)"},{"location":"notebooks/3.1_lattices_skylight/#21-load-the-envelope-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) full_lattice = envelope_lattice * 0 + 1 # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path )","title":"2.1. Load the Envelope Lattice"},{"location":"notebooks/3.1_lattices_skylight/#22-visualize-the-context-mesh-envelope-lattice","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice envelope_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), color = '#aaaaaa' ) # plotting p . show ( use_ipyvtk = True )","title":"2.2. Visualize the Context Mesh + Envelope Lattice"},{"location":"notebooks/3.1_lattices_skylight/#3-skylight-factors","text":"","title":"3. Skylight factors"},{"location":"notebooks/3.1_lattices_skylight/#31-compute-skylight-vectors","text":"#Create a sphere to put points on that represent the sky sphere_mesh = tm . creation . icosphere ( subdivisions = 3 , radius = 300.0 , color = None ) sphere_vectors = np . copy ( sphere_mesh . vertices ) sky_vectors = [] for v in sphere_vectors : if v [ 2 ] > 0.0 : sky_vectors . append ( v ) sky_vectors = np . array ( sky_vectors ) # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice envelope_lattice . fast_vis ( p ) # adding the meshes p . add_mesh ( tri_to_pv ( sphere_mesh ), color = '#aaaaaa' ) # add the sun locations, color orange p . add_points ( sky_vectors * 300 , color = '#0033ff' ) # plotting p . show ( use_ipyvtk = True )","title":"3.1. Compute Skylight Vectors"},{"location":"notebooks/3.1_lattices_skylight/#4-compute-intersection-of-sun-rays-with-context-mesh","text":"","title":"4. Compute Intersection of Sun Rays with Context Mesh"},{"location":"notebooks/3.1_lattices_skylight/#41-preparing-the-list-of-ray-directions-and-origins","text":"# constructing the sky direction from the sky vectors in a numpy array sky_dirs = np . array ( sky_vectors ) # exract the centroids of the envelope voxels full_lattice = envelope_lattice * 0 + 1 vox_cens = full_lattice . centroids # next step we need to shoot in all of the sky directions from all of the voxels ray_dir = [] ray_src = [] for v_cen in vox_cens : for s_dir in sky_dirs : #if s_dir = envelope_mesh ray_src . append ( v_cen ) ray_dir . append ( s_dir ) # converting the list of directions and sources to numpy array ray_dir = np . array ( ray_dir ) ray_src = np . array ( ray_src ) print ( \"number of voxels to shoot rays from :\" , vox_cens . shape ) print ( \"number of rays per each voxel :\" , sky_dirs . shape ) print ( \"number of rays to be shot :\" , ray_src . shape )","title":"4.1. Preparing the List of Ray Directions and Origins"},{"location":"notebooks/3.1_lattices_skylight/#42-computing-the-intersection","text":"# computing the intersections of rays with the context from voxel to sky f_tri_id , f_ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions = ray_dir , multiple_hits = False ) # computing the intersections of rays with the context backwards from voxel to context b_tri_id , b_ray_id = context_mesh . ray . intersects_id ( ray_origins = ray_src , ray_directions =- ray_dir , multiple_hits = False )","title":"4.2. Computing the Intersection"},{"location":"notebooks/3.1_lattices_skylight/#5-aggregate-simulation-result-in-the-sun-access-lattice","text":"","title":"5. Aggregate Simulation Result in the Sun Access Lattice"},{"location":"notebooks/3.1_lattices_skylight/#51-compute-the-percentage-of-time-that-each-voxel-sees-the-sun","text":"# initializing the hits list full of zeros f_hits = [ 0 ] * len ( ray_dir ) b_hits = [ 0 ] * len ( ray_dir ) for id in f_ray_id : f_hits [ id ] = 1 for id in b_ray_id : if not f_hits [ id ]: b_hits [ id ] = 1 sky_count = len ( sky_dirs ) vox_count = len ( vox_cens ) # initiating the list of ratio vox_sky_acc = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( sky_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * sky_count # summing the intersections int_count += f_hits [ r_id ] # computing the percentage of the rays that DID NOT have # an intersection (aka could see the sun) sky_access = 1 - int_count / sky_count # add the ratio to list vox_sky_acc . append ( sky_access ) # hits = np.array(hits) vox_sky_acc = np . array ( vox_sky_acc )","title":"5.1. Compute the percentage of time that each voxel sees the sun"},{"location":"notebooks/3.1_lattices_skylight/#51-compute-the-shadow-casting","text":"# initiating the list of ratio vox_sky_shadowing = [] # iterate over the voxels for v_id in range ( vox_count ): # counter for the intersection int_count = 0 # iterate over the sun rays for s_id in range ( sky_count ): # computing the ray id from voxel id and sun id r_id = s_id + v_id * sky_count # summing the intersections int_count += b_hits [ r_id ] # computing the percentage of the rays that DID NOT have an intersection shadowing = int_count / sky_count # add the ratio to list vox_sky_shadowing . append ( shadowing ) vox_sky_shadowing = np . array ( vox_sky_shadowing )","title":"5.1. Compute the shadow casting"},{"location":"notebooks/3.1_lattices_skylight/#52-store-sun-access-information-in-a-lattice","text":"# getting the condition of all voxels: are they inside the envelop or not env_all_vox = full_lattice . flatten () # all voxels sun access all_vox_sky_acc = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_sky_acc . append ( vox_sky_acc [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 else : # add 0.0 for its sun access all_vox_sky_acc . append ( 0.0 ) # convert to array sky_acc_array = np . array ( all_vox_sky_acc ) # reshape to lattice shape sky_acc_array = sky_acc_array . reshape ( envelope_lattice . shape ) # convert to lattice sky_acc_lattice = tg . to_lattice ( sky_acc_array , envelope_lattice )","title":"5.2. Store sun access information in a Lattice"},{"location":"notebooks/3.1_lattices_skylight/#52-store-shadow-casting-information-in-a-lattice","text":"# getting the condition of all voxels: are they inside the envelop or not env_all_vox = full_lattice . flatten () # all voxels sun access all_vox_sky_shad_cast = [] # v_id: voxel id in the list of only interior voxels v_id = 0 # for all the voxels, place the interiority condition of each voxel in \"vox_in\" for vox_in in env_all_vox : if vox_in == True : # read its value of sun access and append it to the list of all voxel sun access all_vox_sky_shad_cast . append ( vox_sky_shadowing [ v_id ]) # add one to the voxel id so the next time we read the next voxel v_id += 1 else : # add 0.0 for its sun access all_vox_sky_shad_cast . append ( 0.0 ) # convert to array sky_shadcast_array = np . array ( all_vox_sky_shad_cast ) # reshape to lattice shape sky_shadcast_array = sky_shadcast_array . reshape ( envelope_lattice . shape ) # convert to lattice sky_shadcast_lattice = tg . to_lattice ( sky_shadcast_array , envelope_lattice )","title":"5.2. Store shadow casting information in a Lattice"},{"location":"notebooks/3.1_lattices_skylight/#53-visualize-the-sun-access-lattice","text":"# initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sky_acc_lattice # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Sky Access\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0.0 , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True )","title":"5.3. Visualize the sun access lattice"},{"location":"notebooks/3.1_lattices_skylight/#visualize-the-shadow-casting-lattice","text":"# initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sky_shadcast_lattice # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Skylight Blocking\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True )","title":"Visualize the shadow casting lattice"},{"location":"notebooks/3.1_lattices_skylight/#54-interpolation","text":"","title":"5.4 interpolation"},{"location":"notebooks/3.1_lattices_skylight/#interpolation-sky-factor","text":"def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice envelope_lattice = base_highres + 1 # sample points sample_points = envelope_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres #interpolate the lattice over highres sky_acc_highres = interpolate ( sky_acc_lattice , avail_lattice_highres )","title":"interpolation sky factor"},{"location":"notebooks/3.1_lattices_skylight/#interpolation-sky-blocking-factor","text":"def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice envelope_lattice = base_highres + 1 # sample points sample_points = envelope_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres #interpolate the lattice over highres sky_shadcast_highres = interpolate ( sky_shadcast_lattice , avail_lattice_highres )","title":"interpolation sky blocking factor"},{"location":"notebooks/3.1_lattices_skylight/#55-visualize-interpolation","text":"","title":"5.5 visualize interpolation"},{"location":"notebooks/3.1_lattices_skylight/#sky-access-interpolation","text":"# initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sky_acc_highres # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Sky access Highres\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True )","title":"Sky access interpolation"},{"location":"notebooks/3.1_lattices_skylight/#sky-view-blocking-interpolation","text":"# initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = sky_shadcast_highres # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"SkyBlocking highres\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , clim = [ 0. , 1.0 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True )","title":"sky view blocking interpolation"},{"location":"notebooks/3.1_lattices_skylight/#6-save-sun-access-lattice-into-a-csv","text":"#save the sky access latice to csv csv_path = os . path . relpath ( '../data/sky_access_highres.csv' ) sky_acc_highres . to_csv ( csv_path ) #save the skyblocking latice to csv csv_path = os . path . relpath ( '../data/sky_shadowcasting_highres.csv' ) sky_shadcast_highres . to_csv ( csv_path )","title":"6. Save Sun Access Lattice into a CSV"},{"location":"notebooks/3.1_lattices_skylight/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Siebren Meines\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Skylight and skylight blocking calculation\"","title":"Credits"},{"location":"notebooks/3.2_lattice_quietness/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Noise Interpolation This script calculates the noise values throughout a building from a noise source. It takes as inputs a low_res and high_res version of the building, as well as a noise path, which consists of points. As an output it generates a quietness lattice. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import scipy as sp from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator 0.2. Load the envelope lattice as the avialbility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) 0.3. Load noise sources # loading noise points from CSV noise_source_path = os . path . relpath ( '../data/noise_points_2.csv' ) noise_sources = np . genfromtxt ( noise_source_path , delimiter = ',' ) noise_sources 0.4. Visualize noise source points # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the avilability lattice init_avail_lattice . fast_vis ( p ) # adding axes p . add_axes () p . add_mesh ( noise_sources , point_size = 10 ) p . show ( use_ipyvtk = True ) 1. Import Lattice (envelope) 1.1. Load the Envelope Lattice # loading the lowres lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) # loading the highres lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) 2. Creation of Noise Field 2.1. Computing noise lattices # create full lattice full_lattice = envelope_lattice * 0 + 1 # extract the coordiantes of the centroid of all voxel vox_centroids = full_lattice . centroids # extract voxel indices of all voxels vox_indices = np . array ( np . where ( full_lattice == 1 )) . T # setting the noise base pressure level noise_base = 75.0 # initializing the sum lattice of noise sum_noise_lats = envelope_lattice * 0.0 # for each source of noise for noise_src in noise_sources : # initialize the occupation lattice dist_latice = envelope_lattice * 0.0 for cen , ind in zip ( vox_centroids , vox_indices ): # compute the euclidian distance dist_latice [ tuple ( ind )] = sp . spatial . distance . euclidean ( cen , noise_src ) # computing the noise lattice from dist lattice noise_latice = noise_base - 20 * np . log10 ( dist_latice ) - 8 # summing sum_noise_lats += np . power ( 10 , noise_latice / 10.0 ) # computing the final aggregation agg_noise_lats = 10 * np . log10 ( sum_noise_lats ) 2.2. Store noise access information in a Lattice # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = agg_noise_lats # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Noise\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) #Convert the noise distaqnces to a ratio agg_noise_ratio_lats = 1 - ( agg_noise_lats - np . min ( agg_noise_lats )) / ( np . max ( agg_noise_lats ) - np . min ( agg_noise_lats )) 3. Interpolation def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice envelope_lattice = base_highres + 1 # sample points sample_points = envelope_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres noise_highres = interpolate ( agg_noise_ratio_lats , avail_lattice_highres ) # load the context and the envelope envelope_path = os . path . relpath ( \"../data/compulsory_envelope.obj\" ) context_path = os . path . relpath ( \"../data/immediate_context.obj\" ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) print ( context_mesh . is_watertight ) 3.1. Visualize the interpolated noise # initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = noise_highres # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Noise Highress\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) png_path = os . path . relpath ( '../screen/quietness.png' ) p . show ( screenshot = png_path ) 4. Save Quietness Access Lattice into a CSV #select a path and a name to save the csv csv_path = os . path . relpath ( '../data/quietness_highres.csv' ) noise_highres . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi\" __editor__ = 'Siebren Meines' __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Noise interpolation calculation\"","title":"Quietness"},{"location":"notebooks/3.2_lattice_quietness/#noise-interpolation","text":"This script calculates the noise values throughout a building from a noise source. It takes as inputs a low_res and high_res version of the building, as well as a noise path, which consists of points. As an output it generates a quietness lattice.","title":"Noise Interpolation"},{"location":"notebooks/3.2_lattice_quietness/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/3.2_lattice_quietness/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import scipy as sp from ladybug.sunpath import Sunpath from scipy.interpolate import RegularGridInterpolator","title":"0.1. Load required libraries"},{"location":"notebooks/3.2_lattice_quietness/#02-load-the-envelope-lattice-as-the-avialbility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice )","title":"0.2. Load the envelope lattice as the avialbility lattice"},{"location":"notebooks/3.2_lattice_quietness/#03-load-noise-sources","text":"# loading noise points from CSV noise_source_path = os . path . relpath ( '../data/noise_points_2.csv' ) noise_sources = np . genfromtxt ( noise_source_path , delimiter = ',' ) noise_sources","title":"0.3. Load noise sources"},{"location":"notebooks/3.2_lattice_quietness/#04-visualize-noise-source-points","text":"# initiating the plotter p = pv . Plotter ( notebook = True ) # adding the avilability lattice init_avail_lattice . fast_vis ( p ) # adding axes p . add_axes () p . add_mesh ( noise_sources , point_size = 10 ) p . show ( use_ipyvtk = True )","title":"0.4. Visualize noise source points"},{"location":"notebooks/3.2_lattice_quietness/#1-import-lattice-envelope","text":"","title":"1. Import Lattice (envelope)"},{"location":"notebooks/3.2_lattice_quietness/#11-load-the-envelope-lattice","text":"# loading the lowres lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) envelope_lattice = tg . lattice_from_csv ( lattice_path ) # loading the highres lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path )","title":"1.1. Load the Envelope Lattice"},{"location":"notebooks/3.2_lattice_quietness/#2-creation-of-noise-field","text":"","title":"2. Creation of Noise Field"},{"location":"notebooks/3.2_lattice_quietness/#21-computing-noise-lattices","text":"# create full lattice full_lattice = envelope_lattice * 0 + 1 # extract the coordiantes of the centroid of all voxel vox_centroids = full_lattice . centroids # extract voxel indices of all voxels vox_indices = np . array ( np . where ( full_lattice == 1 )) . T # setting the noise base pressure level noise_base = 75.0 # initializing the sum lattice of noise sum_noise_lats = envelope_lattice * 0.0 # for each source of noise for noise_src in noise_sources : # initialize the occupation lattice dist_latice = envelope_lattice * 0.0 for cen , ind in zip ( vox_centroids , vox_indices ): # compute the euclidian distance dist_latice [ tuple ( ind )] = sp . spatial . distance . euclidean ( cen , noise_src ) # computing the noise lattice from dist lattice noise_latice = noise_base - 20 * np . log10 ( dist_latice ) - 8 # summing sum_noise_lats += np . power ( 10 , noise_latice / 10.0 ) # computing the final aggregation agg_noise_lats = 10 * np . log10 ( sum_noise_lats )","title":"2.1. Computing noise lattices"},{"location":"notebooks/3.2_lattice_quietness/#22-store-noise-access-information-in-a-lattice","text":"# initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = agg_noise_lats # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Noise\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"coolwarm\" , opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) #Convert the noise distaqnces to a ratio agg_noise_ratio_lats = 1 - ( agg_noise_lats - np . min ( agg_noise_lats )) / ( np . max ( agg_noise_lats ) - np . min ( agg_noise_lats ))","title":"2.2. Store noise access information in a Lattice"},{"location":"notebooks/3.2_lattice_quietness/#3-interpolation","text":"def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice envelope_lattice = base_highres + 1 # sample points sample_points = envelope_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres noise_highres = interpolate ( agg_noise_ratio_lats , avail_lattice_highres ) # load the context and the envelope envelope_path = os . path . relpath ( \"../data/compulsory_envelope.obj\" ) context_path = os . path . relpath ( \"../data/immediate_context.obj\" ) # load the mesh from file envelope_mesh = tm . load ( envelope_path ) context_mesh = tm . load ( context_path ) # Check if the mesh is watertight print ( envelope_mesh . is_watertight ) print ( context_mesh . is_watertight )","title":"3. Interpolation"},{"location":"notebooks/3.2_lattice_quietness/#31-visualize-the-interpolated-noise","text":"# initiating the plotter p = pv . Plotter ( notebook = True ) vis_lattice = noise_highres # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = vis_lattice . shape # The bottom left corner of the data set grid . origin = vis_lattice . minbound # These are the cell sizes along each axis grid . spacing = vis_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"Noise Highress\" ] = vis_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 1.5 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1 ], opacity = opacity , shade = True ) # plotting p . show ( use_ipyvtk = True ) png_path = os . path . relpath ( '../screen/quietness.png' ) p . show ( screenshot = png_path )","title":"3.1. Visualize the interpolated noise"},{"location":"notebooks/3.2_lattice_quietness/#4-save-quietness-access-lattice-into-a-csv","text":"#select a path and a name to save the csv csv_path = os . path . relpath ( '../data/quietness_highres.csv' ) noise_highres . to_csv ( csv_path )","title":"4. Save Quietness Access Lattice into a CSV"},{"location":"notebooks/3.2_lattice_quietness/#credits","text":"__author__ = \"Shervin Azadi\" __editor__ = 'Siebren Meines' __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Noise interpolation calculation\"","title":"Credits"},{"location":"notebooks/3.3_lattice_public_entrances/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Distance Lattice Public Entrances In this document, The distance lattice is being generated for all possible public entrances: the voxels on ground level on the westside of the building. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator 0.2. Define the Neighborhood (Stencil) # creating neighborhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) print ( stencil ) 0.3. Load the envelope lattice as the avialbility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) p = pv . Plotter ( notebook = True ) # adding the avilability lattice init_avail_lattice . fast_vis ( p ) p . show ( use_ipyvtk = True ) 1. Distance Field Construction 1.1. Extract the connectivity graph from the lattice based on the defined stencil # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice full_lattice = avail_lattice * 0 + 1 avail_index = np . array ( np . where ( full_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx ) 1.2. Compute distances on the graph # compute the distance of all voxels to all voxels using floyd warshal algorithm dist_mtrx = nx . floyd_warshall_numpy ( g ) 1.3. Select the entrance voxel options for public space # create an empty lattice base_lattice = avail_lattice * 0 # select all entrance options; base_lattice [:, 0 , 0 ] = 1 base_flat = base_lattice . flatten () # make a list out of selected entrance options vox_interest = np . where ( base_flat == 1 ) 1.4. Construct Distance to Entrance Lattice ent_dist = dist_mtrx [ vox_interest ] #find the maximum valid value max_valid = np . ma . masked_invalid ( ent_dist ) . max () # set the infinities to one more than the maximum valid values ent_dist [ ent_dist == np . inf ] = max_valid + 1 min_dist = np . min ( ent_dist , axis = 0 ) # mapping the values from (0, max) to (1, 0) min_dist = 1 - min_dist / np . max ( min_dist ) # constructing the lattice ent_acc_lattice = tg . to_lattice ( min_dist . reshape ( avail_lattice . shape ), avail_lattice ) 1.5. Interpolate def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = base_highres + 1 # sample points sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres ent_acc_highres = interpolate ( ent_acc_lattice , avail_lattice_highres ) 1.6. Visualize and save the distance lattice # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Entrance Access\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/3.3_lattice_public_entrances.png' ) p . show ( screenshot = png_path ) 1.6. Save Entrance Access Lattice to CSV # save the entrance access lattice to csv csv_path = os . path . relpath ( '../data/ent_access_highres_public.csv' ) ent_acc_highres . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __co - editor__ = \"Eda Akaltun\" __co - editor__ = \"Siebren Meines\"","title":"Distance calculation, Public entrances"},{"location":"notebooks/3.3_lattice_public_entrances/#distance-lattice-public-entrances","text":"In this document, The distance lattice is being generated for all possible public entrances: the voxels on ground level on the westside of the building.","title":"Distance Lattice Public Entrances"},{"location":"notebooks/3.3_lattice_public_entrances/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/3.3_lattice_public_entrances/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator","title":"0.1. Load required libraries"},{"location":"notebooks/3.3_lattice_public_entrances/#02-define-the-neighborhood-stencil","text":"# creating neighborhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) print ( stencil )","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/3.3_lattice_public_entrances/#03-load-the-envelope-lattice-as-the-avialbility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) p = pv . Plotter ( notebook = True ) # adding the avilability lattice init_avail_lattice . fast_vis ( p ) p . show ( use_ipyvtk = True )","title":"0.3. Load the envelope lattice as the avialbility lattice"},{"location":"notebooks/3.3_lattice_public_entrances/#1-distance-field-construction","text":"","title":"1. Distance Field Construction"},{"location":"notebooks/3.3_lattice_public_entrances/#11-extract-the-connectivity-graph-from-the-lattice-based-on-the-defined-stencil","text":"# find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice full_lattice = avail_lattice * 0 + 1 avail_index = np . array ( np . where ( full_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx )","title":"1.1. Extract the connectivity graph from the lattice based on the defined stencil"},{"location":"notebooks/3.3_lattice_public_entrances/#12-compute-distances-on-the-graph","text":"# compute the distance of all voxels to all voxels using floyd warshal algorithm dist_mtrx = nx . floyd_warshall_numpy ( g )","title":"1.2. Compute distances on the graph"},{"location":"notebooks/3.3_lattice_public_entrances/#13-select-the-entrance-voxel-options-for-public-space","text":"# create an empty lattice base_lattice = avail_lattice * 0 # select all entrance options; base_lattice [:, 0 , 0 ] = 1 base_flat = base_lattice . flatten () # make a list out of selected entrance options vox_interest = np . where ( base_flat == 1 )","title":"1.3. Select the entrance voxel options for public space"},{"location":"notebooks/3.3_lattice_public_entrances/#14-construct-distance-to-entrance-lattice","text":"ent_dist = dist_mtrx [ vox_interest ] #find the maximum valid value max_valid = np . ma . masked_invalid ( ent_dist ) . max () # set the infinities to one more than the maximum valid values ent_dist [ ent_dist == np . inf ] = max_valid + 1 min_dist = np . min ( ent_dist , axis = 0 ) # mapping the values from (0, max) to (1, 0) min_dist = 1 - min_dist / np . max ( min_dist ) # constructing the lattice ent_acc_lattice = tg . to_lattice ( min_dist . reshape ( avail_lattice . shape ), avail_lattice )","title":"1.4. Construct Distance to Entrance Lattice"},{"location":"notebooks/3.3_lattice_public_entrances/#15-interpolate","text":"def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = base_highres + 1 # sample points sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres ent_acc_highres = interpolate ( ent_acc_lattice , avail_lattice_highres )","title":"1.5. Interpolate"},{"location":"notebooks/3.3_lattice_public_entrances/#16-visualize-and-save-the-distance-lattice","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Entrance Access\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/3.3_lattice_public_entrances.png' ) p . show ( screenshot = png_path )","title":"1.6. Visualize and save the distance lattice"},{"location":"notebooks/3.3_lattice_public_entrances/#16-save-entrance-access-lattice-to-csv","text":"# save the entrance access lattice to csv csv_path = os . path . relpath ( '../data/ent_access_highres_public.csv' ) ent_acc_highres . to_csv ( csv_path )","title":"1.6. Save Entrance Access Lattice to CSV"},{"location":"notebooks/3.3_lattice_public_entrances/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __co - editor__ = \"Eda Akaltun\" __co - editor__ = \"Siebren Meines\"","title":"Credits"},{"location":"notebooks/3.4_lattice_gym/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Distance Lattice Gym In this document, The distance lattice is being generated for all possible gym entrances: the voxels on ground level on the south side of the building. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator 0.2. Define the Neighborhood (Stencil) # creating neighborhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) print ( stencil ) 0.3. Load the envelope lattice as the avialbility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) p = pv . Plotter ( notebook = True ) # adding the avilability lattice init_avail_lattice . fast_vis ( p ) p . show ( use_ipyvtk = True ) 1. Distance Field Construction 1.1. Extract the connectivity graph from the lattice based on the defined stencil # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice full_lattice = avail_lattice * 0 + 1 avail_index = np . array ( np . where ( full_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx ) 1.2. Compute distances on the graph # compute the distance of all voxels to all voxels using floyd warshal algorithm dist_mtrx = nx . floyd_warshall_numpy ( g ) 1.3. Select the entrance voxel options for public space p = pv . Plotter ( notebook = True ) # initialize the selection lattice base_lattice = avail_lattice * 0 - 1 # init base flat base_flat = base_lattice . flatten () . astype ( int ) # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice init_avail_lattice . fast_vis ( p ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): i = int ( value ) # init base flat base_copy = np . copy ( base_lattice ) base_copy = base_copy * 0 - 1 base_copy [ - i , :, i ] = 0 base_new = base_copy grid . cell_arrays [ \"Selection\" ] = base_copy . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , 0.9 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) return p . add_slider_widget ( create_mesh , [ 0 , base_lattice . shape [ 1 ]], title = '1D Index' , value = 0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) # question: why do the selected voxels only change in diagonal direction? # question: why is it that it takes voxels outside the available lattice? 1.4. Construct Distance to Entrance Lattice # create an empty lattice base_lattice = avail_lattice * 0 # select all entrance options; base_lattice [ - 1 ,:, 0 ] = 1 base_flat = base_lattice . flatten () # make a list out of selected entrance options vox_interest = np . where ( base_flat == 1 ) ent_dist = dist_mtrx [ vox_interest ] #find the maximum valid value max_valid = np . ma . masked_invalid ( ent_dist ) . max () # set the infinities to one more than the maximum valid values ent_dist [ ent_dist == np . inf ] = max_valid + 1 min_dist = np . min ( ent_dist , axis = 0 ) # mapping the values from (0, max) to (1, 0) min_dist = 1 - min_dist / np . max ( min_dist ) # constructing the lattice ent_acc_lattice = tg . to_lattice ( min_dist . reshape ( avail_lattice . shape ), avail_lattice ) 1.5. Interpolation def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = base_highres + 1 # sample points sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres ent_acc_highres = interpolate ( ent_acc_lattice , avail_lattice_highres ) 1.6. Visualize and save the distance lattice # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Entrance Access\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/3.4_lattice_gym.png' ) p . show ( screenshot = png_path ) 1.7. Save Entrance Access Lattice to CSV # save the entrance access lattice to csv csv_path = os . path . relpath ( '../data/ent_access_highres_gym.csv' ) ent_acc_highres . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Distance calculation, Gym entrance"},{"location":"notebooks/3.4_lattice_gym/#distance-lattice-gym","text":"In this document, The distance lattice is being generated for all possible gym entrances: the voxels on ground level on the south side of the building.","title":"Distance Lattice Gym"},{"location":"notebooks/3.4_lattice_gym/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/3.4_lattice_gym/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator","title":"0.1. Load required libraries"},{"location":"notebooks/3.4_lattice_gym/#02-define-the-neighborhood-stencil","text":"# creating neighborhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) print ( stencil )","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/3.4_lattice_gym/#03-load-the-envelope-lattice-as-the-avialbility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) p = pv . Plotter ( notebook = True ) # adding the avilability lattice init_avail_lattice . fast_vis ( p ) p . show ( use_ipyvtk = True )","title":"0.3. Load the envelope lattice as the avialbility lattice"},{"location":"notebooks/3.4_lattice_gym/#1-distance-field-construction","text":"","title":"1. Distance Field Construction"},{"location":"notebooks/3.4_lattice_gym/#11-extract-the-connectivity-graph-from-the-lattice-based-on-the-defined-stencil","text":"# find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice full_lattice = avail_lattice * 0 + 1 avail_index = np . array ( np . where ( full_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx )","title":"1.1. Extract the connectivity graph from the lattice based on the defined stencil"},{"location":"notebooks/3.4_lattice_gym/#12-compute-distances-on-the-graph","text":"# compute the distance of all voxels to all voxels using floyd warshal algorithm dist_mtrx = nx . floyd_warshall_numpy ( g )","title":"1.2. Compute distances on the graph"},{"location":"notebooks/3.4_lattice_gym/#13-select-the-entrance-voxel-options-for-public-space","text":"p = pv . Plotter ( notebook = True ) # initialize the selection lattice base_lattice = avail_lattice * 0 - 1 # init base flat base_flat = base_lattice . flatten () . astype ( int ) # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice init_avail_lattice . fast_vis ( p ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): i = int ( value ) # init base flat base_copy = np . copy ( base_lattice ) base_copy = base_copy * 0 - 1 base_copy [ - i , :, i ] = 0 base_new = base_copy grid . cell_arrays [ \"Selection\" ] = base_copy . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , 0.9 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) return p . add_slider_widget ( create_mesh , [ 0 , base_lattice . shape [ 1 ]], title = '1D Index' , value = 0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) # question: why do the selected voxels only change in diagonal direction? # question: why is it that it takes voxels outside the available lattice?","title":"1.3. Select the entrance voxel options for public space"},{"location":"notebooks/3.4_lattice_gym/#14-construct-distance-to-entrance-lattice","text":"# create an empty lattice base_lattice = avail_lattice * 0 # select all entrance options; base_lattice [ - 1 ,:, 0 ] = 1 base_flat = base_lattice . flatten () # make a list out of selected entrance options vox_interest = np . where ( base_flat == 1 ) ent_dist = dist_mtrx [ vox_interest ] #find the maximum valid value max_valid = np . ma . masked_invalid ( ent_dist ) . max () # set the infinities to one more than the maximum valid values ent_dist [ ent_dist == np . inf ] = max_valid + 1 min_dist = np . min ( ent_dist , axis = 0 ) # mapping the values from (0, max) to (1, 0) min_dist = 1 - min_dist / np . max ( min_dist ) # constructing the lattice ent_acc_lattice = tg . to_lattice ( min_dist . reshape ( avail_lattice . shape ), avail_lattice )","title":"1.4. Construct Distance to Entrance Lattice"},{"location":"notebooks/3.4_lattice_gym/#15-interpolation","text":"def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = base_highres + 1 # sample points sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres ent_acc_highres = interpolate ( ent_acc_lattice , avail_lattice_highres )","title":"1.5. Interpolation"},{"location":"notebooks/3.4_lattice_gym/#16-visualize-and-save-the-distance-lattice","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Entrance Access\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/3.4_lattice_gym.png' ) p . show ( screenshot = png_path )","title":"1.6. Visualize and save the distance lattice"},{"location":"notebooks/3.4_lattice_gym/#17-save-entrance-access-lattice-to-csv","text":"# save the entrance access lattice to csv csv_path = os . path . relpath ( '../data/ent_access_highres_gym.csv' ) ent_acc_highres . to_csv ( csv_path )","title":"1.7. Save Entrance Access Lattice to CSV"},{"location":"notebooks/3.4_lattice_gym/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/3.5_lattice_parking_entrance/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Distance Lattice Parking Entrance In this document, The distance lattice is being generated for the Parking entrance: a chosen voxel that is located at the place where car presence has minimal influence on the public ambiance. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator 0.2. Define the Neighborhood (Stencil) # creating neighborhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) print ( stencil ) 0.3. Load the envelope lattice as the avialbility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) 1. Distance Field Construction 1.1. Extract the connectivity graph from the lattice based on the defined stencil # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice full_lattice = avail_lattice * 0 + 1 avail_index = np . array ( np . where ( full_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx ) 1.2. Compute distances on the graph # compute the distance of all voxels to all voxels using floyd warshal algorithm dist_mtrx = nx . floyd_warshall_numpy ( g ) 1.3. choose parking entrance voxel and normalize all distances # select the corresponding row in the matrix ent_park_dist = dist_mtrx [ 228 ] # find the maximum valid value max_valid = np . ma . masked_invalid ( ent_park_dist ) . max () # set the infinities to one more than the maximum valid values ent_park_dist [ ent_park_dist == np . inf ] = max_valid + 1 # mapping the values from (0, max) to (1, 0) ent_flat = 1 - ent_park_dist / np . max ( ent_park_dist ) # constructing the lattice ent_acc_lattice_park = tg . to_lattice ( ent_flat . reshape ( avail_lattice . shape ), avail_lattice ) 1.4. Interpolation def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = base_highres + 1 # sample points sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres ent_acc_highres = interpolate ( ent_acc_lattice_park , avail_lattice_highres ) 1.5. Visualize the distance lattice # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Entrance Access\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/3.5_lattice_parking_entrance.png' ) p . show ( screenshot = png_path ) 1.6. Save Entrance Access Lattice to CSV # save the entrance access lattice to csv csv_path = os . path . relpath ( '../data/ent_access_highres_parking.csv' ) ent_acc_highres . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Distance calculation, Parking entrance"},{"location":"notebooks/3.5_lattice_parking_entrance/#distance-lattice-parking-entrance","text":"In this document, The distance lattice is being generated for the Parking entrance: a chosen voxel that is located at the place where car presence has minimal influence on the public ambiance.","title":"Distance Lattice Parking Entrance"},{"location":"notebooks/3.5_lattice_parking_entrance/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/3.5_lattice_parking_entrance/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator","title":"0.1. Load required libraries"},{"location":"notebooks/3.5_lattice_parking_entrance/#02-define-the-neighborhood-stencil","text":"# creating neighborhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) print ( stencil )","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/3.5_lattice_parking_entrance/#03-load-the-envelope-lattice-as-the-avialbility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path )","title":"0.3. Load the envelope lattice as the avialbility lattice"},{"location":"notebooks/3.5_lattice_parking_entrance/#1-distance-field-construction","text":"","title":"1. Distance Field Construction"},{"location":"notebooks/3.5_lattice_parking_entrance/#11-extract-the-connectivity-graph-from-the-lattice-based-on-the-defined-stencil","text":"# find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice full_lattice = avail_lattice * 0 + 1 avail_index = np . array ( np . where ( full_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx )","title":"1.1. Extract the connectivity graph from the lattice based on the defined stencil"},{"location":"notebooks/3.5_lattice_parking_entrance/#12-compute-distances-on-the-graph","text":"# compute the distance of all voxels to all voxels using floyd warshal algorithm dist_mtrx = nx . floyd_warshall_numpy ( g )","title":"1.2. Compute distances on the graph"},{"location":"notebooks/3.5_lattice_parking_entrance/#13-choose-parking-entrance-voxel-and-normalize-all-distances","text":"# select the corresponding row in the matrix ent_park_dist = dist_mtrx [ 228 ] # find the maximum valid value max_valid = np . ma . masked_invalid ( ent_park_dist ) . max () # set the infinities to one more than the maximum valid values ent_park_dist [ ent_park_dist == np . inf ] = max_valid + 1 # mapping the values from (0, max) to (1, 0) ent_flat = 1 - ent_park_dist / np . max ( ent_park_dist ) # constructing the lattice ent_acc_lattice_park = tg . to_lattice ( ent_flat . reshape ( avail_lattice . shape ), avail_lattice )","title":"1.3. choose parking entrance voxel and normalize all distances"},{"location":"notebooks/3.5_lattice_parking_entrance/#14-interpolation","text":"def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = base_highres + 1 # sample points sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres ent_acc_highres = interpolate ( ent_acc_lattice_park , avail_lattice_highres )","title":"1.4. Interpolation"},{"location":"notebooks/3.5_lattice_parking_entrance/#15-visualize-the-distance-lattice","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Entrance Access\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/3.5_lattice_parking_entrance.png' ) p . show ( screenshot = png_path )","title":"1.5. Visualize the distance lattice"},{"location":"notebooks/3.5_lattice_parking_entrance/#16-save-entrance-access-lattice-to-csv","text":"# save the entrance access lattice to csv csv_path = os . path . relpath ( '../data/ent_access_highres_parking.csv' ) ent_acc_highres . to_csv ( csv_path )","title":"1.6. Save Entrance Access Lattice to CSV"},{"location":"notebooks/3.5_lattice_parking_entrance/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/3.6_lattice_housing/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Distance Lattice Housing Entrances In this document, The distance lattice is being generated for all possible housing entrances: chosen voxels on ground level that are practically located. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator 0.2. Define the Neighborhood (Stencil) # creating neighborhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) print ( stencil ) 0.3. Load the envelope lattice as the avialbility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) 1. Distance Field Construction 1.1. Extract the connectivity graph from the lattice based on the defined stencil # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice full_lattice = avail_lattice * 0 + 1 avail_index = np . array ( np . where ( full_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx ) 1.2. Compute distances on the graph # compute the distance of all voxels to all voxels using floyd warshal algorithm dist_mtrx = nx . floyd_warshall_numpy ( g ) 1.3. Construct distances to each housing entrance # select the corresponding row in the matrix ent_1_dist = dist_mtrx [ 136 ] # find the maximum valid value max_valid = np . ma . masked_invalid ( ent_1_dist ) . max () # set the infinities to one more than the maximum valid values ent_1_dist [ ent_1_dist == np . inf ] = max_valid + 1 # select the corresponding row in the matrix ent_2_dist = dist_mtrx [ 213 ] # find the maximum valid value max_valid = np . ma . masked_invalid ( ent_2_dist ) . max () # set the infinities to one more than the maximum valid values ent_2_dist [ ent_2_dist == np . inf ] = max_valid + 1 # select the corresponding row in the matrix ent_3_dist = dist_mtrx [ 223 ] # find the maximum valid value max_valid = np . ma . masked_invalid ( ent_3_dist ) . max () # set the infinities to one more than the maximum valid values ent_3_dist [ ent_3_dist == np . inf ] = max_valid + 1 1.4. Combining different distance fields # finding the shortest distance to one of the entrances for each voxel ent_dist_pt1 = np . minimum ( ent_1_dist , ent_2_dist ) dist_housing_ent = np . minimum ( ent_dist_pt1 , ent_3_dist ) # mapping the values from (0, max) to (1, 0) ent_flat = 1 - dist_housing_ent / np . max ( dist_housing_ent ) # constructing the lattice ent_acc_lattice = tg . to_lattice ( ent_flat . reshape ( avail_lattice . shape ), avail_lattice ) 1.5. Interpolation def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space - 1 , y_space - 1 , z_space - 1 ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = base_highres + 1 # sample points sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres ent_acc_highres = interpolate ( ent_acc_lattice , avail_lattice_highres ) # ent_acc_highres = ent_acc_lattice 1.6. Visualize the distance lattice # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Entrance Access\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/3.6_lattice_housing.png' ) p . show ( screenshot = png_path ) 1.7. Save Entrance Access Lattice to CSV # save the entrance access lattice to csv csv_path = os . path . relpath ( '../data/ent_access_highres_housing.csv' ) ent_acc_highres . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Distance calculation, Housing entrance"},{"location":"notebooks/3.6_lattice_housing/#distance-lattice-housing-entrances","text":"In this document, The distance lattice is being generated for all possible housing entrances: chosen voxels on ground level that are practically located.","title":"Distance Lattice Housing Entrances"},{"location":"notebooks/3.6_lattice_housing/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/3.6_lattice_housing/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator","title":"0.1. Load required libraries"},{"location":"notebooks/3.6_lattice_housing/#02-define-the-neighborhood-stencil","text":"# creating neighborhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) print ( stencil )","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/3.6_lattice_housing/#03-load-the-envelope-lattice-as-the-avialbility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path )","title":"0.3. Load the envelope lattice as the avialbility lattice"},{"location":"notebooks/3.6_lattice_housing/#1-distance-field-construction","text":"","title":"1. Distance Field Construction"},{"location":"notebooks/3.6_lattice_housing/#11-extract-the-connectivity-graph-from-the-lattice-based-on-the-defined-stencil","text":"# find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice full_lattice = avail_lattice * 0 + 1 avail_index = np . array ( np . where ( full_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx )","title":"1.1. Extract the connectivity graph from the lattice based on the defined stencil"},{"location":"notebooks/3.6_lattice_housing/#12-compute-distances-on-the-graph","text":"# compute the distance of all voxels to all voxels using floyd warshal algorithm dist_mtrx = nx . floyd_warshall_numpy ( g )","title":"1.2. Compute distances on the graph"},{"location":"notebooks/3.6_lattice_housing/#13-construct-distances-to-each-housing-entrance","text":"# select the corresponding row in the matrix ent_1_dist = dist_mtrx [ 136 ] # find the maximum valid value max_valid = np . ma . masked_invalid ( ent_1_dist ) . max () # set the infinities to one more than the maximum valid values ent_1_dist [ ent_1_dist == np . inf ] = max_valid + 1 # select the corresponding row in the matrix ent_2_dist = dist_mtrx [ 213 ] # find the maximum valid value max_valid = np . ma . masked_invalid ( ent_2_dist ) . max () # set the infinities to one more than the maximum valid values ent_2_dist [ ent_2_dist == np . inf ] = max_valid + 1 # select the corresponding row in the matrix ent_3_dist = dist_mtrx [ 223 ] # find the maximum valid value max_valid = np . ma . masked_invalid ( ent_3_dist ) . max () # set the infinities to one more than the maximum valid values ent_3_dist [ ent_3_dist == np . inf ] = max_valid + 1","title":"1.3. Construct distances to each housing entrance"},{"location":"notebooks/3.6_lattice_housing/#14-combining-different-distance-fields","text":"# finding the shortest distance to one of the entrances for each voxel ent_dist_pt1 = np . minimum ( ent_1_dist , ent_2_dist ) dist_housing_ent = np . minimum ( ent_dist_pt1 , ent_3_dist ) # mapping the values from (0, max) to (1, 0) ent_flat = 1 - dist_housing_ent / np . max ( dist_housing_ent ) # constructing the lattice ent_acc_lattice = tg . to_lattice ( ent_flat . reshape ( avail_lattice . shape ), avail_lattice )","title":"1.4. Combining different distance fields"},{"location":"notebooks/3.6_lattice_housing/#15-interpolation","text":"def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space - 1 , y_space - 1 , z_space - 1 ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = base_highres + 1 # sample points sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres ent_acc_highres = interpolate ( ent_acc_lattice , avail_lattice_highres ) # ent_acc_highres = ent_acc_lattice","title":"1.5. Interpolation"},{"location":"notebooks/3.6_lattice_housing/#16-visualize-the-distance-lattice","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Entrance Access\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/3.6_lattice_housing.png' ) p . show ( screenshot = png_path )","title":"1.6. Visualize the distance lattice"},{"location":"notebooks/3.6_lattice_housing/#17-save-entrance-access-lattice-to-csv","text":"# save the entrance access lattice to csv csv_path = os . path . relpath ( '../data/ent_access_highres_housing.csv' ) ent_acc_highres . to_csv ( csv_path )","title":"1.7. Save Entrance Access Lattice to CSV"},{"location":"notebooks/3.6_lattice_housing/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/3.7_lattice_comcen_entrance/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Distance Lattice Gym In this document, The distance lattice is being generated for all possible gym entrances: the voxels on ground level on the south side of the building. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator 0.2. Define the Neighborhood (Stencil) # creating neighborhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) print ( stencil ) 0.3. Load the envelope lattice as the avialbility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) init_avail_lattice_highres = tg . to_lattice ( np . copy ( avail_lattice_highres ), avail_lattice_highres ) p = pv . Plotter ( notebook = True ) # adding the avilability lattice init_avail_lattice_highres . fast_vis ( p ) p . show ( use_ipyvtk = True ) 1. Distance Field Construction 1.1. Extract the connectivity graph from the lattice based on the defined stencil # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice full_lattice = avail_lattice * 0 + 1 avail_index = np . array ( np . where ( full_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx ) 1.2. Compute distances on the graph # compute the distance of all voxels to all voxels using floyd warshal algorithm dist_mtrx = nx . floyd_warshall_numpy ( g ) 1.3. choose parking entrance voxel and normalize all distances # select the corresponding row in the matrix ent_park_dist = dist_mtrx [ 217 ] # find the maximum valid value max_valid = np . ma . masked_invalid ( ent_park_dist ) . max () # set the infinities to one more than the maximum valid values ent_park_dist [ ent_park_dist == np . inf ] = max_valid + 1 # mapping the values from (0, max) to (1, 0) ent_flat = 1 - ent_park_dist / np . max ( ent_park_dist ) # constructing the lattice ent_acc_lattice_park = tg . to_lattice ( ent_flat . reshape ( avail_lattice . shape ), avail_lattice ) 1.4. Interpolation def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = base_highres + 1 # sample points sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres ent_acc_highres = interpolate ( ent_acc_lattice_park , avail_lattice_highres ) 1.5. Visualize the distance lattice # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Entrance Access\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/3.7_lattice_comcen_entrance.png' ) p . show ( screenshot = png_path ) 1.6. Save Entrance Access Lattice to CSV # save the entrance access lattice to csv csv_path = os . path . relpath ( '../data/ent_access_highres_comcen.csv' ) ent_acc_highres . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Distance calculation, Comunity Center entrance"},{"location":"notebooks/3.7_lattice_comcen_entrance/#distance-lattice-gym","text":"In this document, The distance lattice is being generated for all possible gym entrances: the voxels on ground level on the south side of the building.","title":"Distance Lattice Gym"},{"location":"notebooks/3.7_lattice_comcen_entrance/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/3.7_lattice_comcen_entrance/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator","title":"0.1. Load required libraries"},{"location":"notebooks/3.7_lattice_comcen_entrance/#02-define-the-neighborhood-stencil","text":"# creating neighborhood definition stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero stencil . set_index ([ 0 , 0 , 0 ], 0 ) print ( stencil )","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/3.7_lattice_comcen_entrance/#03-load-the-envelope-lattice-as-the-avialbility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_lowres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice_highres = tg . lattice_from_csv ( lattice_path ) init_avail_lattice_highres = tg . to_lattice ( np . copy ( avail_lattice_highres ), avail_lattice_highres ) p = pv . Plotter ( notebook = True ) # adding the avilability lattice init_avail_lattice_highres . fast_vis ( p ) p . show ( use_ipyvtk = True )","title":"0.3. Load the envelope lattice as the avialbility lattice"},{"location":"notebooks/3.7_lattice_comcen_entrance/#1-distance-field-construction","text":"","title":"1. Distance Field Construction"},{"location":"notebooks/3.7_lattice_comcen_entrance/#11-extract-the-connectivity-graph-from-the-lattice-based-on-the-defined-stencil","text":"# find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_mtrx = np . zeros (( vox_count , vox_count )) # Finding the index of the available voxels in avail_lattice full_lattice = avail_lattice * 0 + 1 avail_index = np . array ( np . where ( full_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one adj_mtrx [ vox_id , neigh ] = 1.0 # construct the graph g = nx . from_numpy_array ( adj_mtrx )","title":"1.1. Extract the connectivity graph from the lattice based on the defined stencil"},{"location":"notebooks/3.7_lattice_comcen_entrance/#12-compute-distances-on-the-graph","text":"# compute the distance of all voxels to all voxels using floyd warshal algorithm dist_mtrx = nx . floyd_warshall_numpy ( g )","title":"1.2. Compute distances on the graph"},{"location":"notebooks/3.7_lattice_comcen_entrance/#13-choose-parking-entrance-voxel-and-normalize-all-distances","text":"# select the corresponding row in the matrix ent_park_dist = dist_mtrx [ 217 ] # find the maximum valid value max_valid = np . ma . masked_invalid ( ent_park_dist ) . max () # set the infinities to one more than the maximum valid values ent_park_dist [ ent_park_dist == np . inf ] = max_valid + 1 # mapping the values from (0, max) to (1, 0) ent_flat = 1 - ent_park_dist / np . max ( ent_park_dist ) # constructing the lattice ent_acc_lattice_park = tg . to_lattice ( ent_flat . reshape ( avail_lattice . shape ), avail_lattice )","title":"1.3. choose parking entrance voxel and normalize all distances"},{"location":"notebooks/3.7_lattice_comcen_entrance/#14-interpolation","text":"def interpolate ( info_lowres , base_highres ): # line spaces x_space = np . linspace ( info_lowres . minbound [ 0 ], info_lowres . maxbound [ 0 ], info_lowres . shape [ 0 ]) y_space = np . linspace ( info_lowres . minbound [ 1 ], info_lowres . maxbound [ 1 ], info_lowres . shape [ 1 ]) z_space = np . linspace ( info_lowres . minbound [ 2 ], info_lowres . maxbound [ 2 ], info_lowres . shape [ 2 ]) # interpolation function interpolating_function = RegularGridInterpolator (( x_space , y_space , z_space ), info_lowres , bounds_error = False , fill_value = None ) # high_res lattice full_lattice = base_highres + 1 # sample points sample_points = full_lattice . centroids # interpolation interpolated_values = interpolating_function ( sample_points ) # lattice construction info_highres = tg . to_lattice ( interpolated_values . reshape ( base_highres . shape ), base_highres ) # nulling the unavailable cells info_highres *= base_highres return info_highres ent_acc_highres = interpolate ( ent_acc_lattice_park , avail_lattice_highres )","title":"1.4. Interpolation"},{"location":"notebooks/3.7_lattice_comcen_entrance/#15-visualize-the-distance-lattice","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Entrance Access\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/3.7_lattice_comcen_entrance.png' ) p . show ( screenshot = png_path )","title":"1.5. Visualize the distance lattice"},{"location":"notebooks/3.7_lattice_comcen_entrance/#16-save-entrance-access-lattice-to-csv","text":"# save the entrance access lattice to csv csv_path = os . path . relpath ( '../data/ent_access_highres_comcen.csv' ) ent_acc_highres . to_csv ( csv_path )","title":"1.6. Save Entrance Access Lattice to CSV"},{"location":"notebooks/3.7_lattice_comcen_entrance/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/4_full_lattice_minus_greenery/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Defining valuable voxels for the building to select greenery In this notebook, all voxel values are being calculated, and the space for ground floor greenery is being determined based on where the voxels are of low value for the growht of the building. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import pandas as pd from sklearn.cluster import KMeans from scipy.interpolate import RegularGridInterpolator # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l 0.2. Define the Neighborhood (Stencil) # loading the lattice from csv sun_acc_path = os . path . relpath ( '../data/sun_access_highres.csv' ) sun_acc_lattice = lattice_from_csv ( sun_acc_path ) ent_acc_highres_public_path = os . path . relpath ( '../data/ent_access_highres_public.csv' ) ent_acc_public_lattice = lattice_from_csv ( ent_acc_highres_public_path ) ent_acc_highres_housing_path = os . path . relpath ( '../data/ent_access_highres_housing.csv' ) ent_acc_housing_lattice = lattice_from_csv ( ent_acc_highres_housing_path ) ent_acc_highres_gym_path = os . path . relpath ( '../data/ent_access_highres_gym.csv' ) ent_acc_gym_lattice = lattice_from_csv ( ent_acc_highres_gym_path ) ent_acc_highres_parking_path = os . path . relpath ( '../data/ent_access_highres_parking.csv' ) ent_acc_parking_lattice = lattice_from_csv ( ent_acc_highres_parking_path ) ent_acc_highres_comcen_path = os . path . relpath ( '../data/ent_access_highres_comcen.csv' ) ent_acc_comcen_lattice = lattice_from_csv ( ent_acc_highres_comcen_path ) highres_sky_acc_path = os . path . relpath ( '../data/sky_access_highres.csv' ) sky_acc_lattice = lattice_from_csv ( highres_sky_acc_path ) highres_groundfloor = os . path . relpath ( '../data/ent_access_highres_groundfloor.csv' ) groundfloor_lattice = lattice_from_csv ( highres_groundfloor ) # list the environment information layers (lattices) env_info = { \"sun_acc\" : sun_acc_lattice , \"ent_acc_public\" : ent_acc_public_lattice , \"ent_acc_housing\" : ent_acc_housing_lattice , \"ent_acc_gym\" : ent_acc_gym_lattice , \"ent_acc_parking\" : ent_acc_parking_lattice , \"ent_acc_comcen\" : ent_acc_comcen_lattice , \"sky_acc\" : sky_acc_lattice , \"ground_floor\" : groundfloor_lattice } 0.3. Load the envelope lattice as the avialbility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/new_shadremove_envelope_lattice.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) 1.1 calculating an average value lattice avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # initializing a sum lattice val_lattice = avail_lattice * 0.0 + 1.0 # adding all the value of all information lattices for key , info_lattice in env_info . items (): val_lattice *= info_lattice val_lattice *= avail_lattice 1.2. calculating a 2d space value, extract it to the full lattice and normalize # sum all values in z-axis to generate a value of distance_lattice = avail_lattice * 0.0 column_sum = np . sum ( val_lattice , axis = 2 ) # copy this 2d value to all voxels in z-value distance_lattice += column_sum [:, :, np . newaxis ] #find the maximum valid value max_valid = np . ma . masked_invalid ( distance_lattice ) . max () # mapping the values from (0, max) to (1, 0) values_normalized = distance_lattice / np . max ( distance_lattice ) 1.3. Visualize the distance lattice # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh base_lattice = values_normalized # load the mesh from file # context_path = os.path.relpath('../data/immediate_context.obj') # context_mesh = tm.load(context_path) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = base_lattice . shape # The bottom left corner of the data set grid . origin = base_lattice . minbound # These are the cell sizes along each axis grid . spacing = base_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"average voxel values\" ] = base_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes # p.add_mesh(tri_to_pv(context_mesh), opacity=0.1, style='wireframe') p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1 ] , opacity = opacity ) #saving and plotting png_path = os . path . relpath ( '../screenshots/4.2_new_avail_lattice.png' ) p . show ( screenshot = png_path ) 1.4. Determine a threshold for the growth model, where at least 30% of the groundfloor is excluded high_threshold = 1.0 # find the maximum of voxels that can be grown, keeping enough space for greenery needed_greenery_vox = 84 * 47 * 21 * 0.3 sum_vox = new_avail_lattice . size max_vox = sum_vox - needed_greenery_vox print ( max_vox ) low_threshold = 0.19 new_avail_lattice = (( values_normalized < high_threshold ) * ( values_normalized > low_threshold )) * avail_lattice avail_index = np . array ( np . where ( new_avail_lattice != 0.0 )) . T avail_index . size 1.5. visualize new availability lattice # convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # Visualize the voxelization using pyvista plotter ##### # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice new_avail_lattice . fast_vis ( p ) # # adding the base mesh: light blue # p.add_mesh(tri_to_pv(mesh), color='#abd8ff', opacity=0.1) #saving and plotting png_path = os . path . relpath ( '../screenshots/4.2_new_avail_lattice.png' ) p . show ( screenshot = png_path ) 1.6. Save Entrance Access Lattice to CSV # save the sun access latice to csv csv_path = os . path . relpath ( '../data/avail_lattice_good_voxels.csv' ) new_avail_lattice . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Full lattice"},{"location":"notebooks/4_full_lattice_minus_greenery/#defining-valuable-voxels-for-the-building-to-select-greenery","text":"In this notebook, all voxel values are being calculated, and the space for ground floor greenery is being determined based on where the voxels are of low value for the growht of the building.","title":"Defining valuable voxels for the building to select greenery"},{"location":"notebooks/4_full_lattice_minus_greenery/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/4_full_lattice_minus_greenery/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import pandas as pd from sklearn.cluster import KMeans from scipy.interpolate import RegularGridInterpolator # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l","title":"0.1. Load required libraries"},{"location":"notebooks/4_full_lattice_minus_greenery/#02-define-the-neighborhood-stencil","text":"# loading the lattice from csv sun_acc_path = os . path . relpath ( '../data/sun_access_highres.csv' ) sun_acc_lattice = lattice_from_csv ( sun_acc_path ) ent_acc_highres_public_path = os . path . relpath ( '../data/ent_access_highres_public.csv' ) ent_acc_public_lattice = lattice_from_csv ( ent_acc_highres_public_path ) ent_acc_highres_housing_path = os . path . relpath ( '../data/ent_access_highres_housing.csv' ) ent_acc_housing_lattice = lattice_from_csv ( ent_acc_highres_housing_path ) ent_acc_highres_gym_path = os . path . relpath ( '../data/ent_access_highres_gym.csv' ) ent_acc_gym_lattice = lattice_from_csv ( ent_acc_highres_gym_path ) ent_acc_highres_parking_path = os . path . relpath ( '../data/ent_access_highres_parking.csv' ) ent_acc_parking_lattice = lattice_from_csv ( ent_acc_highres_parking_path ) ent_acc_highres_comcen_path = os . path . relpath ( '../data/ent_access_highres_comcen.csv' ) ent_acc_comcen_lattice = lattice_from_csv ( ent_acc_highres_comcen_path ) highres_sky_acc_path = os . path . relpath ( '../data/sky_access_highres.csv' ) sky_acc_lattice = lattice_from_csv ( highres_sky_acc_path ) highres_groundfloor = os . path . relpath ( '../data/ent_access_highres_groundfloor.csv' ) groundfloor_lattice = lattice_from_csv ( highres_groundfloor ) # list the environment information layers (lattices) env_info = { \"sun_acc\" : sun_acc_lattice , \"ent_acc_public\" : ent_acc_public_lattice , \"ent_acc_housing\" : ent_acc_housing_lattice , \"ent_acc_gym\" : ent_acc_gym_lattice , \"ent_acc_parking\" : ent_acc_parking_lattice , \"ent_acc_comcen\" : ent_acc_comcen_lattice , \"sky_acc\" : sky_acc_lattice , \"ground_floor\" : groundfloor_lattice }","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/4_full_lattice_minus_greenery/#03-load-the-envelope-lattice-as-the-avialbility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/new_shadremove_envelope_lattice.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice )","title":"0.3. Load the envelope lattice as the avialbility lattice"},{"location":"notebooks/4_full_lattice_minus_greenery/#11-calculating-an-average-value-lattice","text":"avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # initializing a sum lattice val_lattice = avail_lattice * 0.0 + 1.0 # adding all the value of all information lattices for key , info_lattice in env_info . items (): val_lattice *= info_lattice val_lattice *= avail_lattice","title":"1.1 calculating an average value lattice"},{"location":"notebooks/4_full_lattice_minus_greenery/#12-calculating-a-2d-space-value-extract-it-to-the-full-lattice-and-normalize","text":"# sum all values in z-axis to generate a value of distance_lattice = avail_lattice * 0.0 column_sum = np . sum ( val_lattice , axis = 2 ) # copy this 2d value to all voxels in z-value distance_lattice += column_sum [:, :, np . newaxis ] #find the maximum valid value max_valid = np . ma . masked_invalid ( distance_lattice ) . max () # mapping the values from (0, max) to (1, 0) values_normalized = distance_lattice / np . max ( distance_lattice )","title":"1.2. calculating a 2d space value, extract it to the full lattice and normalize"},{"location":"notebooks/4_full_lattice_minus_greenery/#13-visualize-the-distance-lattice","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh base_lattice = values_normalized # load the mesh from file # context_path = os.path.relpath('../data/immediate_context.obj') # context_mesh = tm.load(context_path) # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = base_lattice . shape # The bottom left corner of the data set grid . origin = base_lattice . minbound # These are the cell sizes along each axis grid . spacing = base_lattice . unit # Add the data values to the cell data grid . point_arrays [ \"average voxel values\" ] = base_lattice . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes # p.add_mesh(tri_to_pv(context_mesh), opacity=0.1, style='wireframe') p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1 ] , opacity = opacity ) #saving and plotting png_path = os . path . relpath ( '../screenshots/4.2_new_avail_lattice.png' ) p . show ( screenshot = png_path )","title":"1.3. Visualize the distance lattice"},{"location":"notebooks/4_full_lattice_minus_greenery/#14-determine-a-threshold-for-the-growth-model-where-at-least-30-of-the-groundfloor-is-excluded","text":"high_threshold = 1.0 # find the maximum of voxels that can be grown, keeping enough space for greenery needed_greenery_vox = 84 * 47 * 21 * 0.3 sum_vox = new_avail_lattice . size max_vox = sum_vox - needed_greenery_vox print ( max_vox ) low_threshold = 0.19 new_avail_lattice = (( values_normalized < high_threshold ) * ( values_normalized > low_threshold )) * avail_lattice avail_index = np . array ( np . where ( new_avail_lattice != 0.0 )) . T avail_index . size","title":"1.4. Determine a threshold for the growth model, where at least 30% of the groundfloor is excluded"},{"location":"notebooks/4_full_lattice_minus_greenery/#15-visualize-new-availability-lattice","text":"# convert trimesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # Visualize the voxelization using pyvista plotter ##### # initiating the plotter p = pv . Plotter ( notebook = True ) # fast visualization of the lattice new_avail_lattice . fast_vis ( p ) # # adding the base mesh: light blue # p.add_mesh(tri_to_pv(mesh), color='#abd8ff', opacity=0.1) #saving and plotting png_path = os . path . relpath ( '../screenshots/4.2_new_avail_lattice.png' ) p . show ( screenshot = png_path )","title":"1.5. visualize new availability lattice"},{"location":"notebooks/4_full_lattice_minus_greenery/#16-save-entrance-access-lattice-to-csv","text":"# save the sun access latice to csv csv_path = os . path . relpath ( '../data/avail_lattice_good_voxels.csv' ) new_avail_lattice . to_csv ( csv_path )","title":"1.6. Save Entrance Access Lattice to CSV"},{"location":"notebooks/4_full_lattice_minus_greenery/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/5.1_corridors_groundfloor/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Corridor generation In this notebook, the location of the corridors is being generated based on the voxel seeds. This for the corridors on the groundfloor, that connect al communal functions and all housing entrances. The public functions have their own entrance on street level. For each function seed and the entrance location a shaft location is generated, and a connection is found to two of their closest shafts to generate a corridornetwork for this floor. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import pandas as pd import scipy as sp import pickle from sklearn.cluster import KMeans np . random . seed ( 0 ) import copy # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l 0.2. Define the Neighborhood (Stencil) # creating neighborhood definition s_1 = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_1 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_2 = tg . create_stencil ( \"von_neumann\" , 1 , 2 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) s_2 . set_index ([ 0 , 0 , 1 ], 0 ) s_2 . set_index ([ 0 , 0 , 2 ], 1 ) s_2 . set_index ([ 0 , 0 , - 1 ], 0 ) s_2 . set_index ([ 0 , 0 , - 2 ], 1 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_3 = tg . create_stencil ( \"von_neumann\" , 1 , 3 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) s_3 . set_index ([ 0 , 0 , 1 ], 0 ) s_3 . set_index ([ 0 , 0 , 3 ], 1 ) s_3 . set_index ([ 0 , 0 , - 1 ], 0 ) s_3 . set_index ([ 0 , 0 , - 3 ], 1 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_groundfloor = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_groundfloor . set_index ([ 0 , 0 , 0 ], 0 ) s_groundfloor . set_index ([ 0 , 0 , 1 ], 0 ) s_groundfloor . set_index ([ 0 , 0 , - 1 ], 0 ) stencils = [ s_1 , s_2 , s_3 , s_groundfloor ] h_stencil = s_groundfloor 0.3. Load the envelope lattice as the avialibility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/highres_envelope.csv' ) avail_lattice = lattice_from_csv ( lattice_path ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/avail_lattice_good_voxels.csv' ) avail_lattice_good_voxels = lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice_good_voxels ), avail_lattice_good_voxels ) avail_lattice *= avail_lattice_good_voxels 0.4. Load Agents Information # loading program (agents information) from CSV prgm_path = os . path . relpath ( '../data/program_exported.csv' ) agn_info = pd . read_csv ( '../data/program_exported.csv' , delimiter = \";\" ) agn_ids = agn_info [ \"space_id\" ] . values agn_prefs = agn_info a_pref = agn_prefs . loc [ 0 ] # Loading program information between agents from CSV matrix_path = os . path . relpath ( '../data/program_exported_matrix.csv' ) matrix_info = pd . read_csv ( '../data/program_exported_matrix.csv' , delimiter = \";\" ) matrix_ids = matrix_info [ \"space_id\" ] . values matrix_prefs = matrix_info 0.5. Initialize environment information layers from Sun Access Lattice and Entrance Access Lattice # loading the lattice from csv sun_acc_path = os . path . relpath ( '../data/sun_access_highres.csv' ) sun_acc_lattice = lattice_from_csv ( sun_acc_path ) ent_acc_highres_public_path = os . path . relpath ( '../data/ent_access_highres_public.csv' ) ent_acc_public_lattice = lattice_from_csv ( ent_acc_highres_public_path ) ent_acc_highres_housing_path = os . path . relpath ( '../data/ent_access_highres_housing.csv' ) ent_acc_housing_lattice = lattice_from_csv ( ent_acc_highres_housing_path ) ent_acc_highres_gym_path = os . path . relpath ( '../data/ent_access_highres_gym.csv' ) ent_acc_gym_lattice = lattice_from_csv ( ent_acc_highres_gym_path ) ent_acc_highres_parking_path = os . path . relpath ( '../data/ent_access_highres_parking.csv' ) ent_acc_parking_lattice = lattice_from_csv ( ent_acc_highres_parking_path ) ent_acc_highres_comcen_path = os . path . relpath ( '../data/ent_access_highres_comcen.csv' ) ent_acc_comcen_lattice = lattice_from_csv ( ent_acc_highres_comcen_path ) highres_sky_acc_path = os . path . relpath ( '../data/sky_access_highres.csv' ) sky_acc_lattice = lattice_from_csv ( highres_sky_acc_path ) highres_quietness_acc_path = os . path . relpath ( '../data/quietness_highres.csv' ) quietness_acc_lattice = lattice_from_csv ( highres_quietness_acc_path ) groundfloor_acc_path = os . path . relpath ( '../data/ent_access_highres_groundfloor.csv' ) groundfloor_acc_lattice = lattice_from_csv ( groundfloor_acc_path ) # list the environment information layers (lattices) env_info = { \"sun_acc\" : sun_acc_lattice + 0.001 , \"ent_acc_public\" : ent_acc_public_lattice + 0.001 , \"ent_acc_housing\" : ent_acc_housing_lattice + 0.001 , \"ent_acc_gym\" : ent_acc_gym_lattice + 0.001 , \"ent_acc_parking\" : ent_acc_parking_lattice + 0.001 , \"ent_acc_comcen\" : ent_acc_comcen_lattice + 0.001 , \"sky_acc\" : sky_acc_lattice + 0.001 , \"quietness_acc\" : quietness_acc_lattice + 0.001 , \"ground_floor_acc\" : groundfloor_acc_lattice + 0.001 } # defining other factors in csv # defining stencil id stencil_id = stencils # area to use in simulation room_area = [] # generate a list of all communal functions community = [] print ( agn_info [ \"ent_acc_comcen\" ] . values ) for i in agn_ids : if agn_info [ \"ent_acc_comcen\" ][ i ] == 1 : community . append ( agn_ids [ i ]) print ( community ) 1.1. initial agent localisation def check_avail ( avail_lattice , ind , a_stencil_id ): condition = 1 ind_array = np . array ( ind ) for step in range ( a_stencil_id + 1 ): new_ind_array = ind_array + np . array ([ 0 , 0 , step ]) condition *= avail_lattice [ tuple ( new_ind_array )] return condition def eval_voxel ( vox , env_info , a_pref ): global_vox_value = 1.0 # for every lattice in the environment informations for key , info_lattice in env_info . items (): # Here we utilise Fuzzy Logics to be able to compare different layers # of environmental information and evaluate the voxel for the agent. # This method is introduced, and generalised in Pirouz Nourian dissertation: # section 5.7.3, pp. 201-208, eq. 57. You can refer to this section for # comprehensive mathematical details. vox_val = info_lattice [ tuple ( vox )] agn_vox_val = np . power ( vox_val , a_pref [ key ]) global_vox_value *= agn_vox_val return global_vox_value def mult_occupation ( selected_vox_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = False ): for step in range ( a_height ): new_address = selected_vox_3d_address + np . array ([ 0 , 0 , step ]) if new_address [ 2 ] < occ_lattice . shape [ 2 ]: # make tuple of the address selected_vox_3d_id = tuple ( new_address ) # find the location of the newly selected voxel selected_vox_loc = np . array ( selected_vox_3d_id ) . flatten () if departure == False : # add the newly selected voxel location to agent locations agn_locs [ a_id ] . append ( selected_vox_loc ) if step == 0 : agn_src_locs [ a_id ] . append ( selected_vox_loc ) # set the newly selected voxel as UNavailable (0) in the availability lattice avail_lattice [ selected_vox_3d_id ] = 0 # set the newly selected voxel as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_vox_3d_id ] = a_id else : # remove the newly selected voxel location to agent locations a_locs_list = [ list ( loc ) for loc in agn_locs [ a_id ]] try : ind = a_locs_list . index ( list ( selected_vox_loc )) agn_locs [ a_id ] . pop ( ind ) # set the newly selected voxel as UNavailable (0) in the availability lattice avail_lattice [ selected_vox_3d_id ] = 1 # set the newly selected voxel as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_vox_3d_id ] = - 1 except : pass return ( agn_locs , agn_src_locs , occ_lattice , avail_lattice ) def find_voxels_masked ( lattice , stencil , loc ): vox_locs = np . argwhere ( stencil ) - stencil . origin + loc vox_filter = np . all ( vox_locs > 0 , axis = 1 ) * np . all ( vox_locs < np . array ( lattice . shape ), axis = 1 ) return ( vox_locs [ vox_filter ]) # initialize the occupation lattice occ_lattice = avail_lattice * 0 - 1 # Finding the index of the available voxels in avail_lattice avail_flat = avail_lattice . flatten () avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # count the number of spaces and intiialize an agent for each space agn_num = len ( agn_info ) # adding the origins to the agents locations agn_locs = [[] for a_id in agn_ids ] agn_src_locs = [[] for a_id in agn_ids ] agn_upper = [] # retrieving the initial location of each agent for a_id in community : voxel_vals = [] pot_voxels = [] # retrieve agent preferences a_pref = agn_prefs . loc [ a_id ] a_stencil_id = 0 stencil = stencils [ a_stencil_id ] # use avail_index voxel Evaluation Loop for pot_vox in avail_index : if check_avail ( avail_lattice , tuple ( pot_vox ), a_stencil_id ): # evaluate each voxel vox_value = eval_voxel ( pot_vox , env_info , a_pref ) # add the voxel value to the list of values voxel_vals . append ( vox_value ) pot_voxels . append ( pot_vox ) # convert voxel values to numpy array voxel_vals = np . array ( voxel_vals ) # convert potential voxels to numpy array pot_voxels = np . array ( pot_voxels ) # select the voxel with highest value selected_int = np . argmax ( voxel_vals ) # find 3D intiger index of selected voxel selected_vox_3d_address = tuple ( pot_voxels [ selected_int ] . T ) # find the location of the newly selected voxel agn_origins = np . array ( selected_vox_3d_address ) . flatten () # Occupy the newly selected voxel in the occupation lattice occ_lattice [ selected_vox_3d_address ] = 5 agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( selected_vox_3d_address , a_id , a_stencil_id + 1 , agn_locs , agn_src_locs , occ_lattice , avail_lattice ) # add entrance voxel to the occ_lattice occ_lattice [( 83 , 20 , 1 )] = 9 1.2. Visualizing the simulation p = pv . Plotter ( notebook = True ) base_lattice = occ_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) agn_num = len ( agn_info ) def create_mesh ( value ): f = int ( value ) lattice = base_lattice # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , 20 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) return p . add_slider_widget ( create_mesh , [ 0 , 1 ], title = 'Time' , value = 0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/5.1_voxel_seeds_groundfloor.png' ) p . show ( screenshot = png_path ) save the ground floor latice to csv csv_path = os.path.relpath('../data/voxel_seeds.csv') occ_lattice.to_csv(csv_path) 1.3. for each seed, generate a shaft location occupation_01_lattice = ( occ_lattice > - 1 ) . astype ( int ) # compute the sum over the columns to add weight to locations that might have multiple seeds above eachother column_sum = np . sum ( occupation_01_lattice , axis = 2 ) max_value_seeds = np . max ( column_sum ) filled_col_list = [] for i in range ( 1 , max_value_seeds + 1 ): # find adresses of columns column_adress = np . where ( column_sum == i ) filled_collumns = np . array ( column_adress ) . T filled_col_list . append ( filled_collumns ) fill_col_stacked = np . vstack ( filled_col_list ) clusters = len ( fill_col_stacked ) kmeans = KMeans ( n_clusters = clusters , random_state = 0 ) . fit ( fill_col_stacked ) col_labels = kmeans . labels_ cluster_centers = kmeans . cluster_centers_ # creating an empty occ lattice cluster_lattice = occ_lattice * 0 - 1 # iterating over each filled column for col , lab in zip ( fill_col_stacked , col_labels ): # setting the base of the column into the label value cluster_lattice [ col [ 0 ], col [ 1 ], :] = lab 1.5. Compute a distance graph rounded_cluster_centres = np . rint ( cluster_centers ) . astype ( int ) shaft_lattice = occ_lattice * 0 # iterating over each shaft for i , cen in enumerate ( rounded_cluster_centres ): shaft_lattice [ cen [ 0 ], cen [ 1 ], :] = i + 1 trimmed_shft_latice = shaft_lattice * init_avail_lattice # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_list = [] # Finding the index of the available voxels in avail_lattice avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # check whether it is in a shaft or not if shaft_lattice [ tuple ( vox_loc )] > 0 : # in case that specific voxel is in a shaft vox_stencil = stencil else : # in case that the voxel is a normal voxel vox_stencil = h_stencil # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( vox_stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one # adj_mtrx[vox_id, neigh] = 1.0 adj_list . append ([ 1.0 , vox_id , neigh ]) import scipy as sp adj_array = np . array ( adj_list ) adj_mtrx_sparse = sp . sparse . csr_matrix (( adj_array [:, 0 ],( adj_array [:, 1 ], adj_array [:, 2 ])), shape = ( vox_count , vox_count )) g = nx . from_scipy_sparse_matrix ( adj_mtrx_sparse ) 1.6. construct the corridors based on the shortest paths corridor_lattice = occ_lattice * 0 - 1 corr_flat = corridor_lattice . flatten () cor_groundfloor = shaft_lattice [:, :, 1 ] shaft_vox_inds = np . array ( np . where ( cor_groundfloor > 0 )) . T corr_latt_shape = corridor_lattice . shape all_shortest_paths = [] # find the shortest path between all locations to generate a corridor network for start_shaft in shaft_vox_inds : paths = [] path_lenghts = [] for dist_shaft_ind in shaft_vox_inds : # construct the destination adress src_vox = np . array ([ start_shaft [ 0 ], start_shaft [ 1 ], 2 ]) dst_vox = np . array ([ dist_shaft_ind [ 0 ], dist_shaft_ind [ 1 ], 2 ]) # construct 1-dimentional indices src_ind = np . ravel_multi_index ( src_vox , corr_latt_shape ) dst_ind = np . ravel_multi_index ( dst_vox , corr_latt_shape ) # find the shortest path try : path = nx . algorithms . shortest_paths . astar . astar_path ( g , src_ind , dst_ind ) if len ( path ) > 1 : paths . append ( path ) path_lenghts . append ( len ( path )) except : pass path_order = np . argsort ( np . array ( path_lenghts )) shortest_path = paths [ path_order [ 1 ]] all_shortest_paths . append ( paths ) corridor_lattice = corr_flat . reshape ( corridor_lattice . shape ) # copy the corridors to all voxels that should make use of these corridors (3 voxels heigh for first level, two voxels heigh for second level) for i , path in enumerate ( all_shortest_paths ): for cen in path : thrd_ind = np . unravel_index ( cen , corridor_lattice . shape ) corridor_lattice [ thrd_ind [ 0 ], thrd_ind [ 1 ], : 6 ] = 1 corridor_lattice [ thrd_ind [ 0 ], thrd_ind [ 1 ], 0 ] = - 1 p = pv . Plotter ( notebook = True ) base_lattice = corridor_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , 20 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) # p.add_slider_widget(create_mesh, [0, n_frames], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1)) p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/5.2_corridors_groundfloor.png' ) p . show ( screenshot = png_path ) 2.3. Saving lattice frames in CSV # save the ground floor latice to csv csv_path = os . path . relpath ( '../data/corridors_groundfloor.csv' ) corridor_lattice . to_csv ( csv_path ) import pickle lattice_pickle_path = os . path . relpath ( '../data/corridors_groundfloor.p' ) pickle . dump ( corridor_lattice , open ( lattice_pickle_path , \"wb\" )) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Corridors ground floor"},{"location":"notebooks/5.1_corridors_groundfloor/#corridor-generation","text":"In this notebook, the location of the corridors is being generated based on the voxel seeds. This for the corridors on the groundfloor, that connect al communal functions and all housing entrances. The public functions have their own entrance on street level. For each function seed and the entrance location a shaft location is generated, and a connection is found to two of their closest shafts to generate a corridornetwork for this floor.","title":"Corridor generation"},{"location":"notebooks/5.1_corridors_groundfloor/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/5.1_corridors_groundfloor/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import pandas as pd import scipy as sp import pickle from sklearn.cluster import KMeans np . random . seed ( 0 ) import copy # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l","title":"0.1. Load required libraries"},{"location":"notebooks/5.1_corridors_groundfloor/#02-define-the-neighborhood-stencil","text":"# creating neighborhood definition s_1 = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_1 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_2 = tg . create_stencil ( \"von_neumann\" , 1 , 2 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) s_2 . set_index ([ 0 , 0 , 1 ], 0 ) s_2 . set_index ([ 0 , 0 , 2 ], 1 ) s_2 . set_index ([ 0 , 0 , - 1 ], 0 ) s_2 . set_index ([ 0 , 0 , - 2 ], 1 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_3 = tg . create_stencil ( \"von_neumann\" , 1 , 3 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) s_3 . set_index ([ 0 , 0 , 1 ], 0 ) s_3 . set_index ([ 0 , 0 , 3 ], 1 ) s_3 . set_index ([ 0 , 0 , - 1 ], 0 ) s_3 . set_index ([ 0 , 0 , - 3 ], 1 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_groundfloor = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_groundfloor . set_index ([ 0 , 0 , 0 ], 0 ) s_groundfloor . set_index ([ 0 , 0 , 1 ], 0 ) s_groundfloor . set_index ([ 0 , 0 , - 1 ], 0 ) stencils = [ s_1 , s_2 , s_3 , s_groundfloor ] h_stencil = s_groundfloor","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/5.1_corridors_groundfloor/#03-load-the-envelope-lattice-as-the-avialibility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/highres_envelope.csv' ) avail_lattice = lattice_from_csv ( lattice_path ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/avail_lattice_good_voxels.csv' ) avail_lattice_good_voxels = lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice_good_voxels ), avail_lattice_good_voxels ) avail_lattice *= avail_lattice_good_voxels","title":"0.3. Load the envelope lattice as the avialibility lattice"},{"location":"notebooks/5.1_corridors_groundfloor/#04-load-agents-information","text":"# loading program (agents information) from CSV prgm_path = os . path . relpath ( '../data/program_exported.csv' ) agn_info = pd . read_csv ( '../data/program_exported.csv' , delimiter = \";\" ) agn_ids = agn_info [ \"space_id\" ] . values agn_prefs = agn_info a_pref = agn_prefs . loc [ 0 ] # Loading program information between agents from CSV matrix_path = os . path . relpath ( '../data/program_exported_matrix.csv' ) matrix_info = pd . read_csv ( '../data/program_exported_matrix.csv' , delimiter = \";\" ) matrix_ids = matrix_info [ \"space_id\" ] . values matrix_prefs = matrix_info","title":"0.4. Load Agents Information"},{"location":"notebooks/5.1_corridors_groundfloor/#05-initialize-environment-information-layers-from-sun-access-lattice-and-entrance-access-lattice","text":"# loading the lattice from csv sun_acc_path = os . path . relpath ( '../data/sun_access_highres.csv' ) sun_acc_lattice = lattice_from_csv ( sun_acc_path ) ent_acc_highres_public_path = os . path . relpath ( '../data/ent_access_highres_public.csv' ) ent_acc_public_lattice = lattice_from_csv ( ent_acc_highres_public_path ) ent_acc_highres_housing_path = os . path . relpath ( '../data/ent_access_highres_housing.csv' ) ent_acc_housing_lattice = lattice_from_csv ( ent_acc_highres_housing_path ) ent_acc_highres_gym_path = os . path . relpath ( '../data/ent_access_highres_gym.csv' ) ent_acc_gym_lattice = lattice_from_csv ( ent_acc_highres_gym_path ) ent_acc_highres_parking_path = os . path . relpath ( '../data/ent_access_highres_parking.csv' ) ent_acc_parking_lattice = lattice_from_csv ( ent_acc_highres_parking_path ) ent_acc_highres_comcen_path = os . path . relpath ( '../data/ent_access_highres_comcen.csv' ) ent_acc_comcen_lattice = lattice_from_csv ( ent_acc_highres_comcen_path ) highres_sky_acc_path = os . path . relpath ( '../data/sky_access_highres.csv' ) sky_acc_lattice = lattice_from_csv ( highres_sky_acc_path ) highres_quietness_acc_path = os . path . relpath ( '../data/quietness_highres.csv' ) quietness_acc_lattice = lattice_from_csv ( highres_quietness_acc_path ) groundfloor_acc_path = os . path . relpath ( '../data/ent_access_highres_groundfloor.csv' ) groundfloor_acc_lattice = lattice_from_csv ( groundfloor_acc_path ) # list the environment information layers (lattices) env_info = { \"sun_acc\" : sun_acc_lattice + 0.001 , \"ent_acc_public\" : ent_acc_public_lattice + 0.001 , \"ent_acc_housing\" : ent_acc_housing_lattice + 0.001 , \"ent_acc_gym\" : ent_acc_gym_lattice + 0.001 , \"ent_acc_parking\" : ent_acc_parking_lattice + 0.001 , \"ent_acc_comcen\" : ent_acc_comcen_lattice + 0.001 , \"sky_acc\" : sky_acc_lattice + 0.001 , \"quietness_acc\" : quietness_acc_lattice + 0.001 , \"ground_floor_acc\" : groundfloor_acc_lattice + 0.001 } # defining other factors in csv # defining stencil id stencil_id = stencils # area to use in simulation room_area = [] # generate a list of all communal functions community = [] print ( agn_info [ \"ent_acc_comcen\" ] . values ) for i in agn_ids : if agn_info [ \"ent_acc_comcen\" ][ i ] == 1 : community . append ( agn_ids [ i ]) print ( community )","title":"0.5. Initialize environment information layers from Sun Access Lattice and Entrance Access Lattice"},{"location":"notebooks/5.1_corridors_groundfloor/#11-initial-agent-localisation","text":"def check_avail ( avail_lattice , ind , a_stencil_id ): condition = 1 ind_array = np . array ( ind ) for step in range ( a_stencil_id + 1 ): new_ind_array = ind_array + np . array ([ 0 , 0 , step ]) condition *= avail_lattice [ tuple ( new_ind_array )] return condition def eval_voxel ( vox , env_info , a_pref ): global_vox_value = 1.0 # for every lattice in the environment informations for key , info_lattice in env_info . items (): # Here we utilise Fuzzy Logics to be able to compare different layers # of environmental information and evaluate the voxel for the agent. # This method is introduced, and generalised in Pirouz Nourian dissertation: # section 5.7.3, pp. 201-208, eq. 57. You can refer to this section for # comprehensive mathematical details. vox_val = info_lattice [ tuple ( vox )] agn_vox_val = np . power ( vox_val , a_pref [ key ]) global_vox_value *= agn_vox_val return global_vox_value def mult_occupation ( selected_vox_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = False ): for step in range ( a_height ): new_address = selected_vox_3d_address + np . array ([ 0 , 0 , step ]) if new_address [ 2 ] < occ_lattice . shape [ 2 ]: # make tuple of the address selected_vox_3d_id = tuple ( new_address ) # find the location of the newly selected voxel selected_vox_loc = np . array ( selected_vox_3d_id ) . flatten () if departure == False : # add the newly selected voxel location to agent locations agn_locs [ a_id ] . append ( selected_vox_loc ) if step == 0 : agn_src_locs [ a_id ] . append ( selected_vox_loc ) # set the newly selected voxel as UNavailable (0) in the availability lattice avail_lattice [ selected_vox_3d_id ] = 0 # set the newly selected voxel as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_vox_3d_id ] = a_id else : # remove the newly selected voxel location to agent locations a_locs_list = [ list ( loc ) for loc in agn_locs [ a_id ]] try : ind = a_locs_list . index ( list ( selected_vox_loc )) agn_locs [ a_id ] . pop ( ind ) # set the newly selected voxel as UNavailable (0) in the availability lattice avail_lattice [ selected_vox_3d_id ] = 1 # set the newly selected voxel as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_vox_3d_id ] = - 1 except : pass return ( agn_locs , agn_src_locs , occ_lattice , avail_lattice ) def find_voxels_masked ( lattice , stencil , loc ): vox_locs = np . argwhere ( stencil ) - stencil . origin + loc vox_filter = np . all ( vox_locs > 0 , axis = 1 ) * np . all ( vox_locs < np . array ( lattice . shape ), axis = 1 ) return ( vox_locs [ vox_filter ]) # initialize the occupation lattice occ_lattice = avail_lattice * 0 - 1 # Finding the index of the available voxels in avail_lattice avail_flat = avail_lattice . flatten () avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # count the number of spaces and intiialize an agent for each space agn_num = len ( agn_info ) # adding the origins to the agents locations agn_locs = [[] for a_id in agn_ids ] agn_src_locs = [[] for a_id in agn_ids ] agn_upper = [] # retrieving the initial location of each agent for a_id in community : voxel_vals = [] pot_voxels = [] # retrieve agent preferences a_pref = agn_prefs . loc [ a_id ] a_stencil_id = 0 stencil = stencils [ a_stencil_id ] # use avail_index voxel Evaluation Loop for pot_vox in avail_index : if check_avail ( avail_lattice , tuple ( pot_vox ), a_stencil_id ): # evaluate each voxel vox_value = eval_voxel ( pot_vox , env_info , a_pref ) # add the voxel value to the list of values voxel_vals . append ( vox_value ) pot_voxels . append ( pot_vox ) # convert voxel values to numpy array voxel_vals = np . array ( voxel_vals ) # convert potential voxels to numpy array pot_voxels = np . array ( pot_voxels ) # select the voxel with highest value selected_int = np . argmax ( voxel_vals ) # find 3D intiger index of selected voxel selected_vox_3d_address = tuple ( pot_voxels [ selected_int ] . T ) # find the location of the newly selected voxel agn_origins = np . array ( selected_vox_3d_address ) . flatten () # Occupy the newly selected voxel in the occupation lattice occ_lattice [ selected_vox_3d_address ] = 5 agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( selected_vox_3d_address , a_id , a_stencil_id + 1 , agn_locs , agn_src_locs , occ_lattice , avail_lattice ) # add entrance voxel to the occ_lattice occ_lattice [( 83 , 20 , 1 )] = 9","title":"1.1. initial agent localisation"},{"location":"notebooks/5.1_corridors_groundfloor/#12-visualizing-the-simulation","text":"p = pv . Plotter ( notebook = True ) base_lattice = occ_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) agn_num = len ( agn_info ) def create_mesh ( value ): f = int ( value ) lattice = base_lattice # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , 20 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) return p . add_slider_widget ( create_mesh , [ 0 , 1 ], title = 'Time' , value = 0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/5.1_voxel_seeds_groundfloor.png' ) p . show ( screenshot = png_path ) save the ground floor latice to csv csv_path = os.path.relpath('../data/voxel_seeds.csv') occ_lattice.to_csv(csv_path)","title":"1.2. Visualizing the simulation"},{"location":"notebooks/5.1_corridors_groundfloor/#13-for-each-seed-generate-a-shaft-location","text":"occupation_01_lattice = ( occ_lattice > - 1 ) . astype ( int ) # compute the sum over the columns to add weight to locations that might have multiple seeds above eachother column_sum = np . sum ( occupation_01_lattice , axis = 2 ) max_value_seeds = np . max ( column_sum ) filled_col_list = [] for i in range ( 1 , max_value_seeds + 1 ): # find adresses of columns column_adress = np . where ( column_sum == i ) filled_collumns = np . array ( column_adress ) . T filled_col_list . append ( filled_collumns ) fill_col_stacked = np . vstack ( filled_col_list ) clusters = len ( fill_col_stacked ) kmeans = KMeans ( n_clusters = clusters , random_state = 0 ) . fit ( fill_col_stacked ) col_labels = kmeans . labels_ cluster_centers = kmeans . cluster_centers_ # creating an empty occ lattice cluster_lattice = occ_lattice * 0 - 1 # iterating over each filled column for col , lab in zip ( fill_col_stacked , col_labels ): # setting the base of the column into the label value cluster_lattice [ col [ 0 ], col [ 1 ], :] = lab","title":"1.3. for each seed, generate a shaft location"},{"location":"notebooks/5.1_corridors_groundfloor/#15-compute-a-distance-graph","text":"rounded_cluster_centres = np . rint ( cluster_centers ) . astype ( int ) shaft_lattice = occ_lattice * 0 # iterating over each shaft for i , cen in enumerate ( rounded_cluster_centres ): shaft_lattice [ cen [ 0 ], cen [ 1 ], :] = i + 1 trimmed_shft_latice = shaft_lattice * init_avail_lattice # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_list = [] # Finding the index of the available voxels in avail_lattice avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # check whether it is in a shaft or not if shaft_lattice [ tuple ( vox_loc )] > 0 : # in case that specific voxel is in a shaft vox_stencil = stencil else : # in case that the voxel is a normal voxel vox_stencil = h_stencil # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( vox_stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one # adj_mtrx[vox_id, neigh] = 1.0 adj_list . append ([ 1.0 , vox_id , neigh ]) import scipy as sp adj_array = np . array ( adj_list ) adj_mtrx_sparse = sp . sparse . csr_matrix (( adj_array [:, 0 ],( adj_array [:, 1 ], adj_array [:, 2 ])), shape = ( vox_count , vox_count )) g = nx . from_scipy_sparse_matrix ( adj_mtrx_sparse )","title":"1.5. Compute a distance graph"},{"location":"notebooks/5.1_corridors_groundfloor/#16-construct-the-corridors-based-on-the-shortest-paths","text":"corridor_lattice = occ_lattice * 0 - 1 corr_flat = corridor_lattice . flatten () cor_groundfloor = shaft_lattice [:, :, 1 ] shaft_vox_inds = np . array ( np . where ( cor_groundfloor > 0 )) . T corr_latt_shape = corridor_lattice . shape all_shortest_paths = [] # find the shortest path between all locations to generate a corridor network for start_shaft in shaft_vox_inds : paths = [] path_lenghts = [] for dist_shaft_ind in shaft_vox_inds : # construct the destination adress src_vox = np . array ([ start_shaft [ 0 ], start_shaft [ 1 ], 2 ]) dst_vox = np . array ([ dist_shaft_ind [ 0 ], dist_shaft_ind [ 1 ], 2 ]) # construct 1-dimentional indices src_ind = np . ravel_multi_index ( src_vox , corr_latt_shape ) dst_ind = np . ravel_multi_index ( dst_vox , corr_latt_shape ) # find the shortest path try : path = nx . algorithms . shortest_paths . astar . astar_path ( g , src_ind , dst_ind ) if len ( path ) > 1 : paths . append ( path ) path_lenghts . append ( len ( path )) except : pass path_order = np . argsort ( np . array ( path_lenghts )) shortest_path = paths [ path_order [ 1 ]] all_shortest_paths . append ( paths ) corridor_lattice = corr_flat . reshape ( corridor_lattice . shape ) # copy the corridors to all voxels that should make use of these corridors (3 voxels heigh for first level, two voxels heigh for second level) for i , path in enumerate ( all_shortest_paths ): for cen in path : thrd_ind = np . unravel_index ( cen , corridor_lattice . shape ) corridor_lattice [ thrd_ind [ 0 ], thrd_ind [ 1 ], : 6 ] = 1 corridor_lattice [ thrd_ind [ 0 ], thrd_ind [ 1 ], 0 ] = - 1 p = pv . Plotter ( notebook = True ) base_lattice = corridor_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , 20 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) # p.add_slider_widget(create_mesh, [0, n_frames], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1)) p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/5.2_corridors_groundfloor.png' ) p . show ( screenshot = png_path )","title":"1.6. construct the corridors based on the shortest paths"},{"location":"notebooks/5.1_corridors_groundfloor/#23-saving-lattice-frames-in-csv","text":"# save the ground floor latice to csv csv_path = os . path . relpath ( '../data/corridors_groundfloor.csv' ) corridor_lattice . to_csv ( csv_path ) import pickle lattice_pickle_path = os . path . relpath ( '../data/corridors_groundfloor.p' ) pickle . dump ( corridor_lattice , open ( lattice_pickle_path , \"wb\" ))","title":"2.3. Saving lattice frames in CSV"},{"location":"notebooks/5.1_corridors_groundfloor/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/5.2_corridors_upper_floors/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Corridor generation In this notebook, the location of the corridors is being generated based on the voxel seeds of the functions that grow above the first two levels. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import pandas as pd from sklearn.cluster import KMeans import pickle np . random . seed ( 0 ) import copy # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l 0.2. Define the Neighborhood (Stencil) # creating neighborhood definition s_1 = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_1 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_2 = tg . create_stencil ( \"von_neumann\" , 1 , 2 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) s_2 . set_index ([ 0 , 0 , 1 ], 0 ) s_2 . set_index ([ 0 , 0 , 2 ], 1 ) s_2 . set_index ([ 0 , 0 , - 1 ], 0 ) s_2 . set_index ([ 0 , 0 , - 2 ], 1 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_3 = tg . create_stencil ( \"von_neumann\" , 1 , 3 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) s_3 . set_index ([ 0 , 0 , 1 ], 0 ) s_3 . set_index ([ 0 , 0 , 3 ], 1 ) s_3 . set_index ([ 0 , 0 , - 1 ], 0 ) s_3 . set_index ([ 0 , 0 , - 3 ], 1 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_groundfloor = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_groundfloor . set_index ([ 0 , 0 , 0 ], 0 ) s_groundfloor . set_index ([ 0 , 0 , 1 ], 0 ) s_groundfloor . set_index ([ 0 , 0 , - 1 ], 0 ) stencils = [ s_1 , s_2 , s_3 , s_groundfloor ] h_stencil = s_groundfloor 0.3. Load the envelope lattice as the avialibility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/highres_envelope.csv' ) avail_lattice = lattice_from_csv ( lattice_path ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/avail_lattice_good_voxels.csv' ) avail_lattice_good_voxels = lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice_good_voxels ), avail_lattice_good_voxels ) avail_lattice *= avail_lattice_good_voxels 0.4. Load Agents Information # loading program (agents information) from CSV prgm_path = os . path . relpath ( '../data/program_exported.csv' ) agn_info = pd . read_csv ( '../data/program_exported.csv' , delimiter = \";\" ) agn_ids = agn_info [ \"space_id\" ] . values agn_prefs = agn_info a_pref = agn_prefs . loc [ 0 ] high_level = [] print ( agn_info [ \"ground_floor\" ] . values ) for i in agn_ids : if agn_info [ \"ground_floor\" ][ i ] == 0 : high_level . append ( agn_ids [ i ]) print ( high_level ) # Loading program information between agents from CSV matrix_path = os . path . relpath ( '../data/program_exported_matrix.csv' ) matrix_info = pd . read_csv ( '../data/program_exported_matrix.csv' , delimiter = \";\" ) matrix_ids = matrix_info [ \"space_id\" ] . values matrix_prefs = matrix_info 0.5. Initialize environment information layers from Sun Access Lattice and Entrance Access Lattice # loading the lattice from csv sun_acc_path = os . path . relpath ( '../data/sun_access_highres.csv' ) sun_acc_lattice = lattice_from_csv ( sun_acc_path ) ent_acc_highres_public_path = os . path . relpath ( '../data/ent_access_highres_public.csv' ) ent_acc_public_lattice = lattice_from_csv ( ent_acc_highres_public_path ) ent_acc_highres_housing_path = os . path . relpath ( '../data/ent_access_highres_housing.csv' ) ent_acc_housing_lattice = lattice_from_csv ( ent_acc_highres_housing_path ) ent_acc_highres_gym_path = os . path . relpath ( '../data/ent_access_highres_gym.csv' ) ent_acc_gym_lattice = lattice_from_csv ( ent_acc_highres_gym_path ) ent_acc_highres_parking_path = os . path . relpath ( '../data/ent_access_highres_parking.csv' ) ent_acc_parking_lattice = lattice_from_csv ( ent_acc_highres_parking_path ) ent_acc_highres_comcen_path = os . path . relpath ( '../data/ent_access_highres_comcen.csv' ) ent_acc_comcen_lattice = lattice_from_csv ( ent_acc_highres_comcen_path ) highres_sky_acc_path = os . path . relpath ( '../data/sky_access_highres.csv' ) sky_acc_lattice = lattice_from_csv ( highres_sky_acc_path ) highres_quietness_acc_path = os . path . relpath ( '../data/quietness_highres.csv' ) quietness_acc_lattice = lattice_from_csv ( highres_quietness_acc_path ) groundfloor_acc_path = os . path . relpath ( '../data/ent_access_highres_groundfloor.csv' ) groundfloor_acc_lattice = lattice_from_csv ( groundfloor_acc_path ) # list the environment information layers (lattices) env_info = { \"sun_acc\" : sun_acc_lattice + 0.001 , \"ent_acc_public\" : ent_acc_public_lattice + 0.001 , \"ent_acc_housing\" : ent_acc_housing_lattice + 0.001 , \"ent_acc_gym\" : ent_acc_gym_lattice + 0.001 , \"ent_acc_parking\" : ent_acc_parking_lattice + 0.001 , \"ent_acc_comcen\" : ent_acc_comcen_lattice + 0.001 , \"sky_acc\" : sky_acc_lattice + 0.001 , \"quietness_acc\" : quietness_acc_lattice + 0.001 , \"ground_floor_acc\" : groundfloor_acc_lattice + 0.001 } # defining stencil id stencil_id = stencils # area to use in simulation room_area = [] 1.1. Initial agent localisation def check_avail ( avail_lattice , ind , a_stencil_id ): condition = 1 ind_array = np . array ( ind ) for step in range ( a_stencil_id + 1 ): new_ind_array = ind_array + np . array ([ 0 , 0 , step ]) condition *= avail_lattice [ tuple ( new_ind_array )] return condition def eval_voxel ( vox , env_info , a_pref ): global_vox_value = 1.0 # for every lattice in the environment informations for key , info_lattice in env_info . items (): # Here we utilise Fuzzy Logics to be able to compare different layers # of environmental information and evaluate the voxel for the agent. # This method is introduced, and generalised in Pirouz Nourian dissertation: # section 5.7.3, pp. 201-208, eq. 57. You can refer to this section for # comprehensive mathematical details. vox_val = info_lattice [ tuple ( vox )] agn_vox_val = np . power ( vox_val , a_pref [ key ]) global_vox_value *= agn_vox_val return global_vox_value def mult_occupation ( selected_neigh_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = False ): for step in range ( a_height ): new_address = selected_neigh_3d_address + np . array ([ 0 , 0 , step ]) if new_address [ 2 ] < occ_lattice . shape [ 2 ]: # make tuple of the address selected_neigh_3d_id = tuple ( new_address ) # find the location of the newly selected neighbour selected_neigh_loc = np . array ( selected_neigh_3d_id ) . flatten () if departure == False : # add the newly selected neighbour location to agent locations agn_locs [ a_id ] . append ( selected_neigh_loc ) if step == 0 : agn_src_locs [ a_id ] . append ( selected_neigh_loc ) # set the newly selected neighbour as UNavailable (0) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 0 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_neigh_3d_id ] = a_id else : # remove the newly selected neighbour location to agent locations a_locs_list = [ list ( loc ) for loc in agn_locs [ a_id ]] try : ind = a_locs_list . index ( list ( selected_neigh_loc )) agn_locs [ a_id ] . pop ( ind ) # set the newly selected neighbour as UNavailable (0) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 1 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_neigh_3d_id ] = - 1 except : pass return ( agn_locs , agn_src_locs , occ_lattice , avail_lattice ) def find_neighbours_masked ( lattice , stencil , loc ): neigh_locs = np . argwhere ( stencil ) - stencil . origin + loc neigh_filter = np . all ( neigh_locs > 0 , axis = 1 ) * np . all ( neigh_locs < np . array ( lattice . shape ), axis = 1 ) return ( neigh_locs [ neigh_filter ]) # initialize the occupation lattice occ_lattice = avail_lattice * 0 - 1 # Finding the index of the available voxels in avail_lattice avail_flat = avail_lattice . flatten () avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # count the number of spaces and intiialize an agent for each space agn_num = len ( agn_info ) # adding the origins to the agents locations agn_locs = [[] for a_id in agn_ids ] agn_src_locs = [[] for a_id in agn_ids ] agn_upper = [] # retrieving the initial location of each agent for a_id in high_level : voxel_vals = [] pot_voxels = [] # retrieve agent preferences a_pref = agn_prefs . loc [ a_id ] a_stencil_id = 0 stencil = stencils [ a_stencil_id ] # use avail_index voxel Evaluation Loop for pot_vox in avail_index : if check_avail ( avail_lattice , tuple ( pot_vox ), a_stencil_id ): # evaluate each voxel vox_value = eval_voxel ( pot_vox , env_info , a_pref ) # add the voxel value to the list of values voxel_vals . append ( vox_value ) pot_voxels . append ( pot_vox ) # convert voxel values to numpy array voxel_vals = np . array ( voxel_vals ) # convert potential voxels to numpy array pot_voxels = np . array ( pot_voxels ) # select the voxel with highest value selected_int = np . argmax ( voxel_vals ) # find 3D intiger index of selected voxel selected_vox_3d_address = tuple ( pot_voxels [ selected_int ] . T ) # find the location of the newly selected voxel agn_origins = np . array ( selected_vox_3d_address ) . flatten () # Occupy the newly selected voxel in the occupation lattice occ_lattice [ selected_vox_3d_address ] = 5 agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( selected_vox_3d_address , a_id , a_stencil_id + 1 , agn_locs , agn_src_locs , occ_lattice , avail_lattice ) # append locations of entrances (housing entrance east, garden & south: comcen entrance south) occ_lattice [( 83 , 7 , 1 )] = 5 occ_lattice [( 40 , 20 , 1 )] = 6 occ_lattice [( 70 , 1 , 1 )] = 7 occ_lattice [( 83 , 20 , 1 )] = 8 1.3. Visualizing the simulation p = pv . Plotter ( notebook = True ) base_lattice = occ_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) agn_num = len ( agn_info ) def create_mesh ( value ): f = int ( value ) lattice = base_lattice # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , 20 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) return p . add_slider_widget ( create_mesh , [ 0 , 1 ], title = 'Time' , value = 0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/5.2_voxel_seeds_upper_floors.png' ) p . show ( screenshot = png_path ) 1.3. for each seed, generate a shaft location occupation_01_lattice = ( occ_lattice > - 1 ) . astype ( int ) # compute the sum over the columns to add weight to locations that might have multiple seeds above eachother column_sum = np . sum ( occupation_01_lattice , axis = 2 ) max_value_seeds = np . max ( column_sum ) filled_col_list = [] for i in range ( 1 , max_value_seeds + 1 ): # find adresses of columns column_adress = np . where ( column_sum == i ) filled_collumns = np . array ( column_adress ) . T filled_col_list . append ( filled_collumns ) fill_col_stacked = np . vstack ( filled_col_list ) clusters = len ( fill_col_stacked ) kmeans = KMeans ( n_clusters = clusters , random_state = 0 ) . fit ( fill_col_stacked ) col_labels = kmeans . labels_ cluster_centers = kmeans . cluster_centers_ # creating an empty occ lattice cluster_lattice = occ_lattice * 0 - 1 # iterating over each filled column for col , lab in zip ( fill_col_stacked , col_labels ): # setting the base of the column into the label value cluster_lattice [ col [ 0 ], col [ 1 ], :] = lab 1.4. Compute a graph rounded_cluster_centres = np . rint ( cluster_centers ) . astype ( int ) shaft_lattice = occ_lattice * 0 # iterating over each shaft for i , cen in enumerate ( rounded_cluster_centres ): shaft_lattice [ cen [ 0 ], cen [ 1 ], :] = i + 1 trimmed_shft_latice = shaft_lattice * init_avail_lattice # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_list = [] # Finding the index of the available voxels in avail_lattice avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # check whether it is in a shaft or not if trimmed_shaft_lattice [ tuple ( vox_loc )] > 0 : # in case that specific voxel is in a shaft vox_stencil = stencil else : # in case that the voxel is a normal voxel vox_stencil = h_stencil # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( vox_stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one # adj_mtrx[vox_id, neigh] = 1.0 adj_list . append ([ 1.0 , vox_id , neigh ]) import scipy as sp adj_array = np . array ( adj_list ) adj_mtrx_sparse = sp . sparse . csr_matrix (( adj_array [:, 0 ],( adj_array [:, 1 ], adj_array [:, 2 ])), shape = ( vox_count , vox_count )) g = nx . from_scipy_sparse_matrix ( adj_mtrx_sparse ) 1.5. construct the corridors based on the shortest paths corridor_lattice = occ_lattice * 0 - 1 corr_flat = corridor_lattice . flatten () cor_groundfloor = shaft_lattice [:, :, 1 ] shaft_vox_inds = np . array ( np . where ( cor_groundfloor > 0 )) . T corr_latt_shape = corridor_lattice . shape all_shortest_paths = [] # find the shortest path between all locations to generate a corridor network for start_shaft in shaft_vox_inds : paths = [] path_lenghts = [] for dist_shaft_ind in shaft_vox_inds : # construct the destination adress src_vox = np . array ([ start_shaft [ 0 ], start_shaft [ 1 ], 2 ]) dst_vox = np . array ([ dist_shaft_ind [ 0 ], dist_shaft_ind [ 1 ], 2 ]) # construct 1-dimentional indices src_ind = np . ravel_multi_index ( src_vox , corr_latt_shape ) dst_ind = np . ravel_multi_index ( dst_vox , corr_latt_shape ) # find the shortest path try : path = nx . algorithms . shortest_paths . astar . astar_path ( g , src_ind , dst_ind ) if len ( path ) > 1 : paths . append ( path ) path_lenghts . append ( len ( path )) except : pass path_order = np . argsort ( np . array ( path_lenghts )) shortest_path = paths [ path_order [ 1 ]] all_shortest_paths . append ( paths ) corridor_lattice = corr_flat . reshape ( corridor_lattice . shape ) 1.6. limit corridor height to max shaft height shft_count = int ( trimmed_shaft_lattice . max ()) shft_max_heights = [] for sh in range ( 1 , shft_count + 1 ): shft_voxels = np . argwhere ( trimmed_shaft_lattice == sh ) max_height = shft_voxels [ - 1 , 2 ] shft_max_heights . append ( max_height ) for i , paths in enumerate ( all_shortest_paths ): for path in paths : thrd_ind = np . unravel_index ( path , corridor_lattice . shape ) thrd_ind_array = np . array ( thrd_ind ) . T src_shft = thrd_ind_array [ 0 ] dst_shft = thrd_ind_array [ - 1 ] src_shft_ind = trimmed_shaft_lattice [ tuple ( src_shft )] dst_shft_ind = trimmed_shaft_lattice [ tuple ( dst_shft )] min_value = np . min ([ shft_max_heights [ src_shft_ind - 1 ], shft_max_heights [ dst_shft_ind - 1 ]]) corridor_lattice [ thrd_ind [ 0 ], thrd_ind [ 1 ], 4 :] = 1 corridor_lattice [ thrd_ind [ 0 ], thrd_ind [ 1 ], : 4 ] = - 1 corridor_lattice [ thrd_ind [ 0 ], thrd_ind [ 1 ], min_value :] = - 1 p = pv . Plotter ( notebook = True ) base_lattice = corridor_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , 20 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) # p.add_slider_widget(create_mesh, [0, n_frames], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1)) p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/5.2_corridors_upper_floors.png' ) p . show ( screenshot = png_path ) Credits # save the lorridor lattice upper floors latice to csv csv_path = os . path . relpath ( '../data/corridor_lattice_upper_floors.csv' ) corridor_lattice . to_csv ( csv_path ) import pickle lattice_pickle_path = os . path . relpath ( '../data/corridor_lattice_upper_floors.p' ) pickle . dump ( corridor_lattice , open ( lattice_pickle_path , \"wb\" )) __author__ = \"Shervin Azadi and Pirouz Nourian\" _Chief_editor_ = \"Maartje Damen\" _editor_mentor_ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Corridors upper floor"},{"location":"notebooks/5.2_corridors_upper_floors/#corridor-generation","text":"In this notebook, the location of the corridors is being generated based on the voxel seeds of the functions that grow above the first two levels.","title":"Corridor generation"},{"location":"notebooks/5.2_corridors_upper_floors/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/5.2_corridors_upper_floors/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import pandas as pd from sklearn.cluster import KMeans import pickle np . random . seed ( 0 ) import copy # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l","title":"0.1. Load required libraries"},{"location":"notebooks/5.2_corridors_upper_floors/#02-define-the-neighborhood-stencil","text":"# creating neighborhood definition s_1 = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_1 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_2 = tg . create_stencil ( \"von_neumann\" , 1 , 2 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) s_2 . set_index ([ 0 , 0 , 1 ], 0 ) s_2 . set_index ([ 0 , 0 , 2 ], 1 ) s_2 . set_index ([ 0 , 0 , - 1 ], 0 ) s_2 . set_index ([ 0 , 0 , - 2 ], 1 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_3 = tg . create_stencil ( \"von_neumann\" , 1 , 3 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) s_3 . set_index ([ 0 , 0 , 1 ], 0 ) s_3 . set_index ([ 0 , 0 , 3 ], 1 ) s_3 . set_index ([ 0 , 0 , - 1 ], 0 ) s_3 . set_index ([ 0 , 0 , - 3 ], 1 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition s_groundfloor = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_groundfloor . set_index ([ 0 , 0 , 0 ], 0 ) s_groundfloor . set_index ([ 0 , 0 , 1 ], 0 ) s_groundfloor . set_index ([ 0 , 0 , - 1 ], 0 ) stencils = [ s_1 , s_2 , s_3 , s_groundfloor ] h_stencil = s_groundfloor","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/5.2_corridors_upper_floors/#03-load-the-envelope-lattice-as-the-avialibility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/highres_envelope.csv' ) avail_lattice = lattice_from_csv ( lattice_path ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/avail_lattice_good_voxels.csv' ) avail_lattice_good_voxels = lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice_good_voxels ), avail_lattice_good_voxels ) avail_lattice *= avail_lattice_good_voxels","title":"0.3. Load the envelope lattice as the avialibility lattice"},{"location":"notebooks/5.2_corridors_upper_floors/#04-load-agents-information","text":"# loading program (agents information) from CSV prgm_path = os . path . relpath ( '../data/program_exported.csv' ) agn_info = pd . read_csv ( '../data/program_exported.csv' , delimiter = \";\" ) agn_ids = agn_info [ \"space_id\" ] . values agn_prefs = agn_info a_pref = agn_prefs . loc [ 0 ] high_level = [] print ( agn_info [ \"ground_floor\" ] . values ) for i in agn_ids : if agn_info [ \"ground_floor\" ][ i ] == 0 : high_level . append ( agn_ids [ i ]) print ( high_level ) # Loading program information between agents from CSV matrix_path = os . path . relpath ( '../data/program_exported_matrix.csv' ) matrix_info = pd . read_csv ( '../data/program_exported_matrix.csv' , delimiter = \";\" ) matrix_ids = matrix_info [ \"space_id\" ] . values matrix_prefs = matrix_info","title":"0.4. Load Agents Information"},{"location":"notebooks/5.2_corridors_upper_floors/#05-initialize-environment-information-layers-from-sun-access-lattice-and-entrance-access-lattice","text":"# loading the lattice from csv sun_acc_path = os . path . relpath ( '../data/sun_access_highres.csv' ) sun_acc_lattice = lattice_from_csv ( sun_acc_path ) ent_acc_highres_public_path = os . path . relpath ( '../data/ent_access_highres_public.csv' ) ent_acc_public_lattice = lattice_from_csv ( ent_acc_highres_public_path ) ent_acc_highres_housing_path = os . path . relpath ( '../data/ent_access_highres_housing.csv' ) ent_acc_housing_lattice = lattice_from_csv ( ent_acc_highres_housing_path ) ent_acc_highres_gym_path = os . path . relpath ( '../data/ent_access_highres_gym.csv' ) ent_acc_gym_lattice = lattice_from_csv ( ent_acc_highres_gym_path ) ent_acc_highres_parking_path = os . path . relpath ( '../data/ent_access_highres_parking.csv' ) ent_acc_parking_lattice = lattice_from_csv ( ent_acc_highres_parking_path ) ent_acc_highres_comcen_path = os . path . relpath ( '../data/ent_access_highres_comcen.csv' ) ent_acc_comcen_lattice = lattice_from_csv ( ent_acc_highres_comcen_path ) highres_sky_acc_path = os . path . relpath ( '../data/sky_access_highres.csv' ) sky_acc_lattice = lattice_from_csv ( highres_sky_acc_path ) highres_quietness_acc_path = os . path . relpath ( '../data/quietness_highres.csv' ) quietness_acc_lattice = lattice_from_csv ( highres_quietness_acc_path ) groundfloor_acc_path = os . path . relpath ( '../data/ent_access_highres_groundfloor.csv' ) groundfloor_acc_lattice = lattice_from_csv ( groundfloor_acc_path ) # list the environment information layers (lattices) env_info = { \"sun_acc\" : sun_acc_lattice + 0.001 , \"ent_acc_public\" : ent_acc_public_lattice + 0.001 , \"ent_acc_housing\" : ent_acc_housing_lattice + 0.001 , \"ent_acc_gym\" : ent_acc_gym_lattice + 0.001 , \"ent_acc_parking\" : ent_acc_parking_lattice + 0.001 , \"ent_acc_comcen\" : ent_acc_comcen_lattice + 0.001 , \"sky_acc\" : sky_acc_lattice + 0.001 , \"quietness_acc\" : quietness_acc_lattice + 0.001 , \"ground_floor_acc\" : groundfloor_acc_lattice + 0.001 } # defining stencil id stencil_id = stencils # area to use in simulation room_area = []","title":"0.5. Initialize environment information layers from Sun Access Lattice and Entrance Access Lattice"},{"location":"notebooks/5.2_corridors_upper_floors/#11-initial-agent-localisation","text":"def check_avail ( avail_lattice , ind , a_stencil_id ): condition = 1 ind_array = np . array ( ind ) for step in range ( a_stencil_id + 1 ): new_ind_array = ind_array + np . array ([ 0 , 0 , step ]) condition *= avail_lattice [ tuple ( new_ind_array )] return condition def eval_voxel ( vox , env_info , a_pref ): global_vox_value = 1.0 # for every lattice in the environment informations for key , info_lattice in env_info . items (): # Here we utilise Fuzzy Logics to be able to compare different layers # of environmental information and evaluate the voxel for the agent. # This method is introduced, and generalised in Pirouz Nourian dissertation: # section 5.7.3, pp. 201-208, eq. 57. You can refer to this section for # comprehensive mathematical details. vox_val = info_lattice [ tuple ( vox )] agn_vox_val = np . power ( vox_val , a_pref [ key ]) global_vox_value *= agn_vox_val return global_vox_value def mult_occupation ( selected_neigh_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = False ): for step in range ( a_height ): new_address = selected_neigh_3d_address + np . array ([ 0 , 0 , step ]) if new_address [ 2 ] < occ_lattice . shape [ 2 ]: # make tuple of the address selected_neigh_3d_id = tuple ( new_address ) # find the location of the newly selected neighbour selected_neigh_loc = np . array ( selected_neigh_3d_id ) . flatten () if departure == False : # add the newly selected neighbour location to agent locations agn_locs [ a_id ] . append ( selected_neigh_loc ) if step == 0 : agn_src_locs [ a_id ] . append ( selected_neigh_loc ) # set the newly selected neighbour as UNavailable (0) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 0 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_neigh_3d_id ] = a_id else : # remove the newly selected neighbour location to agent locations a_locs_list = [ list ( loc ) for loc in agn_locs [ a_id ]] try : ind = a_locs_list . index ( list ( selected_neigh_loc )) agn_locs [ a_id ] . pop ( ind ) # set the newly selected neighbour as UNavailable (0) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 1 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_neigh_3d_id ] = - 1 except : pass return ( agn_locs , agn_src_locs , occ_lattice , avail_lattice ) def find_neighbours_masked ( lattice , stencil , loc ): neigh_locs = np . argwhere ( stencil ) - stencil . origin + loc neigh_filter = np . all ( neigh_locs > 0 , axis = 1 ) * np . all ( neigh_locs < np . array ( lattice . shape ), axis = 1 ) return ( neigh_locs [ neigh_filter ]) # initialize the occupation lattice occ_lattice = avail_lattice * 0 - 1 # Finding the index of the available voxels in avail_lattice avail_flat = avail_lattice . flatten () avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # count the number of spaces and intiialize an agent for each space agn_num = len ( agn_info ) # adding the origins to the agents locations agn_locs = [[] for a_id in agn_ids ] agn_src_locs = [[] for a_id in agn_ids ] agn_upper = [] # retrieving the initial location of each agent for a_id in high_level : voxel_vals = [] pot_voxels = [] # retrieve agent preferences a_pref = agn_prefs . loc [ a_id ] a_stencil_id = 0 stencil = stencils [ a_stencil_id ] # use avail_index voxel Evaluation Loop for pot_vox in avail_index : if check_avail ( avail_lattice , tuple ( pot_vox ), a_stencil_id ): # evaluate each voxel vox_value = eval_voxel ( pot_vox , env_info , a_pref ) # add the voxel value to the list of values voxel_vals . append ( vox_value ) pot_voxels . append ( pot_vox ) # convert voxel values to numpy array voxel_vals = np . array ( voxel_vals ) # convert potential voxels to numpy array pot_voxels = np . array ( pot_voxels ) # select the voxel with highest value selected_int = np . argmax ( voxel_vals ) # find 3D intiger index of selected voxel selected_vox_3d_address = tuple ( pot_voxels [ selected_int ] . T ) # find the location of the newly selected voxel agn_origins = np . array ( selected_vox_3d_address ) . flatten () # Occupy the newly selected voxel in the occupation lattice occ_lattice [ selected_vox_3d_address ] = 5 agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( selected_vox_3d_address , a_id , a_stencil_id + 1 , agn_locs , agn_src_locs , occ_lattice , avail_lattice ) # append locations of entrances (housing entrance east, garden & south: comcen entrance south) occ_lattice [( 83 , 7 , 1 )] = 5 occ_lattice [( 40 , 20 , 1 )] = 6 occ_lattice [( 70 , 1 , 1 )] = 7 occ_lattice [( 83 , 20 , 1 )] = 8","title":"1.1. Initial agent localisation"},{"location":"notebooks/5.2_corridors_upper_floors/#13-visualizing-the-simulation","text":"p = pv . Plotter ( notebook = True ) base_lattice = occ_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) agn_num = len ( agn_info ) def create_mesh ( value ): f = int ( value ) lattice = base_lattice # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , 20 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) return p . add_slider_widget ( create_mesh , [ 0 , 1 ], title = 'Time' , value = 0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/5.2_voxel_seeds_upper_floors.png' ) p . show ( screenshot = png_path )","title":"1.3. Visualizing the simulation"},{"location":"notebooks/5.2_corridors_upper_floors/#13-for-each-seed-generate-a-shaft-location","text":"occupation_01_lattice = ( occ_lattice > - 1 ) . astype ( int ) # compute the sum over the columns to add weight to locations that might have multiple seeds above eachother column_sum = np . sum ( occupation_01_lattice , axis = 2 ) max_value_seeds = np . max ( column_sum ) filled_col_list = [] for i in range ( 1 , max_value_seeds + 1 ): # find adresses of columns column_adress = np . where ( column_sum == i ) filled_collumns = np . array ( column_adress ) . T filled_col_list . append ( filled_collumns ) fill_col_stacked = np . vstack ( filled_col_list ) clusters = len ( fill_col_stacked ) kmeans = KMeans ( n_clusters = clusters , random_state = 0 ) . fit ( fill_col_stacked ) col_labels = kmeans . labels_ cluster_centers = kmeans . cluster_centers_ # creating an empty occ lattice cluster_lattice = occ_lattice * 0 - 1 # iterating over each filled column for col , lab in zip ( fill_col_stacked , col_labels ): # setting the base of the column into the label value cluster_lattice [ col [ 0 ], col [ 1 ], :] = lab","title":"1.3. for each seed, generate a shaft location"},{"location":"notebooks/5.2_corridors_upper_floors/#14-compute-a-graph","text":"rounded_cluster_centres = np . rint ( cluster_centers ) . astype ( int ) shaft_lattice = occ_lattice * 0 # iterating over each shaft for i , cen in enumerate ( rounded_cluster_centres ): shaft_lattice [ cen [ 0 ], cen [ 1 ], :] = i + 1 trimmed_shft_latice = shaft_lattice * init_avail_lattice # find the number of all voxels vox_count = avail_lattice . size # initialize the adjacency matrix adj_list = [] # Finding the index of the available voxels in avail_lattice avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # fill the adjacency matrix using the list of all neighbours for vox_loc in avail_index : # find the 1D id vox_id = np . ravel_multi_index ( vox_loc , avail_lattice . shape ) # check whether it is in a shaft or not if trimmed_shaft_lattice [ tuple ( vox_loc )] > 0 : # in case that specific voxel is in a shaft vox_stencil = stencil else : # in case that the voxel is a normal voxel vox_stencil = h_stencil # retrieve the list of neighbours of the voxel based on the stencil vox_neighs = avail_lattice . find_neighbours_masked ( vox_stencil , loc = vox_loc ) # iterating over the neighbours for neigh in vox_neighs : # setting the entry to one # adj_mtrx[vox_id, neigh] = 1.0 adj_list . append ([ 1.0 , vox_id , neigh ]) import scipy as sp adj_array = np . array ( adj_list ) adj_mtrx_sparse = sp . sparse . csr_matrix (( adj_array [:, 0 ],( adj_array [:, 1 ], adj_array [:, 2 ])), shape = ( vox_count , vox_count )) g = nx . from_scipy_sparse_matrix ( adj_mtrx_sparse )","title":"1.4. Compute a graph"},{"location":"notebooks/5.2_corridors_upper_floors/#15-construct-the-corridors-based-on-the-shortest-paths","text":"corridor_lattice = occ_lattice * 0 - 1 corr_flat = corridor_lattice . flatten () cor_groundfloor = shaft_lattice [:, :, 1 ] shaft_vox_inds = np . array ( np . where ( cor_groundfloor > 0 )) . T corr_latt_shape = corridor_lattice . shape all_shortest_paths = [] # find the shortest path between all locations to generate a corridor network for start_shaft in shaft_vox_inds : paths = [] path_lenghts = [] for dist_shaft_ind in shaft_vox_inds : # construct the destination adress src_vox = np . array ([ start_shaft [ 0 ], start_shaft [ 1 ], 2 ]) dst_vox = np . array ([ dist_shaft_ind [ 0 ], dist_shaft_ind [ 1 ], 2 ]) # construct 1-dimentional indices src_ind = np . ravel_multi_index ( src_vox , corr_latt_shape ) dst_ind = np . ravel_multi_index ( dst_vox , corr_latt_shape ) # find the shortest path try : path = nx . algorithms . shortest_paths . astar . astar_path ( g , src_ind , dst_ind ) if len ( path ) > 1 : paths . append ( path ) path_lenghts . append ( len ( path )) except : pass path_order = np . argsort ( np . array ( path_lenghts )) shortest_path = paths [ path_order [ 1 ]] all_shortest_paths . append ( paths ) corridor_lattice = corr_flat . reshape ( corridor_lattice . shape )","title":"1.5. construct the corridors based on the shortest paths"},{"location":"notebooks/5.2_corridors_upper_floors/#16-limit-corridor-height-to-max-shaft-height","text":"shft_count = int ( trimmed_shaft_lattice . max ()) shft_max_heights = [] for sh in range ( 1 , shft_count + 1 ): shft_voxels = np . argwhere ( trimmed_shaft_lattice == sh ) max_height = shft_voxels [ - 1 , 2 ] shft_max_heights . append ( max_height ) for i , paths in enumerate ( all_shortest_paths ): for path in paths : thrd_ind = np . unravel_index ( path , corridor_lattice . shape ) thrd_ind_array = np . array ( thrd_ind ) . T src_shft = thrd_ind_array [ 0 ] dst_shft = thrd_ind_array [ - 1 ] src_shft_ind = trimmed_shaft_lattice [ tuple ( src_shft )] dst_shft_ind = trimmed_shaft_lattice [ tuple ( dst_shft )] min_value = np . min ([ shft_max_heights [ src_shft_ind - 1 ], shft_max_heights [ dst_shft_ind - 1 ]]) corridor_lattice [ thrd_ind [ 0 ], thrd_ind [ 1 ], 4 :] = 1 corridor_lattice [ thrd_ind [ 0 ], thrd_ind [ 1 ], : 4 ] = - 1 corridor_lattice [ thrd_ind [ 0 ], thrd_ind [ 1 ], min_value :] = - 1 p = pv . Plotter ( notebook = True ) base_lattice = corridor_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , 20 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) # p.add_slider_widget(create_mesh, [0, n_frames], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1)) p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/5.2_corridors_upper_floors.png' ) p . show ( screenshot = png_path )","title":"1.6. limit corridor height to max shaft height"},{"location":"notebooks/5.2_corridors_upper_floors/#credits","text":"# save the lorridor lattice upper floors latice to csv csv_path = os . path . relpath ( '../data/corridor_lattice_upper_floors.csv' ) corridor_lattice . to_csv ( csv_path ) import pickle lattice_pickle_path = os . path . relpath ( '../data/corridor_lattice_upper_floors.p' ) pickle . dump ( corridor_lattice , open ( lattice_pickle_path , \"wb\" )) __author__ = \"Shervin Azadi and Pirouz Nourian\" _Chief_editor_ = \"Maartje Damen\" _editor_mentor_ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/5.3_shafts/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Shafts In this notebook, the shafts that connect the groundfloors, entrances and all floors above are being generated in a lattice. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import pandas as pd from sklearn.cluster import KMeans np . random . seed ( 0 ) import copy # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l shaft_stencil = tg . create_stencil ( \"von_neumann\" , 1 , 2 ) shaft_stencil . set_index ([ 0 , 0 , 0 ], 0 ) shaft_stencil . set_index ([ 1 , 0 , 0 ], 0 ) shaft_stencil . set_index ([ - 1 , 0 , 0 ], 0 ) shaft_stencil . set_index ([ 0 , 1 , 1 ], 1 ) shaft_stencil . set_index ([ 0 , 2 , 1 ], 1 ) shaft_stencil . set_index ([ 0 , 2 , 2 ], 1 ) shaft_stencil . set_index ([ 0 , 1 , 2 ], 1 ) shaft_stencil . set_index ([ 0 , 2 , 0 ], 1 ) shaft_stencil . set_index ([ 0 , 0 , 2 ], 1 ) shaft_stencil . set_index ([ 0 , 1 , 1 ], 1 ) shaft_stencil . set_index ([ 0 , - 1 , 1 ], 1 ) shaft_stencil . set_index ([ 0 , - 1 , 2 ], 1 ) shaft_stencil . set_index ([ 0 , - 1 , - 1 ], 1 ) shaft_stencil . set_index ([ 0 , 1 , - 1 ], 1 ) shaft_stencil . set_index ([ 0 , 2 , - 1 ], 1 ) 0.3. Load the envelope lattice as the avialibility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/highres_envelope.csv' ) avail_lattice = lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) 0.4. Load Agents Information # loading program (agents information) from CSV prgm_path = os . path . relpath ( '../data/program_exported.csv' ) agn_info = pd . read_csv ( '../data/program_exported.csv' , delimiter = \";\" ) agn_ids = agn_info [ \"space_id\" ] . values agn_prefs = agn_info a_pref = agn_prefs . loc [ 0 ] agn_num = len ( agn_info ) 1.1 determine all shaft locations at the location of the entrance voxel start_shaft_lattice = avail_lattice * 0 - 1 start_shaft_lattice [( 83 , 7 , 1 )] = 3 start_shaft_lattice [( 40 , 20 , 1 )] = 3 start_shaft_lattice [( 70 , 1 , 1 )] = 3 start_shaft_lattice [( 83 , 20 , 1 )] = 3 occupation_latice = ( start_shaft_lattice > - 1 ) . astype ( int ) # compute the sum over the columns column_sum = np . sum ( occupation_latice , axis = 2 ) max_value = np . max ( column_sum ) filled_col_list = [] for i in range ( 1 , max_value + 1 ): # find adresses of columns column_adress = np . where ( column_sum == i ) filled_collumns = np . array ( column_adress ) . T filled_col_list . append ( filled_collumns ) fill_col_stacked = np . vstack ( filled_col_list ) clusters = len ( fill_col_stacked ) kmeans = KMeans ( n_clusters = clusters , random_state = 0 ) . fit ( fill_col_stacked ) col_labels = kmeans . labels_ cluster_centers = kmeans . cluster_centers_ # creating an empty occ lattice cluster_lattice = avail_lattice * 0 - 1 # iterating over each filled column for col , lab in zip ( fill_col_stacked , col_labels ): cluster_lattice [ col [ 0 ], col [ 1 ], :] = lab 1.2. generate height of each shaft rounded_cluster_centres = np . rint ( cluster_centers ) . astype ( int ) shaft_placement_lattice = avail_lattice * 0 # iterating over each shaft for i , cen in enumerate ( rounded_cluster_centres ): shaft_placement_lattice [ cen [ 0 ], cen [ 1 ], :] = 1 trimmed_shaft_lattice = shaft_placement_lattice * init_avail_lattice p = pv . Plotter ( notebook = True ) base_lattice = trimmed_shaft_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.9 , agn_num - 0.9 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) # p.add_slider_widget(create_mesh, [0, n_frames], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1)) p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/6.3_shafts.png' ) p . show ( screenshot = png_path ) 2.3. Saving lattice frames in CSV # save the ground floor latice to csv csv_path = os . path . relpath ( '../data/shaft_lattice.csv' ) trimmed_shaft_lattice . to_csv ( csv_path ) import pickle lattice_pickle_path = os . path . relpath ( '../data/shaft_lattice.p' ) pickle . dump ( trimmed_shaft_lattice , open ( lattice_pickle_path , \"wb\" )) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" _Chief_editor_ = \"Maartje Damen\" _Co_editor_ = \"Eda Akaltun\" _Co_editor_ = \"Siebren Meines\" _editor_mentor_ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Shafts"},{"location":"notebooks/5.3_shafts/#shafts","text":"In this notebook, the shafts that connect the groundfloors, entrances and all floors above are being generated in a lattice.","title":"Shafts"},{"location":"notebooks/5.3_shafts/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/5.3_shafts/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import pandas as pd from sklearn.cluster import KMeans np . random . seed ( 0 ) import copy # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l shaft_stencil = tg . create_stencil ( \"von_neumann\" , 1 , 2 ) shaft_stencil . set_index ([ 0 , 0 , 0 ], 0 ) shaft_stencil . set_index ([ 1 , 0 , 0 ], 0 ) shaft_stencil . set_index ([ - 1 , 0 , 0 ], 0 ) shaft_stencil . set_index ([ 0 , 1 , 1 ], 1 ) shaft_stencil . set_index ([ 0 , 2 , 1 ], 1 ) shaft_stencil . set_index ([ 0 , 2 , 2 ], 1 ) shaft_stencil . set_index ([ 0 , 1 , 2 ], 1 ) shaft_stencil . set_index ([ 0 , 2 , 0 ], 1 ) shaft_stencil . set_index ([ 0 , 0 , 2 ], 1 ) shaft_stencil . set_index ([ 0 , 1 , 1 ], 1 ) shaft_stencil . set_index ([ 0 , - 1 , 1 ], 1 ) shaft_stencil . set_index ([ 0 , - 1 , 2 ], 1 ) shaft_stencil . set_index ([ 0 , - 1 , - 1 ], 1 ) shaft_stencil . set_index ([ 0 , 1 , - 1 ], 1 ) shaft_stencil . set_index ([ 0 , 2 , - 1 ], 1 )","title":"0.1. Load required libraries"},{"location":"notebooks/5.3_shafts/#03-load-the-envelope-lattice-as-the-avialibility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/highres_envelope.csv' ) avail_lattice = lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice )","title":"0.3. Load the envelope lattice as the avialibility lattice"},{"location":"notebooks/5.3_shafts/#04-load-agents-information","text":"# loading program (agents information) from CSV prgm_path = os . path . relpath ( '../data/program_exported.csv' ) agn_info = pd . read_csv ( '../data/program_exported.csv' , delimiter = \";\" ) agn_ids = agn_info [ \"space_id\" ] . values agn_prefs = agn_info a_pref = agn_prefs . loc [ 0 ] agn_num = len ( agn_info )","title":"0.4. Load Agents Information"},{"location":"notebooks/5.3_shafts/#11-determine-all-shaft-locations-at-the-location-of-the-entrance-voxel","text":"start_shaft_lattice = avail_lattice * 0 - 1 start_shaft_lattice [( 83 , 7 , 1 )] = 3 start_shaft_lattice [( 40 , 20 , 1 )] = 3 start_shaft_lattice [( 70 , 1 , 1 )] = 3 start_shaft_lattice [( 83 , 20 , 1 )] = 3 occupation_latice = ( start_shaft_lattice > - 1 ) . astype ( int ) # compute the sum over the columns column_sum = np . sum ( occupation_latice , axis = 2 ) max_value = np . max ( column_sum ) filled_col_list = [] for i in range ( 1 , max_value + 1 ): # find adresses of columns column_adress = np . where ( column_sum == i ) filled_collumns = np . array ( column_adress ) . T filled_col_list . append ( filled_collumns ) fill_col_stacked = np . vstack ( filled_col_list ) clusters = len ( fill_col_stacked ) kmeans = KMeans ( n_clusters = clusters , random_state = 0 ) . fit ( fill_col_stacked ) col_labels = kmeans . labels_ cluster_centers = kmeans . cluster_centers_ # creating an empty occ lattice cluster_lattice = avail_lattice * 0 - 1 # iterating over each filled column for col , lab in zip ( fill_col_stacked , col_labels ): cluster_lattice [ col [ 0 ], col [ 1 ], :] = lab","title":"1.1 determine all shaft locations at the location of the entrance voxel"},{"location":"notebooks/5.3_shafts/#12-generate-height-of-each-shaft","text":"rounded_cluster_centres = np . rint ( cluster_centers ) . astype ( int ) shaft_placement_lattice = avail_lattice * 0 # iterating over each shaft for i , cen in enumerate ( rounded_cluster_centres ): shaft_placement_lattice [ cen [ 0 ], cen [ 1 ], :] = 1 trimmed_shaft_lattice = shaft_placement_lattice * init_avail_lattice p = pv . Plotter ( notebook = True ) base_lattice = trimmed_shaft_lattice # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice # init_avail_lattice.fast_vis(p) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = base_lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ 0.9 , agn_num - 0.9 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = False ) # p.add_slider_widget(create_mesh, [0, n_frames], title='Time', value=0, event_type=\"always\", style=\"classic\", pointa=(0.1, 0.1), pointb=(0.9, 0.1)) p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/6.3_shafts.png' ) p . show ( screenshot = png_path )","title":"1.2. generate height of each shaft"},{"location":"notebooks/5.3_shafts/#23-saving-lattice-frames-in-csv","text":"# save the ground floor latice to csv csv_path = os . path . relpath ( '../data/shaft_lattice.csv' ) trimmed_shaft_lattice . to_csv ( csv_path ) import pickle lattice_pickle_path = os . path . relpath ( '../data/shaft_lattice.p' ) pickle . dump ( trimmed_shaft_lattice , open ( lattice_pickle_path , \"wb\" ))","title":"2.3. Saving lattice frames in CSV"},{"location":"notebooks/5.3_shafts/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" _Chief_editor_ = \"Maartje Damen\" _Co_editor_ = \"Eda Akaltun\" _Co_editor_ = \"Siebren Meines\" _editor_mentor_ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/6.1_lattice_distance_community/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Distance Lattice Communal functions in this notebook, the distance lattice from the communal corridors is being generated. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import scipy as sp import pickle np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator 0.2. Define the Neighborhood (Stencil) # creating neighborhood definition h_stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero h_stencil . set_index ([ 0 , 0 , 0 ], 0 ) h_stencil . set_index ([ 0 , 0 , 1 ], 0 ) h_stencil . set_index ([ 0 , 0 , - 1 ], 0 ) print ( h_stencil ) 0.3. Load the envelope lattice as the avialbility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/new_shadremove_envelope_lattice.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) lattice_pickle_path = os . path . relpath ( '../data/corridors_groundfloor.p' ) corridors_groundfloor = pickle . load ( open ( lattice_pickle_path , \"rb\" )) corridors_groundfloor . bounds = avail_lattice . bounds corridors_groundfloor . unit = avail_lattice . unit 1. Distance Field Construction 1.1. Create distance lattice to comcen corridors # initializing the distance lattice distance_lattice = avail_lattice * 0 # cutting an slice of the lattice distance_floor = distance_lattice [:, :, 1 ] # cutting an slice of the groundfloor corridors lattice cor_groundfloor_floor = corridors_groundfloor [:, :, 1 ] # extracting all it's voxel indices corr_vox_inds = np . argwhere ( cor_groundfloor_floor > 0 ) # extract the indicies of the distance floor dist_indices = np . indices ( distance_floor . shape ) # init list of slice dists slice_dist_arrays = [] # iterate over voxels of the coridor for cor_vox in corr_vox_inds : # find the relative distance of corridor voxel to all dist floor voxels in X, Y relative_dist = np . abs ( dist_indices - cor_vox [:, np . newaxis , np . newaxis ]) # sum X, Y components slice_dist = relative_dist . sum ( axis = 0 ) # append to list slice_dist_arrays . append ( slice_dist ) # find the minimum fo earch dist voxel min_dist_slice = np . min ( np . stack ( slice_dist_arrays ), axis = 0 ) # construc the distance lattice from one slice distance_lattice += min_dist_slice [:, :, np . newaxis ] 1.2. Normalize all values #find the maximum valid value max_valid = np . ma . masked_invalid ( distance_lattice ) . max () # set the infinities to one more than the maximum valid values distance_lattice [ distance_lattice == np . inf ] = max_valid + 1 # mapping the values from (0, max) to (1, 0) ent_flat = 1 - distance_lattice / np . max ( distance_lattice ) 1.3. copy distance slice to all floors that have these corridors, set all other values to 0 base_lattice = avail_lattice * 0 base_lattice [:,:,: 6 ] = 1 base_lattice *= avail_lattice base_flat = base_lattice . flatten () dist_flat = ent_flat . flatten () dist_flat *= base_flat # # constructing the lattice dist_lattice_comcen_corridors = tg . to_lattice ( dist_flat . reshape ( avail_lattice . shape ), avail_lattice ) 1.4. Visualize the distance lattice # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) ent_acc_highres = dist_lattice_comcen_corridors # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Distance lattice communal functions\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/6.2_lattice_distance_communal_functions.png' ) p . show ( screenshot = png_path ) 1.5. Save Entrance Access Lattice to CSV # save the entrance access latice to csv csv_path = os . path . relpath ( '../data/dist_lattice_comcen_groundfloor.csv' ) dist_lattice_comcen_corridors . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Distance calculation, ground floor"},{"location":"notebooks/6.1_lattice_distance_community/#distance-lattice-communal-functions","text":"in this notebook, the distance lattice from the communal corridors is being generated.","title":"Distance Lattice Communal functions"},{"location":"notebooks/6.1_lattice_distance_community/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/6.1_lattice_distance_community/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import scipy as sp import pickle np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator","title":"0.1. Load required libraries"},{"location":"notebooks/6.1_lattice_distance_community/#02-define-the-neighborhood-stencil","text":"# creating neighborhood definition h_stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero h_stencil . set_index ([ 0 , 0 , 0 ], 0 ) h_stencil . set_index ([ 0 , 0 , 1 ], 0 ) h_stencil . set_index ([ 0 , 0 , - 1 ], 0 ) print ( h_stencil )","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/6.1_lattice_distance_community/#03-load-the-envelope-lattice-as-the-avialbility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/new_shadremove_envelope_lattice.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) lattice_pickle_path = os . path . relpath ( '../data/corridors_groundfloor.p' ) corridors_groundfloor = pickle . load ( open ( lattice_pickle_path , \"rb\" )) corridors_groundfloor . bounds = avail_lattice . bounds corridors_groundfloor . unit = avail_lattice . unit","title":"0.3. Load the envelope lattice as the avialbility lattice"},{"location":"notebooks/6.1_lattice_distance_community/#1-distance-field-construction","text":"","title":"1. Distance Field Construction"},{"location":"notebooks/6.1_lattice_distance_community/#11-create-distance-lattice-to-comcen-corridors","text":"# initializing the distance lattice distance_lattice = avail_lattice * 0 # cutting an slice of the lattice distance_floor = distance_lattice [:, :, 1 ] # cutting an slice of the groundfloor corridors lattice cor_groundfloor_floor = corridors_groundfloor [:, :, 1 ] # extracting all it's voxel indices corr_vox_inds = np . argwhere ( cor_groundfloor_floor > 0 ) # extract the indicies of the distance floor dist_indices = np . indices ( distance_floor . shape ) # init list of slice dists slice_dist_arrays = [] # iterate over voxels of the coridor for cor_vox in corr_vox_inds : # find the relative distance of corridor voxel to all dist floor voxels in X, Y relative_dist = np . abs ( dist_indices - cor_vox [:, np . newaxis , np . newaxis ]) # sum X, Y components slice_dist = relative_dist . sum ( axis = 0 ) # append to list slice_dist_arrays . append ( slice_dist ) # find the minimum fo earch dist voxel min_dist_slice = np . min ( np . stack ( slice_dist_arrays ), axis = 0 ) # construc the distance lattice from one slice distance_lattice += min_dist_slice [:, :, np . newaxis ]","title":"1.1. Create distance lattice to comcen corridors"},{"location":"notebooks/6.1_lattice_distance_community/#12-normalize-all-values","text":"#find the maximum valid value max_valid = np . ma . masked_invalid ( distance_lattice ) . max () # set the infinities to one more than the maximum valid values distance_lattice [ distance_lattice == np . inf ] = max_valid + 1 # mapping the values from (0, max) to (1, 0) ent_flat = 1 - distance_lattice / np . max ( distance_lattice )","title":"1.2. Normalize all values"},{"location":"notebooks/6.1_lattice_distance_community/#13-copy-distance-slice-to-all-floors-that-have-these-corridors-set-all-other-values-to-0","text":"base_lattice = avail_lattice * 0 base_lattice [:,:,: 6 ] = 1 base_lattice *= avail_lattice base_flat = base_lattice . flatten () dist_flat = ent_flat . flatten () dist_flat *= base_flat # # constructing the lattice dist_lattice_comcen_corridors = tg . to_lattice ( dist_flat . reshape ( avail_lattice . shape ), avail_lattice )","title":"1.3. copy distance slice to all floors that have these corridors, set all other values to 0"},{"location":"notebooks/6.1_lattice_distance_community/#14-visualize-the-distance-lattice","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) ent_acc_highres = dist_lattice_comcen_corridors # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"Distance lattice communal functions\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/6.2_lattice_distance_communal_functions.png' ) p . show ( screenshot = png_path )","title":"1.4. Visualize the distance lattice"},{"location":"notebooks/6.1_lattice_distance_community/#15-save-entrance-access-lattice-to-csv","text":"# save the entrance access latice to csv csv_path = os . path . relpath ( '../data/dist_lattice_comcen_groundfloor.csv' ) dist_lattice_comcen_corridors . to_csv ( csv_path )","title":"1.5. Save Entrance Access Lattice to CSV"},{"location":"notebooks/6.1_lattice_distance_community/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/6.2_lattice_distance_upper_floors/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Distance Lattice upper floors in this notebook, the distance lattice is being generated for all higher levels. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import scipy as sp import pickle np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator 0.2. Define the Neighborhood (Stencil) # creating neighborhood definition h_stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero h_stencil . set_index ([ 0 , 0 , 0 ], 0 ) h_stencil . set_index ([ 0 , 0 , 1 ], 0 ) h_stencil . set_index ([ 0 , 0 , - 1 ], 0 ) 0.3. Load the envelope lattice as the avialbility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_pickle_path = os . path . relpath ( '../data/corridor_lattice_upper_floors.p' ) corridor_lattice_upper_floors = pickle . load ( open ( lattice_pickle_path , \"rb\" )) corridor_lattice_upper_floors . bounds = avail_lattice . bounds corridor_lattice_upper_floors . unit = avail_lattice . unit 1. Distance Field Construction 1.1. Create distance lattice to upper floor corridors # initializing the distance lattice distance_lattice = avail_lattice * 0 # cutting an slice of the distance lattice distance_floor = distance_lattice [:, :, 1 ] # cutting an slice of the groundfloor corridors lattice cor_upper_floor = corridor_lattice_upper_floors [:, :, 8 ] # extracting all it's voxel indices corr_vox_inds = np . argwhere ( cor_upper_floor > 0 ) # extract the indicies of the distance floor dist_indices = np . indices ( distance_floor . shape ) # init list of slice dists slice_dist_arrays = [] # iterate over voxels of the corridor for cor_vox in corr_vox_inds : # find the relative distance of corridor voxel to all dist floor voxels in X, Y relative_dist = np . abs ( dist_indices - cor_vox [:, np . newaxis , np . newaxis ]) # sum X, Y components slice_dist = relative_dist . sum ( axis = 0 ) # append to list slice_dist_arrays . append ( slice_dist ) # find the minimum fo earch dist voxel min_dist_slice = np . min ( np . stack ( slice_dist_arrays ), axis = 0 ) # construc the distance lattice from one slice distance_lattice += min_dist_slice [:, :, np . newaxis ] 1.2. Normalize all values #find the maximum valid value max_valid = np . ma . masked_invalid ( distance_lattice ) . max () # set the infinities to one more than the maximum valid values distance_lattice [ distance_lattice == np . inf ] = max_valid + 1 # mapping the values from (0, max) to (1, 0) ent_flat = 1 - distance_lattice / np . max ( distance_lattice ) 1.3. copy distance slice to all floors that have these corridors, set all other values to 0 base_lattice = avail_lattice * 0 base_lattice [:,:, 6 :] = 1 base_lattice *= avail_lattice base_flat = base_lattice . flatten () dist_flat = ent_flat . flatten () dist_flat *= base_flat # # constructing the lattice dist_lattice_upper_floors = tg . to_lattice ( dist_flat . reshape ( avail_lattice . shape ), avail_lattice ) 1.4. Visualize the distance lattice # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) ent_acc_highres = dist_lattice_upper_floors # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"distance lattice upper floors\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/6.2_lattice_distance_upper_floors.png' ) p . show ( screenshot = png_path ) 1.6. Save Entrance Access Lattice to CSV # save the sun access latice to csv csv_path = os . path . relpath ( '../data/dist_lattice_upper_floors.csv' ) dist_lattice_upper_floors . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Distance calculation, upper floors"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#distance-lattice-upper-floors","text":"in this notebook, the distance lattice is being generated for all higher levels.","title":"Distance Lattice upper floors"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import scipy as sp import pickle np . random . seed ( 0 ) from scipy.interpolate import RegularGridInterpolator","title":"0.1. Load required libraries"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#02-define-the-neighborhood-stencil","text":"# creating neighborhood definition h_stencil = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero h_stencil . set_index ([ 0 , 0 , 0 ], 0 ) h_stencil . set_index ([ 0 , 0 , 1 ], 0 ) h_stencil . set_index ([ 0 , 0 , - 1 ], 0 )","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#03-load-the-envelope-lattice-as-the-avialbility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/voxelized_envelope_highres.csv' ) avail_lattice = tg . lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_pickle_path = os . path . relpath ( '../data/corridor_lattice_upper_floors.p' ) corridor_lattice_upper_floors = pickle . load ( open ( lattice_pickle_path , \"rb\" )) corridor_lattice_upper_floors . bounds = avail_lattice . bounds corridor_lattice_upper_floors . unit = avail_lattice . unit","title":"0.3. Load the envelope lattice as the avialbility lattice"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#1-distance-field-construction","text":"","title":"1. Distance Field Construction"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#11-create-distance-lattice-to-upper-floor-corridors","text":"# initializing the distance lattice distance_lattice = avail_lattice * 0 # cutting an slice of the distance lattice distance_floor = distance_lattice [:, :, 1 ] # cutting an slice of the groundfloor corridors lattice cor_upper_floor = corridor_lattice_upper_floors [:, :, 8 ] # extracting all it's voxel indices corr_vox_inds = np . argwhere ( cor_upper_floor > 0 ) # extract the indicies of the distance floor dist_indices = np . indices ( distance_floor . shape ) # init list of slice dists slice_dist_arrays = [] # iterate over voxels of the corridor for cor_vox in corr_vox_inds : # find the relative distance of corridor voxel to all dist floor voxels in X, Y relative_dist = np . abs ( dist_indices - cor_vox [:, np . newaxis , np . newaxis ]) # sum X, Y components slice_dist = relative_dist . sum ( axis = 0 ) # append to list slice_dist_arrays . append ( slice_dist ) # find the minimum fo earch dist voxel min_dist_slice = np . min ( np . stack ( slice_dist_arrays ), axis = 0 ) # construc the distance lattice from one slice distance_lattice += min_dist_slice [:, :, np . newaxis ]","title":"1.1. Create distance lattice to upper floor corridors"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#12-normalize-all-values","text":"#find the maximum valid value max_valid = np . ma . masked_invalid ( distance_lattice ) . max () # set the infinities to one more than the maximum valid values distance_lattice [ distance_lattice == np . inf ] = max_valid + 1 # mapping the values from (0, max) to (1, 0) ent_flat = 1 - distance_lattice / np . max ( distance_lattice )","title":"1.2. Normalize all values"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#13-copy-distance-slice-to-all-floors-that-have-these-corridors-set-all-other-values-to-0","text":"base_lattice = avail_lattice * 0 base_lattice [:,:, 6 :] = 1 base_lattice *= avail_lattice base_flat = base_lattice . flatten () dist_flat = ent_flat . flatten () dist_flat *= base_flat # # constructing the lattice dist_lattice_upper_floors = tg . to_lattice ( dist_flat . reshape ( avail_lattice . shape ), avail_lattice )","title":"1.3. copy distance slice to all floors that have these corridors, set all other values to 0"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#14-visualize-the-distance-lattice","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # load the mesh from file context_path = os . path . relpath ( '../data/immediate_context.obj' ) context_mesh = tm . load ( context_path ) ent_acc_highres = dist_lattice_upper_floors # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = ent_acc_highres . shape # The bottom left corner of the data set grid . origin = ent_acc_highres . minbound # These are the cell sizes along each axis grid . spacing = ent_acc_highres . unit # Add the data values to the cell data grid . point_arrays [ \"distance lattice upper floors\" ] = ent_acc_highres . flatten ( order = \"F\" ) # Flatten the Lattice # adding the meshes p . add_mesh ( tri_to_pv ( context_mesh ), opacity = 0.1 , style = 'wireframe' ) # adding the volume opacity = np . array ([ 0.0 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.6 ]) * 0.6 p . add_volume ( grid , cmap = \"plasma\" , clim = [ 0.0 , 1.0 ] , opacity = opacity ) # plotting p . show ( use_ipyvtk = True ) #saving and plotting png_path = os . path . relpath ( '../screenshots/6.2_lattice_distance_upper_floors.png' ) p . show ( screenshot = png_path )","title":"1.4. Visualize the distance lattice"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#16-save-entrance-access-lattice-to-csv","text":"# save the sun access latice to csv csv_path = os . path . relpath ( '../data/dist_lattice_upper_floors.csv' ) dist_lattice_upper_floors . to_csv ( csv_path )","title":"1.6. Save Entrance Access Lattice to CSV"},{"location":"notebooks/6.2_lattice_distance_upper_floors/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" __editor__ = \"Maartje Damen\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/7_ABM_growth/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Generative Relations: MCDA script Enabling agents to utilize MCDA (Multi Criteria Decision Analyses) in their spatial behaviors. input: Lattice info; CSV files from the sun/sky/quitness access and entrance and/or specific parts of the lattice accesses CSV with the table of values for each lattice info (as described before) and remaining necessary values such as (maz z coordinate, max voxel count, stencil id and evaluation per agent) included within the space names and space id's. output: Lattice frames (growth) saved as CSV. 0. Initialization 0.1. Load required libraries import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import pandas as pd import scipy as sp import pickle import matplotlib.pyplot as plt np . random . seed ( 0 ) # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l 0.2. Define the Neighborhood (Stencil) 0.2.1. Basic stencils with z axes differences # creating neighborhood definition for stencil that is 1.8m high s_1 = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_1 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition for stencil that is 3.6m high s_2 = tg . create_stencil ( \"von_neumann\" , 1 , 2 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) s_2 . set_index ([ 0 , 0 , 1 ], 0 ) s_2 . set_index ([ 0 , 0 , 2 ], 1 ) s_2 . set_index ([ 0 , 0 , - 1 ], 0 ) s_2 . set_index ([ 0 , 0 , - 2 ], 1 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition for stencil that is 5.4m high s_3 = tg . create_stencil ( \"von_neumann\" , 1 , 3 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) s_3 . set_index ([ 0 , 0 , 1 ], 0 ) s_3 . set_index ([ 0 , 0 , 3 ], 1 ) s_3 . set_index ([ 0 , 0 , - 1 ], 0 ) s_3 . set_index ([ 0 , 0 , - 3 ], 1 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition for stencil that is 7.2m high s_4 = tg . create_stencil ( \"von_neumann\" , 1 , 4 ) # setting the center to zero s_4 . set_index ([ 0 , 0 , 0 ], 0 ) s_4 . set_index ([ 0 , 0 , 1 ], 0 ) s_4 . set_index ([ 0 , 0 , 4 ], 1 ) s_4 . set_index ([ 0 , 0 , - 1 ], 0 ) s_4 . set_index ([ 0 , 0 , - 4 ], 1 ) # setting the center to zero s_4 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition for stencil that is 9m high s_5 = tg . create_stencil ( \"von_neumann\" , 1 , 5 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) s_5 . set_index ([ 0 , 0 , 1 ], 0 ) s_5 . set_index ([ 0 , 0 , 5 ], 1 ) s_5 . set_index ([ 0 , 0 , - 1 ], 0 ) s_5 . set_index ([ 0 , 0 , - 5 ], 1 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) # listing the stencils in order to make them correspond later with the spaces and their height requirement stencils = [ s_1 , s_2 , s_3 , s_4 , s_5 ] 0.2.2. Visualization stencils 0.2.3. Listing all stencils stencil = s_5 # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = np . array ( stencil . shape ) + 1 # The bottom left corner of the data set grid . origin = [ 0 , 0 , 0 ] # These are the cell sizes along each axis grid . spacing = [ 5 , 5 , 5 ] # Add the data values to the cell data grid . cell_arrays [ \"values\" ] = stencil . flatten ( order = \"F\" ) # Flatten the stencil threshed = grid . threshold ([ 0.9 , 1.1 ]) # adding the voxels: light red p . add_mesh ( threshed , show_edges = True , color = \"white\" , opacity = 0.3 ) # plotting p . show ( use_ipyvtk = True ) 0.2.4 Stencil visualization (for checking) 0.3. Load the envelope lattice as the avialbility lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/highres_envelope.csv' ) avail_lattice = lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/avail_lattice_good_voxels.csv' ) avail_lattice_good_voxels = lattice_from_csv ( lattice_path ) init_avail_lattice_good_voxels = tg . to_lattice ( np . copy ( avail_lattice_good_voxels ), avail_lattice_good_voxels ) avail_lattice *= avail_lattice_good_voxels 0.4. Load Agents Information # loading program (agents information) from CSV prgm_path = os . path . relpath ( '../data/program_exported.csv' ) agn_info = pd . read_csv ( '../data/program_exported.csv' , delimiter = \";\" ) agn_ids = agn_info [ \"space_id\" ] . values agn_prefs = agn_info agn_prefs 0.5. Initialize environment information layers from Sun Access Lattice and Entrance Access Lattice # loading the lattice from csv sun_acc_path = os . path . relpath ( '../data/sun_access_highres.csv' ) sun_acc_lattice = lattice_from_csv ( sun_acc_path ) ent_acc_highres_public_path = os . path . relpath ( '../data/ent_access_highres_public.csv' ) ent_acc_public_lattice = lattice_from_csv ( ent_acc_highres_public_path ) ent_acc_highres_housing_path = os . path . relpath ( '../data/ent_access_highres_housing.csv' ) ent_acc_housing_lattice = lattice_from_csv ( ent_acc_highres_housing_path ) ent_acc_highres_gym_path = os . path . relpath ( '../data/ent_access_highres_gym.csv' ) ent_acc_gym_lattice = lattice_from_csv ( ent_acc_highres_gym_path ) ent_acc_highres_parking_path = os . path . relpath ( '../data/ent_access_highres_parking.csv' ) ent_acc_parking_lattice = lattice_from_csv ( ent_acc_highres_parking_path ) ent_acc_highres_comcen_path = os . path . relpath ( '../data/ent_access_highres_comcen.csv' ) ent_acc_comcen_lattice = lattice_from_csv ( ent_acc_highres_comcen_path ) highres_sky_acc_path = os . path . relpath ( '../data/sky_access_highres.csv' ) sky_acc_lattice = lattice_from_csv ( highres_sky_acc_path ) highres_quietness_acc_path = os . path . relpath ( '../data/quietness_highres.csv' ) quietness_acc_lattice = lattice_from_csv ( highres_quietness_acc_path ) groundfloor_acc_path = os . path . relpath ( '../data/ent_access_highres_groundfloor.csv' ) groundfloor_acc_lattice = lattice_from_csv ( groundfloor_acc_path ) # list the environment information layers (lattices) env_info = { \"sun_acc\" : sun_acc_lattice + 0.001 , \"ent_acc_public\" : ent_acc_public_lattice + 0.001 , \"ent_acc_housing\" : ent_acc_housing_lattice + 0.001 , \"ent_acc_gym\" : ent_acc_gym_lattice + 0.001 , \"ent_acc_parking\" : ent_acc_parking_lattice + 0.001 , \"ent_acc_comcen\" : ent_acc_comcen_lattice + 0.001 , \"sky_acc\" : sky_acc_lattice + 0.001 , \"quietness_acc\" : quietness_acc_lattice + 0.001 , \"ground_floor_acc\" : groundfloor_acc_lattice + 0.001 } # defining other factors in csv # defining stencil id stencil_id = stencils # area to use in simulation room_area = [] # check if all the csv files loaded are highres for key , info_lattice in env_info . items (): print ( key , info_lattice . shape ) 1. ABM Simulation Basic run Making defs # Function for checking the availability (Since it is repeated several times in the main loop) def check_avail ( avail_lattice , ind , a_stencil_id ): condition = 1 ind_array = np . array ( ind ) for step in range ( a_stencil_id + 1 ): new_ind_array = ind_array + np . array ([ 0 , 0 , step ]) condition *= avail_lattice [ tuple ( new_ind_array )] return condition # Function for evaluation (Since it is repeated several times in the main loop) def eval_voxel ( vox , env_info , a_pref ): global_vox_value = 1.0 # for every lattice in the environment informations for key , info_lattice in env_info . items (): # Here we utilise Fuzzy Logics to be able to compare different layers # of environmental information and evaluate the voxel for the agent. # This method is introduced, and generalised in Pirouz Nourian dissertation: # section 5.7.3, pp. 201-208, eq. 57. You can refer to this section for # comprehensive mathematical details. vox_val = info_lattice [ tuple ( vox )] agn_vox_val = np . power ( vox_val , a_pref [ key ]) global_vox_value *= agn_vox_val return global_vox_value # Function for the occupation and departure (Since it is repeated several times in the main loop) def mult_occupation ( selected_neigh_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = False ): # Doing this for x times in the z axis with x coming from a_height for step in range ( a_height ): #giving a step to the regular occupation in order to run this for every step in the z aces new_address = selected_neigh_3d_address + np . array ([ 0 , 0 , step ]) # check if there's enough space in the z axis if new_address [ 2 ] < occ_lattice . shape [ 2 ]: # make tuple of the address selected_neigh_3d_id = tuple ( new_address ) # find the location of the newly selected neighbour selected_neigh_loc = np . array ( selected_neigh_3d_id ) . flatten () if departure == False : # add the newly selected neighbour location to agent locations agn_locs [ a_id ] . append ( selected_neigh_loc ) if step == 0 : agn_src_locs [ a_id ] . append ( selected_neigh_loc ) # set the newly selected neighbour as UNavailable (0) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 0 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_neigh_3d_id ] = a_id else : # remove the newly selected neighbour location to agent locations a_locs_list = [ list ( loc ) for loc in agn_locs [ a_id ]] try : ind = a_locs_list . index ( list ( selected_neigh_loc )) agn_locs [ a_id ] . pop ( ind ) # set the selected neighbour as available (1) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 1 # set the newly selected neighbour as NOT OCCUPIED by current agent occ_lattice [ selected_neigh_3d_id ] = - 1 except : pass return ( agn_locs , agn_src_locs , occ_lattice , avail_lattice ) # Simple version of finding neighbours provided by Shervin in order to fix the growth issue (agents didnt grow on the bottom level of the lattice). # This function takes a stencil, a lattice and the address of a voxel in that lattice and it returns the index of the neighbours of that voxel def find_neighbours_masked ( lattice , stencil , loc ): neigh_locs = np . argwhere ( stencil ) - stencil . origin + loc neigh_filter = np . all ( neigh_locs > 0 , axis = 1 ) * np . all ( neigh_locs < np . array ( lattice . shape ), axis = 1 ) return ( neigh_locs [ neigh_filter ]) Intialization # initialize the occupation lattice occ_lattice = avail_lattice * 0 - 1 # Finding the index of the available voxels in avail_lattice avail_flat = avail_lattice . flatten () avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # count the number of spaces (rows) and intiialize an agent for each space agn_num = len ( agn_info ) # adding the origins to the agents locations agn_locs = [[] for a_id in agn_ids ] agn_src_locs = [[] for a_id in agn_ids ] agn_upper = [] # retrieving the entrance access value of the free neighbours for a_id in agn_ids : voxel_vals = [] pot_voxels = [] # retrieve agent preferences a_pref = agn_prefs . loc [ a_id ] a_stencil_id = agn_prefs [ \"stencil_id\" ][ a_id ] stencil = stencils [ a_stencil_id ] # max height (z dimension) a_max_z = agn_prefs [ \"max_z\" ][ a_id ] # use avail_index # Voxel Evaluation Loop for pot_vox in avail_index : if check_avail ( avail_lattice , tuple ( pot_vox ), a_stencil_id ) and pot_vox [ 2 ] < a_max_z : # eval voxel vox_value = eval_voxel ( pot_vox , env_info , a_pref ) # add the neighbour value to the list of values voxel_vals . append ( vox_value ) pot_voxels . append ( pot_vox ) # convert to numpy array voxel_vals = np . array ( voxel_vals ) # convert to numpy array pot_voxels = np . array ( pot_voxels ) # select the neighbour with highest value selected_int = np . argmax ( voxel_vals ) # find 3D intiger index of selected neighbour selected_neigh_3d_address = tuple ( pot_voxels [ selected_int ] . T ) # find the location of the newly selected neighbour agn_origins = np . array ( selected_neigh_3d_address ) . flatten () agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( selected_neigh_3d_address , a_id , a_stencil_id + 1 , agn_locs , agn_src_locs , occ_lattice , avail_lattice ) 1.2. Running the simulation Basic run # empty lists to fill in order to track satisfaction and area growth satisfaction_record = [] area_record = [] # make a deep copy of occupation lattice cur_occ_lattice = tg . to_lattice ( np . copy ( occ_lattice ), occ_lattice ) # initialzing the list of frames frames = [ cur_occ_lattice ] # setting the time variable to 0 t = 0 n_frames = 2500 # check size of used csv (reach of the code) print ( agn_info . shape ) # max voxel count per space (here we do the stencil type + 1 #times the amount of area needed in order to obtain the total amount of voxels that need to be occupied by the script) # pick room area data a_room_vox = agn_prefs [ \"room_area\" ] # pick stencil id's and do +1 because we start with 0 instead of 1 (id 2 would have stencil 3 high otherwise) a_room_stencil = agn_prefs [ \"stencil_id\" ] + 1 # obtain the max amount of voxels needing to be occupied by doing the room area times the height of the space (stencil) a_room_voxels = a_room_stencil * a_room_vox # print in order to check below if you obtain correct values print ( a_room_voxels ) # Simulation Loop # main feedback loop of the simulation (for each time step ...) while t < n_frames : all_agn_sat = [] agn_loc_vals = [] all_agn_area = [] # for each agent ... (evaluation/satisfaction) for a_id in range ( agn_num ): # creating variable that takes per id a_locs = agn_locs [ a_id ] a_src_locs = agn_src_locs [ a_id ] # retrieving the entrance access value of the free neighbours loc_vals = [] # retrieve agent preferences a_pref = agn_prefs . loc [ a_id ] # Neighbour Evaluation Loop for loc in a_src_locs : # eval voxel loc_value = eval_voxel ( tuple ( loc ), env_info , a_pref ) loc_vals . append ( loc_value ) agn_loc_vals . append ( loc_vals ) agent_satisfaction = np . mean ( loc_value ) all_agn_sat . append ( agent_satisfaction ) # end of the satisfaction for loop satisfaction_record . append ( all_agn_sat ) # Main Agent Loop for a_id in range ( agn_num ): # creating variable that takes per id a_locs = agn_locs [ a_id ] a_src_locs = agn_src_locs [ a_id ] # creating variable that takes stencil per id a_stencil_id = agn_prefs [ \"stencil_id\" ][ a_id ] # making a variable that gives the height of the stencils in voxel (coincidentally +1 since all stencils grow with 1 voxel per id) a_height = a_stencil_id + 1 # variable for stencil values stencil = stencils [ a_stencil_id ] # making a variable of the result per id (for the loop) a_room_voxel = a_room_voxels [ a_id ] # initialize the list of free neighbours free_neighs = [] # Location loop # for each location of the agent for loc in a_src_locs : # retrieve the list of neighbours of the agent based on the stencil neighs_3d = find_neighbours_masked ( avail_lattice , s_2 , loc = loc ) # for each neighbour ... for neigh_3d_id in neighs_3d : if check_avail ( avail_lattice , neigh_3d_id , a_stencil_id ) and neigh_3d_id [ 2 ] < a_max_z : # add the neighbour to the list of free neighbours free_neighs . append ( neigh_3d_id ) # check if found any free neighbour if len ( free_neighs ) > 0 : # convert free neighbours to a numpy array free_neighs = np . array ( free_neighs ) # retrieving the entrance access value of the free neighbours neigh_vals = [] # retrieve agent preferences a_pref = agn_prefs . loc [ a_id ] # Neighbour Evaluation Loop for neigh in free_neighs : # vox eval neigh_value = eval_voxel ( tuple ( neigh ), env_info , a_pref ) neigh_vals . append ( neigh_value ) # convert to numpy array neigh_vals = np . array ( neigh_vals ) # select the neighbour with highest value selected_neighbour = np . argmax ( neigh_vals ) # find 3D intiger index of selected neighbour selected_neigh_3d_address = free_neighs [ selected_neighbour ] . T agent_satisfaction = all_agn_sat [ a_id ] # removing for better voxels a_evaluation = a_pref [ \"evaluation\" ] # normal growth condition if len ( agn_locs [ a_id ]) < a_room_voxel : # Ocupation agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( selected_neigh_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice ) # if evaluation value is higher than the agent satisfaction elif a_evaluation > agent_satisfaction : # select the lowest valued voxel for that agent loc_vals = agn_loc_vals [ a_id ] selected_loc = np . argmin ( loc_vals ) # Departure if neigh_vals [ selected_neighbour ] > loc_vals [ selected_loc ]: # Running stencil departure with the function vox_loc = agn_src_locs [ a_id ][ selected_loc ] agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( vox_loc , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = True ) # Ocupation after departure with the function agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( free_neighs [ selected_neighbour ], a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice ) # end of swapping condition # end of dynamic condition # end of available free neighbour condition # inside the agent iteration loop all_agn_area . append ( len ( agn_locs [ a_id ])) # end of the agent iteration loop area_record . append ( all_agn_area ) # constructing the new lattice new_occ_lattice = tg . to_lattice ( np . copy ( occ_lattice ), occ_lattice ) # adding the new lattice to the list of frames frames . append ( new_occ_lattice ) # adding one to the time counter t += 1 # satisfaction tracking satisfaction_df = pd . DataFrame . from_records ( satisfaction_record , columns = [ \"Agent_\" + str ( a_id ) for a_id in range ( agn_num )]) satisfaction_df . index = [ \"Frame_\" + str ( f ) for f in range ( len ( satisfaction_record ))] satisfaction_df #save the table table = satisfaction_df . to_csv ( '../data/2500frames.csv' ) #load the table table = pd . read_csv ( '../data/2500frames.csv' ) # dividing the table sat1 = table [[ \"Agent_0\" , \"Agent_1\" , \"Agent_2\" , \"Agent_3\" , \"Agent_4\" , \"Agent_5\" , \"Agent_6\" , \"Agent_7\" , \"Agent_8\" , \"Agent_9\" , \"Agent_10\" , \"Agent_12\" , \"Agent_13\" , \"Agent_14\" , \"Agent_15\" , \"Agent_18\" ]] # set limit sat1 = sat1 [ 0 : 100 ] # dividing the table sat2 = table [[ \"Agent_11\" , \"Agent_17\" , \"Agent_19\" ]] # set limit sat2 = sat2 [ 0 : 800 ] # dividing the table sat3 = table [[ \"Agent_16\" ]] # set limit sat3 = sat3 [ 0 : 2500 ] #plot graph df = sat1 df . plot ( legend = True , figsize = ( 15 , 10 ), xlabel = \"new x\" , ylabel = \"new y\" , title = \"xx\" , colormap = \"tab20\" ); plt . legend ( bbox_to_anchor = ( 1.0 , 0.5 )) #plot graph df = sat2 df . plot ( legend = True , figsize = ( 15 , 10 ), xlabel = \"new x\" , ylabel = \"new y\" , title = \"xx\" , colormap = \"tab10\" ); plt . legend ( bbox_to_anchor = ( 1.0 , 0.5 )) #plot graph df = sat3 df . plot ( legend = True , figsize = ( 15 , 10 ), xlabel = \"new x\" , ylabel = \"new y\" , title = \"xx\" , colormap = \"tab10\" ); plt . legend ( bbox_to_anchor = ( 1.0 , 0.5 )) #area tracking spacesize_df = pd . DataFrame . from_records ( area_record , columns = [ \"Agent_\" + str ( a_id ) for a_id in range ( agn_num )]) spacesize_df . index = [ \"Frame_\" + str ( f ) for f in range ( len ( area_record ))] spacesize_df #saving the tables to compare if script is runned again with different results pickle . dump ( frames , open ( \"../data/frames.p\" , \"wb\" )) #saving the tables to compare if script is runned again with different results frames = pickle . load ( open ( \"../data/frames.p\" , \"rb\" )) for frame in frames : frame . bounds = occ_lattice . bounds frame . unit = occ_lattice . unit 1.3. Visualizing the simulation p = pv . Plotter ( notebook = True ) base_lattice = frames [ 0 ] # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice init_avail_lattice_good_voxels . fast_vis ( p ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # making space list with index for the sargs space_list = agn_prefs . get ( 'space_name' ) # formatting for the sarg annotation space_list = space_list . to_dict () sargs = dict ( shadow = True , n_labels = 0 , italic = False , fmt = \" %.0f \" , font_family = \"arial\" , height = 0.6 , vertical = True , position_x = 1.05 , position_y = 1 ) def create_mesh ( value ): f = int ( value ) lattice = frames [ f ] # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , agn_num - 0.9 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = True , annotations = space_list , scalar_bar_args = sargs , cmap = \"nipy_spectral\" ) return # new cell in order to maintain vis size p . add_slider_widget ( create_mesh , [ 0 , n_frames ], title = 'Time' , value = 0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) 2.3. Saving lattice frames in CSV # save for every frame for i , lattice in enumerate ( frames ): csv_path = os . path . relpath ( '../data/abm_mcda/abm_f_' + f ' { i : 03 } ' + '.csv' ) lattice . to_csv ( csv_path ) #or just end frame csv_path = os . path . relpath ( '../data/final_lattice.csv' ) lattice . to_csv ( csv_path ) # An issue occured regarding specific agents not occuring when loading in and visualizing the lattice, #it was solved this way: #load in final lattice lattice_path = os . path . relpath ( '../data/final_lattice.csv' ) avail_lattice_good_voxels = lattice_from_csv ( lattice_path ) init_avail_lattice_good_voxels = tg . to_lattice ( np . copy ( avail_lattice_good_voxels ), avail_lattice_good_voxels ) #instead of values, make it true/false high_threshold = 50 low_threshold = - 0.9 new_avail_lattice = (( init_avail_lattice_good_voxels < high_threshold ) * ( init_avail_lattice_good_voxels > low_threshold )) #save it csv_path = os . path . relpath ( '../data/fixed_final_lattice.csv' ) new_avail_lattice . to_csv ( csv_path ) Credits __author__ = \"Shervin Azadi and Pirouz Nourian\" _Chief_editor_ = \"PROJECT APIDAE\" _editor_mentor_ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Agent Based Model growth simulation"},{"location":"notebooks/7_ABM_growth/#generative-relations-mcda-script","text":"Enabling agents to utilize MCDA (Multi Criteria Decision Analyses) in their spatial behaviors. input: Lattice info; CSV files from the sun/sky/quitness access and entrance and/or specific parts of the lattice accesses CSV with the table of values for each lattice info (as described before) and remaining necessary values such as (maz z coordinate, max voxel count, stencil id and evaluation per agent) included within the space names and space id's. output: Lattice frames (growth) saved as CSV.","title":"Generative Relations: MCDA script"},{"location":"notebooks/7_ABM_growth/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/7_ABM_growth/#01-load-required-libraries","text":"import os import topogenesis as tg import pyvista as pv import trimesh as tm import numpy as np import networkx as nx import pandas as pd import scipy as sp import pickle import matplotlib.pyplot as plt np . random . seed ( 0 ) # extra import function def lattice_from_csv ( file_path ): # read metadata meta_df = pd . read_csv ( file_path , nrows = 3 ) shape = np . array ( meta_df [ 'shape' ]) unit = np . array ( meta_df [ 'unit' ]) minbound = np . array ( meta_df [ 'minbound' ]) # read lattice lattice_df = pd . read_csv ( file_path , skiprows = 5 ) # create the buffer buffer = np . array ( lattice_df [ 'value' ]) . reshape ( shape ) # create the lattice l = tg . to_lattice ( buffer , minbound = minbound , unit = unit ) return l","title":"0.1. Load required libraries"},{"location":"notebooks/7_ABM_growth/#02-define-the-neighborhood-stencil","text":"","title":"0.2. Define the Neighborhood (Stencil)"},{"location":"notebooks/7_ABM_growth/#021-basic-stencils-with-z-axes-differences","text":"# creating neighborhood definition for stencil that is 1.8m high s_1 = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) # setting the center to zero s_1 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition for stencil that is 3.6m high s_2 = tg . create_stencil ( \"von_neumann\" , 1 , 2 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) s_2 . set_index ([ 0 , 0 , 1 ], 0 ) s_2 . set_index ([ 0 , 0 , 2 ], 1 ) s_2 . set_index ([ 0 , 0 , - 1 ], 0 ) s_2 . set_index ([ 0 , 0 , - 2 ], 1 ) # setting the center to zero s_2 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition for stencil that is 5.4m high s_3 = tg . create_stencil ( \"von_neumann\" , 1 , 3 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) s_3 . set_index ([ 0 , 0 , 1 ], 0 ) s_3 . set_index ([ 0 , 0 , 3 ], 1 ) s_3 . set_index ([ 0 , 0 , - 1 ], 0 ) s_3 . set_index ([ 0 , 0 , - 3 ], 1 ) # setting the center to zero s_3 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition for stencil that is 7.2m high s_4 = tg . create_stencil ( \"von_neumann\" , 1 , 4 ) # setting the center to zero s_4 . set_index ([ 0 , 0 , 0 ], 0 ) s_4 . set_index ([ 0 , 0 , 1 ], 0 ) s_4 . set_index ([ 0 , 0 , 4 ], 1 ) s_4 . set_index ([ 0 , 0 , - 1 ], 0 ) s_4 . set_index ([ 0 , 0 , - 4 ], 1 ) # setting the center to zero s_4 . set_index ([ 0 , 0 , 0 ], 0 ) # creating neighborhood definition for stencil that is 9m high s_5 = tg . create_stencil ( \"von_neumann\" , 1 , 5 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) s_5 . set_index ([ 0 , 0 , 1 ], 0 ) s_5 . set_index ([ 0 , 0 , 5 ], 1 ) s_5 . set_index ([ 0 , 0 , - 1 ], 0 ) s_5 . set_index ([ 0 , 0 , - 5 ], 1 ) # setting the center to zero s_5 . set_index ([ 0 , 0 , 0 ], 0 ) # listing the stencils in order to make them correspond later with the spaces and their height requirement stencils = [ s_1 , s_2 , s_3 , s_4 , s_5 ]","title":"0.2.1. Basic stencils with z axes differences"},{"location":"notebooks/7_ABM_growth/#022-visualization-stencils","text":"","title":"0.2.2. Visualization stencils"},{"location":"notebooks/7_ABM_growth/#023-listing-all-stencils","text":"stencil = s_5 # initiating the plotter p = pv . Plotter ( notebook = True ) # Create the spatial reference grid = pv . UniformGrid () # Set the grid dimensions: shape because we want to inject our values grid . dimensions = np . array ( stencil . shape ) + 1 # The bottom left corner of the data set grid . origin = [ 0 , 0 , 0 ] # These are the cell sizes along each axis grid . spacing = [ 5 , 5 , 5 ] # Add the data values to the cell data grid . cell_arrays [ \"values\" ] = stencil . flatten ( order = \"F\" ) # Flatten the stencil threshed = grid . threshold ([ 0.9 , 1.1 ]) # adding the voxels: light red p . add_mesh ( threshed , show_edges = True , color = \"white\" , opacity = 0.3 ) # plotting p . show ( use_ipyvtk = True )","title":"0.2.3. Listing all stencils"},{"location":"notebooks/7_ABM_growth/#024-stencil-visualization-for-checking","text":"","title":"0.2.4 Stencil visualization (for checking)"},{"location":"notebooks/7_ABM_growth/#03-load-the-envelope-lattice-as-the-avialbility-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/highres_envelope.csv' ) avail_lattice = lattice_from_csv ( lattice_path ) init_avail_lattice = tg . to_lattice ( np . copy ( avail_lattice ), avail_lattice ) # loading the lattice from csv lattice_path = os . path . relpath ( '../data/avail_lattice_good_voxels.csv' ) avail_lattice_good_voxels = lattice_from_csv ( lattice_path ) init_avail_lattice_good_voxels = tg . to_lattice ( np . copy ( avail_lattice_good_voxels ), avail_lattice_good_voxels ) avail_lattice *= avail_lattice_good_voxels","title":"0.3. Load the envelope lattice as the avialbility lattice"},{"location":"notebooks/7_ABM_growth/#04-load-agents-information","text":"# loading program (agents information) from CSV prgm_path = os . path . relpath ( '../data/program_exported.csv' ) agn_info = pd . read_csv ( '../data/program_exported.csv' , delimiter = \";\" ) agn_ids = agn_info [ \"space_id\" ] . values agn_prefs = agn_info agn_prefs","title":"0.4. Load Agents Information"},{"location":"notebooks/7_ABM_growth/#05-initialize-environment-information-layers-from-sun-access-lattice-and-entrance-access-lattice","text":"# loading the lattice from csv sun_acc_path = os . path . relpath ( '../data/sun_access_highres.csv' ) sun_acc_lattice = lattice_from_csv ( sun_acc_path ) ent_acc_highres_public_path = os . path . relpath ( '../data/ent_access_highres_public.csv' ) ent_acc_public_lattice = lattice_from_csv ( ent_acc_highres_public_path ) ent_acc_highres_housing_path = os . path . relpath ( '../data/ent_access_highres_housing.csv' ) ent_acc_housing_lattice = lattice_from_csv ( ent_acc_highres_housing_path ) ent_acc_highres_gym_path = os . path . relpath ( '../data/ent_access_highres_gym.csv' ) ent_acc_gym_lattice = lattice_from_csv ( ent_acc_highres_gym_path ) ent_acc_highres_parking_path = os . path . relpath ( '../data/ent_access_highres_parking.csv' ) ent_acc_parking_lattice = lattice_from_csv ( ent_acc_highres_parking_path ) ent_acc_highres_comcen_path = os . path . relpath ( '../data/ent_access_highres_comcen.csv' ) ent_acc_comcen_lattice = lattice_from_csv ( ent_acc_highres_comcen_path ) highres_sky_acc_path = os . path . relpath ( '../data/sky_access_highres.csv' ) sky_acc_lattice = lattice_from_csv ( highres_sky_acc_path ) highres_quietness_acc_path = os . path . relpath ( '../data/quietness_highres.csv' ) quietness_acc_lattice = lattice_from_csv ( highres_quietness_acc_path ) groundfloor_acc_path = os . path . relpath ( '../data/ent_access_highres_groundfloor.csv' ) groundfloor_acc_lattice = lattice_from_csv ( groundfloor_acc_path ) # list the environment information layers (lattices) env_info = { \"sun_acc\" : sun_acc_lattice + 0.001 , \"ent_acc_public\" : ent_acc_public_lattice + 0.001 , \"ent_acc_housing\" : ent_acc_housing_lattice + 0.001 , \"ent_acc_gym\" : ent_acc_gym_lattice + 0.001 , \"ent_acc_parking\" : ent_acc_parking_lattice + 0.001 , \"ent_acc_comcen\" : ent_acc_comcen_lattice + 0.001 , \"sky_acc\" : sky_acc_lattice + 0.001 , \"quietness_acc\" : quietness_acc_lattice + 0.001 , \"ground_floor_acc\" : groundfloor_acc_lattice + 0.001 } # defining other factors in csv # defining stencil id stencil_id = stencils # area to use in simulation room_area = [] # check if all the csv files loaded are highres for key , info_lattice in env_info . items (): print ( key , info_lattice . shape )","title":"0.5. Initialize environment information layers from Sun Access Lattice and Entrance Access Lattice"},{"location":"notebooks/7_ABM_growth/#1-abm-simulation","text":"","title":"1. ABM Simulation"},{"location":"notebooks/7_ABM_growth/#basic-run","text":"","title":"Basic run"},{"location":"notebooks/7_ABM_growth/#making-defs","text":"# Function for checking the availability (Since it is repeated several times in the main loop) def check_avail ( avail_lattice , ind , a_stencil_id ): condition = 1 ind_array = np . array ( ind ) for step in range ( a_stencil_id + 1 ): new_ind_array = ind_array + np . array ([ 0 , 0 , step ]) condition *= avail_lattice [ tuple ( new_ind_array )] return condition # Function for evaluation (Since it is repeated several times in the main loop) def eval_voxel ( vox , env_info , a_pref ): global_vox_value = 1.0 # for every lattice in the environment informations for key , info_lattice in env_info . items (): # Here we utilise Fuzzy Logics to be able to compare different layers # of environmental information and evaluate the voxel for the agent. # This method is introduced, and generalised in Pirouz Nourian dissertation: # section 5.7.3, pp. 201-208, eq. 57. You can refer to this section for # comprehensive mathematical details. vox_val = info_lattice [ tuple ( vox )] agn_vox_val = np . power ( vox_val , a_pref [ key ]) global_vox_value *= agn_vox_val return global_vox_value # Function for the occupation and departure (Since it is repeated several times in the main loop) def mult_occupation ( selected_neigh_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = False ): # Doing this for x times in the z axis with x coming from a_height for step in range ( a_height ): #giving a step to the regular occupation in order to run this for every step in the z aces new_address = selected_neigh_3d_address + np . array ([ 0 , 0 , step ]) # check if there's enough space in the z axis if new_address [ 2 ] < occ_lattice . shape [ 2 ]: # make tuple of the address selected_neigh_3d_id = tuple ( new_address ) # find the location of the newly selected neighbour selected_neigh_loc = np . array ( selected_neigh_3d_id ) . flatten () if departure == False : # add the newly selected neighbour location to agent locations agn_locs [ a_id ] . append ( selected_neigh_loc ) if step == 0 : agn_src_locs [ a_id ] . append ( selected_neigh_loc ) # set the newly selected neighbour as UNavailable (0) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 0 # set the newly selected neighbour as OCCUPIED by current agent # (-1 means not-occupied so a_id) occ_lattice [ selected_neigh_3d_id ] = a_id else : # remove the newly selected neighbour location to agent locations a_locs_list = [ list ( loc ) for loc in agn_locs [ a_id ]] try : ind = a_locs_list . index ( list ( selected_neigh_loc )) agn_locs [ a_id ] . pop ( ind ) # set the selected neighbour as available (1) in the availability lattice avail_lattice [ selected_neigh_3d_id ] = 1 # set the newly selected neighbour as NOT OCCUPIED by current agent occ_lattice [ selected_neigh_3d_id ] = - 1 except : pass return ( agn_locs , agn_src_locs , occ_lattice , avail_lattice ) # Simple version of finding neighbours provided by Shervin in order to fix the growth issue (agents didnt grow on the bottom level of the lattice). # This function takes a stencil, a lattice and the address of a voxel in that lattice and it returns the index of the neighbours of that voxel def find_neighbours_masked ( lattice , stencil , loc ): neigh_locs = np . argwhere ( stencil ) - stencil . origin + loc neigh_filter = np . all ( neigh_locs > 0 , axis = 1 ) * np . all ( neigh_locs < np . array ( lattice . shape ), axis = 1 ) return ( neigh_locs [ neigh_filter ])","title":"Making defs"},{"location":"notebooks/7_ABM_growth/#intialization","text":"# initialize the occupation lattice occ_lattice = avail_lattice * 0 - 1 # Finding the index of the available voxels in avail_lattice avail_flat = avail_lattice . flatten () avail_index = np . array ( np . where ( avail_lattice == 1 )) . T # count the number of spaces (rows) and intiialize an agent for each space agn_num = len ( agn_info ) # adding the origins to the agents locations agn_locs = [[] for a_id in agn_ids ] agn_src_locs = [[] for a_id in agn_ids ] agn_upper = [] # retrieving the entrance access value of the free neighbours for a_id in agn_ids : voxel_vals = [] pot_voxels = [] # retrieve agent preferences a_pref = agn_prefs . loc [ a_id ] a_stencil_id = agn_prefs [ \"stencil_id\" ][ a_id ] stencil = stencils [ a_stencil_id ] # max height (z dimension) a_max_z = agn_prefs [ \"max_z\" ][ a_id ] # use avail_index # Voxel Evaluation Loop for pot_vox in avail_index : if check_avail ( avail_lattice , tuple ( pot_vox ), a_stencil_id ) and pot_vox [ 2 ] < a_max_z : # eval voxel vox_value = eval_voxel ( pot_vox , env_info , a_pref ) # add the neighbour value to the list of values voxel_vals . append ( vox_value ) pot_voxels . append ( pot_vox ) # convert to numpy array voxel_vals = np . array ( voxel_vals ) # convert to numpy array pot_voxels = np . array ( pot_voxels ) # select the neighbour with highest value selected_int = np . argmax ( voxel_vals ) # find 3D intiger index of selected neighbour selected_neigh_3d_address = tuple ( pot_voxels [ selected_int ] . T ) # find the location of the newly selected neighbour agn_origins = np . array ( selected_neigh_3d_address ) . flatten () agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( selected_neigh_3d_address , a_id , a_stencil_id + 1 , agn_locs , agn_src_locs , occ_lattice , avail_lattice )","title":"Intialization"},{"location":"notebooks/7_ABM_growth/#12-running-the-simulation","text":"","title":"1.2. Running the simulation"},{"location":"notebooks/7_ABM_growth/#basic-run_1","text":"# empty lists to fill in order to track satisfaction and area growth satisfaction_record = [] area_record = [] # make a deep copy of occupation lattice cur_occ_lattice = tg . to_lattice ( np . copy ( occ_lattice ), occ_lattice ) # initialzing the list of frames frames = [ cur_occ_lattice ] # setting the time variable to 0 t = 0 n_frames = 2500 # check size of used csv (reach of the code) print ( agn_info . shape ) # max voxel count per space (here we do the stencil type + 1 #times the amount of area needed in order to obtain the total amount of voxels that need to be occupied by the script) # pick room area data a_room_vox = agn_prefs [ \"room_area\" ] # pick stencil id's and do +1 because we start with 0 instead of 1 (id 2 would have stencil 3 high otherwise) a_room_stencil = agn_prefs [ \"stencil_id\" ] + 1 # obtain the max amount of voxels needing to be occupied by doing the room area times the height of the space (stencil) a_room_voxels = a_room_stencil * a_room_vox # print in order to check below if you obtain correct values print ( a_room_voxels ) # Simulation Loop # main feedback loop of the simulation (for each time step ...) while t < n_frames : all_agn_sat = [] agn_loc_vals = [] all_agn_area = [] # for each agent ... (evaluation/satisfaction) for a_id in range ( agn_num ): # creating variable that takes per id a_locs = agn_locs [ a_id ] a_src_locs = agn_src_locs [ a_id ] # retrieving the entrance access value of the free neighbours loc_vals = [] # retrieve agent preferences a_pref = agn_prefs . loc [ a_id ] # Neighbour Evaluation Loop for loc in a_src_locs : # eval voxel loc_value = eval_voxel ( tuple ( loc ), env_info , a_pref ) loc_vals . append ( loc_value ) agn_loc_vals . append ( loc_vals ) agent_satisfaction = np . mean ( loc_value ) all_agn_sat . append ( agent_satisfaction ) # end of the satisfaction for loop satisfaction_record . append ( all_agn_sat ) # Main Agent Loop for a_id in range ( agn_num ): # creating variable that takes per id a_locs = agn_locs [ a_id ] a_src_locs = agn_src_locs [ a_id ] # creating variable that takes stencil per id a_stencil_id = agn_prefs [ \"stencil_id\" ][ a_id ] # making a variable that gives the height of the stencils in voxel (coincidentally +1 since all stencils grow with 1 voxel per id) a_height = a_stencil_id + 1 # variable for stencil values stencil = stencils [ a_stencil_id ] # making a variable of the result per id (for the loop) a_room_voxel = a_room_voxels [ a_id ] # initialize the list of free neighbours free_neighs = [] # Location loop # for each location of the agent for loc in a_src_locs : # retrieve the list of neighbours of the agent based on the stencil neighs_3d = find_neighbours_masked ( avail_lattice , s_2 , loc = loc ) # for each neighbour ... for neigh_3d_id in neighs_3d : if check_avail ( avail_lattice , neigh_3d_id , a_stencil_id ) and neigh_3d_id [ 2 ] < a_max_z : # add the neighbour to the list of free neighbours free_neighs . append ( neigh_3d_id ) # check if found any free neighbour if len ( free_neighs ) > 0 : # convert free neighbours to a numpy array free_neighs = np . array ( free_neighs ) # retrieving the entrance access value of the free neighbours neigh_vals = [] # retrieve agent preferences a_pref = agn_prefs . loc [ a_id ] # Neighbour Evaluation Loop for neigh in free_neighs : # vox eval neigh_value = eval_voxel ( tuple ( neigh ), env_info , a_pref ) neigh_vals . append ( neigh_value ) # convert to numpy array neigh_vals = np . array ( neigh_vals ) # select the neighbour with highest value selected_neighbour = np . argmax ( neigh_vals ) # find 3D intiger index of selected neighbour selected_neigh_3d_address = free_neighs [ selected_neighbour ] . T agent_satisfaction = all_agn_sat [ a_id ] # removing for better voxels a_evaluation = a_pref [ \"evaluation\" ] # normal growth condition if len ( agn_locs [ a_id ]) < a_room_voxel : # Ocupation agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( selected_neigh_3d_address , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice ) # if evaluation value is higher than the agent satisfaction elif a_evaluation > agent_satisfaction : # select the lowest valued voxel for that agent loc_vals = agn_loc_vals [ a_id ] selected_loc = np . argmin ( loc_vals ) # Departure if neigh_vals [ selected_neighbour ] > loc_vals [ selected_loc ]: # Running stencil departure with the function vox_loc = agn_src_locs [ a_id ][ selected_loc ] agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( vox_loc , a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice , departure = True ) # Ocupation after departure with the function agn_locs , agn_src_locs , occ_lattice , avail_lattice = mult_occupation ( free_neighs [ selected_neighbour ], a_id , a_height , agn_locs , agn_src_locs , occ_lattice , avail_lattice ) # end of swapping condition # end of dynamic condition # end of available free neighbour condition # inside the agent iteration loop all_agn_area . append ( len ( agn_locs [ a_id ])) # end of the agent iteration loop area_record . append ( all_agn_area ) # constructing the new lattice new_occ_lattice = tg . to_lattice ( np . copy ( occ_lattice ), occ_lattice ) # adding the new lattice to the list of frames frames . append ( new_occ_lattice ) # adding one to the time counter t += 1 # satisfaction tracking satisfaction_df = pd . DataFrame . from_records ( satisfaction_record , columns = [ \"Agent_\" + str ( a_id ) for a_id in range ( agn_num )]) satisfaction_df . index = [ \"Frame_\" + str ( f ) for f in range ( len ( satisfaction_record ))] satisfaction_df #save the table table = satisfaction_df . to_csv ( '../data/2500frames.csv' ) #load the table table = pd . read_csv ( '../data/2500frames.csv' ) # dividing the table sat1 = table [[ \"Agent_0\" , \"Agent_1\" , \"Agent_2\" , \"Agent_3\" , \"Agent_4\" , \"Agent_5\" , \"Agent_6\" , \"Agent_7\" , \"Agent_8\" , \"Agent_9\" , \"Agent_10\" , \"Agent_12\" , \"Agent_13\" , \"Agent_14\" , \"Agent_15\" , \"Agent_18\" ]] # set limit sat1 = sat1 [ 0 : 100 ] # dividing the table sat2 = table [[ \"Agent_11\" , \"Agent_17\" , \"Agent_19\" ]] # set limit sat2 = sat2 [ 0 : 800 ] # dividing the table sat3 = table [[ \"Agent_16\" ]] # set limit sat3 = sat3 [ 0 : 2500 ] #plot graph df = sat1 df . plot ( legend = True , figsize = ( 15 , 10 ), xlabel = \"new x\" , ylabel = \"new y\" , title = \"xx\" , colormap = \"tab20\" ); plt . legend ( bbox_to_anchor = ( 1.0 , 0.5 )) #plot graph df = sat2 df . plot ( legend = True , figsize = ( 15 , 10 ), xlabel = \"new x\" , ylabel = \"new y\" , title = \"xx\" , colormap = \"tab10\" ); plt . legend ( bbox_to_anchor = ( 1.0 , 0.5 )) #plot graph df = sat3 df . plot ( legend = True , figsize = ( 15 , 10 ), xlabel = \"new x\" , ylabel = \"new y\" , title = \"xx\" , colormap = \"tab10\" ); plt . legend ( bbox_to_anchor = ( 1.0 , 0.5 )) #area tracking spacesize_df = pd . DataFrame . from_records ( area_record , columns = [ \"Agent_\" + str ( a_id ) for a_id in range ( agn_num )]) spacesize_df . index = [ \"Frame_\" + str ( f ) for f in range ( len ( area_record ))] spacesize_df #saving the tables to compare if script is runned again with different results pickle . dump ( frames , open ( \"../data/frames.p\" , \"wb\" )) #saving the tables to compare if script is runned again with different results frames = pickle . load ( open ( \"../data/frames.p\" , \"rb\" )) for frame in frames : frame . bounds = occ_lattice . bounds frame . unit = occ_lattice . unit","title":"Basic run"},{"location":"notebooks/7_ABM_growth/#13-visualizing-the-simulation","text":"p = pv . Plotter ( notebook = True ) base_lattice = frames [ 0 ] # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding the avilability lattice init_avail_lattice_good_voxels . fast_vis ( p ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # making space list with index for the sargs space_list = agn_prefs . get ( 'space_name' ) # formatting for the sarg annotation space_list = space_list . to_dict () sargs = dict ( shadow = True , n_labels = 0 , italic = False , fmt = \" %.0f \" , font_family = \"arial\" , height = 0.6 , vertical = True , position_x = 1.05 , position_y = 1 ) def create_mesh ( value ): f = int ( value ) lattice = frames [ f ] # Add the data values to the cell data grid . cell_arrays [ \"Agents\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ - 0.1 , agn_num - 0.9 ]) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 1.0 , show_scalar_bar = True , annotations = space_list , scalar_bar_args = sargs , cmap = \"nipy_spectral\" ) return # new cell in order to maintain vis size p . add_slider_widget ( create_mesh , [ 0 , n_frames ], title = 'Time' , value = 0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True )","title":"1.3. Visualizing the simulation"},{"location":"notebooks/7_ABM_growth/#23-saving-lattice-frames-in-csv","text":"# save for every frame for i , lattice in enumerate ( frames ): csv_path = os . path . relpath ( '../data/abm_mcda/abm_f_' + f ' { i : 03 } ' + '.csv' ) lattice . to_csv ( csv_path ) #or just end frame csv_path = os . path . relpath ( '../data/final_lattice.csv' ) lattice . to_csv ( csv_path ) # An issue occured regarding specific agents not occuring when loading in and visualizing the lattice, #it was solved this way: #load in final lattice lattice_path = os . path . relpath ( '../data/final_lattice.csv' ) avail_lattice_good_voxels = lattice_from_csv ( lattice_path ) init_avail_lattice_good_voxels = tg . to_lattice ( np . copy ( avail_lattice_good_voxels ), avail_lattice_good_voxels ) #instead of values, make it true/false high_threshold = 50 low_threshold = - 0.9 new_avail_lattice = (( init_avail_lattice_good_voxels < high_threshold ) * ( init_avail_lattice_good_voxels > low_threshold )) #save it csv_path = os . path . relpath ( '../data/fixed_final_lattice.csv' ) new_avail_lattice . to_csv ( csv_path )","title":"2.3. Saving lattice frames in CSV"},{"location":"notebooks/7_ABM_growth/#credits","text":"__author__ = \"Shervin Azadi and Pirouz Nourian\" _Chief_editor_ = \"PROJECT APIDAE\" _editor_mentor_ = \"Shervin Azadi\" __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on MCDA and Path Finding for Generative Spatial Relations\"","title":"Credits"},{"location":"notebooks/8_polygonization/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Polygonization In this workshop we will learn how to convert our topological model of the building into a geometric model. This script turns a topological model of a building into a geometric model. As input it takes an envelope lattice. In chapter 0 and 1 you can create symmetry stencills, and save unique profile lattices. In chapter 2 you can load a sub-tile set and generate the complete tile set. In chapter 3 you can, using the boolean marching cube algorithm create your geometry based on the tileset(s) chapter 3 can run seperatly without chapter 0,1 and 2 It is possible to use stencills to select different parts of the building and run a different tile set on each stencill. In this code, there is a different tileset for the roof,groundfloor, facade in y direction, and 4 for the variation in the x direction. As output this script generates a meshed geometry. Unfortunately without texture. 0. Initialization 0.0. Importing libraries import topogenesis as tg import numpy as np import pyvista as pv import os import copy import trimesh as tm import pandas as pd import resources.boolean_marching_cubes as bmc 0.1. Generate Symmetry Stencils sym_str = [[ \"OO\" ], [ \"XX\" ], [ \"YY\" ], [ \"ZP\" ], [ \"ZN\" ]] stencils = bmc . create_symmetry_stencils ( sym_str ) for s in stencils : print ( s ) print ( \"-----\" ) 0.2. Generate lattices for all possible cubes # generate bianary representation of all the possible cubes l_bis = bmc . bi_cube_lattices () l_bis [ 3 ] 1. Profiling 1.1. Catalogue the profile of all corners # find all unique corner arrangements based on stencils corner_profiles = bmc . extract_corner_profiles ( stencils , l_bis ) 1.2. Find unique corner profiles # stack corner_profiles vertically cp_stacked = np . vstack ( corner_profiles ) # find the uniqe arangements of corners uniq_corner_arang = np . unique ( cp_stacked , axis = 0 ) print ( cp_stacked ) #print(uniq_corner_arang) #print(len(uniq_corner_arang)) print ( len ( cp_stacked )) 1.3. Construct unique profile latices # construct lattices for all unique corner profiles ( corner_loc_lattices , corner_neigh_lattices ) = bmc . profiles_to_lattices ( uniq_corner_arang , stencils ) 1.4. Visualize unique profiles p = pv . Plotter ( notebook = True ) base_lattice = corner_neigh_lattices [ 0 ] # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): f = int ( value ) lattice = corner_neigh_lattices [ f ] loc = corner_loc_lattices [ f ] # Add the data values to the cell data grid . cell_arrays [ \"filled\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ . 9 , 1.1 ], scalars = \"filled\" ) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 0.7 , show_scalar_bar = False ) # Add the data values to the cell data grid . cell_arrays [ \"corner\" ] = loc . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ . 9 , 1.1 ], scalars = \"corner\" ) # adding the voxels p . add_mesh ( threshed , name = 'sphere2' , show_edges = True , opacity = 1.0 , show_scalar_bar = False , color = \"white\" ) return p . add_slider_widget ( create_mesh , [ 1 , len ( corner_neigh_lattices )], title = 'Arrangements' , value = 0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) 1.5. Save unique arrangement profiles # save all design templates into lattice CSVs templates_path = os . path . relpath ( '../data/bmc/bmc_templates' ) bmc . save_design_templates ( corner_loc_lattices , corner_neigh_lattices , templates_path ) 2. Construct the tile-set 2.1. Load sub-tile meshes # load subtile meshes subtile_meshes = [] for c in range ( len ( corner_loc_lattices )): corner_mesh_path = os . path . relpath ( '../data/bmc/balcony_top/t_' + f ' { c : 02 } ' + '.obj' ) corner_mesh = tm . load ( corner_mesh_path ) subtile_meshes . append ( corner_mesh ) 2.2. Combine sub-tile meshes to create tile meshes tiles_meshes = bmc . construct_tile_meshes ( subtile_meshes , corner_profiles , uniq_corner_arang , corner_loc_lattices ) 2.3. Visualize tile meshes # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh p = pv . Plotter ( notebook = True ) base_lattice = l_bis [ 0 ] # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left cornerempty of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit * 0.5 # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): i = int ( value ) mesh = tiles_meshes [ i ] lattice = l_bis [ i ] # Add the data values to the cell data grid . cell_arrays [ \"cube\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ . 9 , 1.1 ], scalars = \"cube\" ) # adding the voxels p . add_mesh ( threshed , name = 'sphere2' , show_edges = True , opacity = 0.2 , show_scalar_bar = False , color = \"white\" ) # adding the meshes p . add_mesh ( tri_to_pv ( mesh ), color = '#abd8ff' , name = \"sphere\" ) return p . add_slider_widget ( create_mesh , [ 0 , len ( tiles_meshes )], title = 'Tiles' , value = 1 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True ) 2.4. Save the tile-set tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_balconytop' ) bmc . save_tile_meshes ( tiles_meshes , l_bis , tiles_path ) import topogenesis as tg import numpy as np import pyvista as pv import os import copy import trimesh as tm import pandas as pd import resources.boolean_marching_cubes as bmc 3. Boolean Marching Cube 3.1. Load envelope lattice # loading the lattice from csv lattice_path = os . path . relpath ( '../data/final_lattice_ihope_x2PLS.csv' ) envelope_lattice_0 = tg . lattice_from_csv ( lattice_path ) Removing the interior voxels Clean up the geometry, make the script run smoother # create the stencil s = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) s . set_index ([ 0 , 0 , 0 ], 0 ) # add the sum function to the stencil s . function = tg . sfunc . sum # apply the stencil on the lattice neighbor_sum = envelope_lattice_0 . apply_stencil ( s ) # remove if less than 6 new_envelope_lattice = envelope_lattice_0 * ( neighbor_sum <= 5 ) new_envelope_lattice_expanded = np . pad ( new_envelope_lattice , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) new_envelope_lattice_expanded = tg . to_lattice ( new_envelope_lattice_expanded , new_envelope_lattice . minbound - new_envelope_lattice . unit , new_envelope_lattice . unit ) Creating the roof lattice s = tg . create_stencil ( \"von_neumann\" , 0 , 2 ) s . set_index ([ 0 , 0 , 0 ], 0 ) s . set_index ([ 0 , 0 , 1 ], 1 ) s . set_index ([ 0 , 0 , 2 ], 1 ) s . function = tg . sfunc . sum upsum_lattice = envelope_lattice_0 . apply_stencil ( s ) roof_lattice = ( upsum_lattice == 0 ) * envelope_lattice_0 roof_lattice_expanded = np . pad ( roof_lattice , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) roof_lattice_expanded = tg . to_lattice ( roof_lattice_expanded , roof_lattice . minbound - roof_lattice . unit , roof_lattice . unit ) cube_roof_lattice = roof_lattice . boolean_marching_cubes () Selecting singular facade #every 2 other floor avail_index = np . array ( np . where ( new_envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , new_envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind regular_facade = new_envelope_lattice * 0 regular_facade [ 1 ,:,:] = 1 regular_facade [ 2 , 15 : 50 ,:] = 1 regular_facade [ 3 , 31 : 50 ,:] = 1 regular_facade [ 83 ,:,:] = 1 regular_facade *= new_envelope_lattice regular_facade_expanded = np . pad ( regular_facade , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) regular_facade_expanded = tg . to_lattice ( regular_facade_expanded , regular_facade . minbound - regular_facade . unit , regular_facade . unit ) Selecting Ground Floor # Finding the index of the available voxels in avail_lattice avail_index = np . array ( np . where ( new_envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , new_envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind # Ground Floor ground_floor_lattice = new_envelope_lattice * 0 ground_floor_lattice [:,:,: 4 ] = 1 ground_floor_lattice *= new_envelope_lattice ground_floor_lattice_expanded = np . pad ( ground_floor_lattice , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) ground_floor_lattice_expanded = tg . to_lattice ( ground_floor_lattice_expanded , ground_floor_lattice . minbound - ground_floor_lattice . unit , ground_floor_lattice . unit ) envelope_lattice = new_envelope_lattice_expanded - ground_floor_lattice_expanded - regular_facade_expanded - roof_lattice_expanded regular_facade_expanded = regular_facade_expanded - ground_floor_lattice_expanded ground_floor_cube_lattice = ground_floor_lattice_expanded . boolean_marching_cubes () regular_facade_cube = regular_facade_expanded . boolean_marching_cubes () 3.2. Extract the cube lattice from the envelope lattice Facade part 1 repeats on the 1st ::4 and 2nd::4 floor and in the x direction as 2::3 repeats on the 3rd::4 and 4th::4 floor and in the x direction as 0::3 avail_index = np . array ( np . where ( envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind facade_part_1 = envelope_lattice * 0 facade_part_1 [ 2 :: 3 ,:, 1 :: 4 ] = 1 facade_part_1 [ 2 :: 3 ,:, 2 :: 4 ] = 1 facade_part_1 [ 0 :: 3 ,:, 3 :: 4 ] = 1 facade_part_1 [ 0 :: 3 ,:, 4 :: 4 ] = 1 facade_part_1 *= envelope_lattice facade_part_1_expanded = np . pad ( facade_part_1 , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) facade_part_1_expanded = tg . to_lattice ( facade_part_1_expanded , facade_part_1 . minbound - facade_part_1 . unit , facade_part_1 . unit ) facade_1_cube = facade_part_1_expanded . boolean_marching_cubes () Facade part 2 repeats on the 3st ::4 floor and in the x direction as 1::3 repeats on the 1st::4 floor and in the x direction as 3::3 avail_index = np . array ( np . where ( envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind facade_part_2 = envelope_lattice * 0 facade_part_2 [ 3 :: 3 ,:, 1 :: 4 ] = 1 facade_part_2 [ 1 :: 3 ,:, 3 :: 4 ] = 1 facade_part_2 *= envelope_lattice facade_part_2_expanded = np . pad ( facade_part_2 , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) facade_part_2_expanded = tg . to_lattice ( facade_part_2_expanded , facade_part_2 . minbound - facade_part_2 . unit , facade_part_2 . unit ) facade_2_cube = facade_part_2_expanded . boolean_marching_cubes () Facade part 3 repeats on the 4rd ::4 floor and in the x direction as 1::3 repeats on the 2nd::4 floor and in the x direction as 3::3 avail_index = np . array ( np . where ( envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind facade_part_3 = envelope_lattice * 0 facade_part_3 [ 1 :: 3 ,:, 4 :: 4 ] = 1 facade_part_3 [ 3 :: 3 ,:, 2 :: 4 ] = 1 facade_part_3 *= envelope_lattice facade_part_3_expanded = np . pad ( facade_part_3 , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) facade_part_3_expanded = tg . to_lattice ( facade_part_3_expanded , facade_part_3 . minbound - facade_part_3 . unit , facade_part_3 . unit ) facade_3_cube = facade_part_3_expanded . boolean_marching_cubes () Facade part 4 repeats on the 1st::4 and 2nd::4 floor and in the x direction as 1::3 repeats on the 3rd::4 and 4th::4 floor and in the x direction as 2::3 avail_index = np . array ( np . where ( envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind facade_part_4 = envelope_lattice * 0 facade_part_4 [ 1 :: 3 ,:, 1 :: 4 ] = 1 facade_part_4 [ 1 :: 3 ,:, 2 :: 4 ] = 1 facade_part_4 [ 2 :: 3 ,:, 3 :: 4 ] = 1 facade_part_4 [ 2 :: 3 ,:, 4 :: 4 ] = 1 facade_part_4 *= envelope_lattice facade_part_4_expanded = np . pad ( facade_part_4 , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) facade_part_4_expanded = tg . to_lattice ( facade_part_4_expanded , facade_part_4 . minbound - facade_part_4 . unit , facade_part_4 . unit ) facade_4_cube = facade_part_4_expanded . boolean_marching_cubes () 3.3. tile the cube lattice with a tileset #loading the tilepaths groundfloor_tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_groundfloor' ) roof_tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_roof' ) doublewindow_tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_doublewindow' ) balconybottom_tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_balconybottom' ) balconytop_tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_balconytop' ) flat_tiles_path = os . path . relpath ( '../data/bmc/bmc_flat_tiles' ) regular_facade_path = os . path . relpath ( '../data/bmc/bmc_tiles_regular_facade' ) #doing the boolean marching cube algorithm per building part with its desired tilepath #these are split, to save RAM. bmc_mesh_1 = bmc . marching_cube_mesh ( ground_floor_cube_lattice , groundfloor_tiles_path ) bmc_mesh_2 = bmc . marching_cube_mesh ( cube_roof_lattice , roof_tiles_path ) bmc_mesh_3 = bmc . marching_cube_mesh ( facade_1_cube , doublewindow_tiles_path ) bmc_mesh_4 = bmc . marching_cube_mesh ( facade_2_cube , balconybottom_tiles_path ) bmc_mesh_5 = bmc . marching_cube_mesh ( facade_3_cube , balconytop_tiles_path ) bmc_mesh_6 = bmc . marching_cube_mesh ( facade_4_cube , flat_tiles_path ) bmc_mesh_7 = bmc . marching_cube_mesh ( regular_facade_cube , regular_facade_path ) #adding the boolean marching cubes together bmc_mesh = bmc_mesh_1 + bmc_mesh_2 + bmc_mesh_3 + bmc_mesh_4 + bmc_mesh_5 + bmc_mesh_6 + bmc_mesh_7 3.4. Visualize the final mesh # convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the meshes p . add_mesh ( tri_to_pv ( bmc_mesh ), color = 'white' , opacity = 1 , name = \"sphere\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # fast visualization of the lattice p = envelope_lattice_0 . fast_vis ( p ) # plotting p . show ( use_ipyvtk = True ) # png_path = os.path.relpath('../screen/finalmodel.png') # p.show(screenshot = png_path) 3.5. Save the final mesh #Saving the generated geometry as a mesh. final_mesh_path = os . path . relpath ( '../data/final_mesh.obj' ) with open ( final_mesh_path , 'w' ) as file : file . write ( tm . exchange . obj . export_obj ( bmc_mesh )) Credits __author__ = \"Shervin Azadi\" __editro__ = 'Siebren Meines' __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Polygonization\"","title":"Polygonization"},{"location":"notebooks/8_polygonization/#polygonization","text":"In this workshop we will learn how to convert our topological model of the building into a geometric model. This script turns a topological model of a building into a geometric model. As input it takes an envelope lattice. In chapter 0 and 1 you can create symmetry stencills, and save unique profile lattices. In chapter 2 you can load a sub-tile set and generate the complete tile set. In chapter 3 you can, using the boolean marching cube algorithm create your geometry based on the tileset(s) chapter 3 can run seperatly without chapter 0,1 and 2 It is possible to use stencills to select different parts of the building and run a different tile set on each stencill. In this code, there is a different tileset for the roof,groundfloor, facade in y direction, and 4 for the variation in the x direction. As output this script generates a meshed geometry. Unfortunately without texture.","title":"Polygonization"},{"location":"notebooks/8_polygonization/#0-initialization","text":"","title":"0. Initialization"},{"location":"notebooks/8_polygonization/#00-importing-libraries","text":"import topogenesis as tg import numpy as np import pyvista as pv import os import copy import trimesh as tm import pandas as pd import resources.boolean_marching_cubes as bmc","title":"0.0. Importing libraries"},{"location":"notebooks/8_polygonization/#01-generate-symmetry-stencils","text":"sym_str = [[ \"OO\" ], [ \"XX\" ], [ \"YY\" ], [ \"ZP\" ], [ \"ZN\" ]] stencils = bmc . create_symmetry_stencils ( sym_str ) for s in stencils : print ( s ) print ( \"-----\" )","title":"0.1. Generate Symmetry Stencils"},{"location":"notebooks/8_polygonization/#02-generate-lattices-for-all-possible-cubes","text":"# generate bianary representation of all the possible cubes l_bis = bmc . bi_cube_lattices () l_bis [ 3 ]","title":"0.2. Generate lattices for all possible cubes"},{"location":"notebooks/8_polygonization/#1-profiling","text":"","title":"1. Profiling"},{"location":"notebooks/8_polygonization/#11-catalogue-the-profile-of-all-corners","text":"# find all unique corner arrangements based on stencils corner_profiles = bmc . extract_corner_profiles ( stencils , l_bis )","title":"1.1. Catalogue the profile of all corners"},{"location":"notebooks/8_polygonization/#12-find-unique-corner-profiles","text":"# stack corner_profiles vertically cp_stacked = np . vstack ( corner_profiles ) # find the uniqe arangements of corners uniq_corner_arang = np . unique ( cp_stacked , axis = 0 ) print ( cp_stacked ) #print(uniq_corner_arang) #print(len(uniq_corner_arang)) print ( len ( cp_stacked ))","title":"1.2. Find unique corner profiles"},{"location":"notebooks/8_polygonization/#13-construct-unique-profile-latices","text":"# construct lattices for all unique corner profiles ( corner_loc_lattices , corner_neigh_lattices ) = bmc . profiles_to_lattices ( uniq_corner_arang , stencils )","title":"1.3. Construct unique profile latices"},{"location":"notebooks/8_polygonization/#14-visualize-unique-profiles","text":"p = pv . Plotter ( notebook = True ) base_lattice = corner_neigh_lattices [ 0 ] # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left corner of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): f = int ( value ) lattice = corner_neigh_lattices [ f ] loc = corner_loc_lattices [ f ] # Add the data values to the cell data grid . cell_arrays [ \"filled\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ . 9 , 1.1 ], scalars = \"filled\" ) # adding the voxels p . add_mesh ( threshed , name = 'sphere' , show_edges = True , opacity = 0.7 , show_scalar_bar = False ) # Add the data values to the cell data grid . cell_arrays [ \"corner\" ] = loc . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ . 9 , 1.1 ], scalars = \"corner\" ) # adding the voxels p . add_mesh ( threshed , name = 'sphere2' , show_edges = True , opacity = 1.0 , show_scalar_bar = False , color = \"white\" ) return p . add_slider_widget ( create_mesh , [ 1 , len ( corner_neigh_lattices )], title = 'Arrangements' , value = 0 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True )","title":"1.4. Visualize unique profiles"},{"location":"notebooks/8_polygonization/#15-save-unique-arrangement-profiles","text":"# save all design templates into lattice CSVs templates_path = os . path . relpath ( '../data/bmc/bmc_templates' ) bmc . save_design_templates ( corner_loc_lattices , corner_neigh_lattices , templates_path )","title":"1.5. Save unique arrangement profiles"},{"location":"notebooks/8_polygonization/#2-construct-the-tile-set","text":"","title":"2. Construct the tile-set"},{"location":"notebooks/8_polygonization/#21-load-sub-tile-meshes","text":"# load subtile meshes subtile_meshes = [] for c in range ( len ( corner_loc_lattices )): corner_mesh_path = os . path . relpath ( '../data/bmc/balcony_top/t_' + f ' { c : 02 } ' + '.obj' ) corner_mesh = tm . load ( corner_mesh_path ) subtile_meshes . append ( corner_mesh )","title":"2.1. Load sub-tile meshes"},{"location":"notebooks/8_polygonization/#22-combine-sub-tile-meshes-to-create-tile-meshes","text":"tiles_meshes = bmc . construct_tile_meshes ( subtile_meshes , corner_profiles , uniq_corner_arang , corner_loc_lattices )","title":"2.2. Combine sub-tile meshes to create tile meshes"},{"location":"notebooks/8_polygonization/#23-visualize-tile-meshes","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh p = pv . Plotter ( notebook = True ) base_lattice = l_bis [ 0 ] # Set the grid dimensions: shape + 1 because we want to inject our values on the CELL data grid = pv . UniformGrid () grid . dimensions = np . array ( base_lattice . shape ) + 1 # The bottom left cornerempty of the data set grid . origin = base_lattice . minbound - base_lattice . unit * 0.5 # These are the cell sizes along each axis grid . spacing = base_lattice . unit * 0.5 # adding the boundingbox wireframe p . add_mesh ( grid . outline (), color = \"grey\" , label = \"Domain\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) def create_mesh ( value ): i = int ( value ) mesh = tiles_meshes [ i ] lattice = l_bis [ i ] # Add the data values to the cell data grid . cell_arrays [ \"cube\" ] = lattice . flatten ( order = \"F\" ) . astype ( int ) # Flatten the array! # filtering the voxels threshed = grid . threshold ([ . 9 , 1.1 ], scalars = \"cube\" ) # adding the voxels p . add_mesh ( threshed , name = 'sphere2' , show_edges = True , opacity = 0.2 , show_scalar_bar = False , color = \"white\" ) # adding the meshes p . add_mesh ( tri_to_pv ( mesh ), color = '#abd8ff' , name = \"sphere\" ) return p . add_slider_widget ( create_mesh , [ 0 , len ( tiles_meshes )], title = 'Tiles' , value = 1 , event_type = \"always\" , style = \"classic\" , pointa = ( 0.1 , 0.1 ), pointb = ( 0.9 , 0.1 )) p . show ( use_ipyvtk = True )","title":"2.3. Visualize tile meshes"},{"location":"notebooks/8_polygonization/#24-save-the-tile-set","text":"tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_balconytop' ) bmc . save_tile_meshes ( tiles_meshes , l_bis , tiles_path ) import topogenesis as tg import numpy as np import pyvista as pv import os import copy import trimesh as tm import pandas as pd import resources.boolean_marching_cubes as bmc","title":"2.4. Save the tile-set"},{"location":"notebooks/8_polygonization/#3-boolean-marching-cube","text":"","title":"3. Boolean Marching Cube"},{"location":"notebooks/8_polygonization/#31-load-envelope-lattice","text":"# loading the lattice from csv lattice_path = os . path . relpath ( '../data/final_lattice_ihope_x2PLS.csv' ) envelope_lattice_0 = tg . lattice_from_csv ( lattice_path )","title":"3.1. Load envelope lattice"},{"location":"notebooks/8_polygonization/#removing-the-interior-voxels","text":"","title":"Removing the interior voxels"},{"location":"notebooks/8_polygonization/#clean-up-the-geometry-make-the-script-run-smoother","text":"# create the stencil s = tg . create_stencil ( \"von_neumann\" , 1 , 1 ) s . set_index ([ 0 , 0 , 0 ], 0 ) # add the sum function to the stencil s . function = tg . sfunc . sum # apply the stencil on the lattice neighbor_sum = envelope_lattice_0 . apply_stencil ( s ) # remove if less than 6 new_envelope_lattice = envelope_lattice_0 * ( neighbor_sum <= 5 ) new_envelope_lattice_expanded = np . pad ( new_envelope_lattice , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) new_envelope_lattice_expanded = tg . to_lattice ( new_envelope_lattice_expanded , new_envelope_lattice . minbound - new_envelope_lattice . unit , new_envelope_lattice . unit )","title":"Clean up the geometry, make the script run smoother"},{"location":"notebooks/8_polygonization/#creating-the-roof-lattice","text":"s = tg . create_stencil ( \"von_neumann\" , 0 , 2 ) s . set_index ([ 0 , 0 , 0 ], 0 ) s . set_index ([ 0 , 0 , 1 ], 1 ) s . set_index ([ 0 , 0 , 2 ], 1 ) s . function = tg . sfunc . sum upsum_lattice = envelope_lattice_0 . apply_stencil ( s ) roof_lattice = ( upsum_lattice == 0 ) * envelope_lattice_0 roof_lattice_expanded = np . pad ( roof_lattice , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) roof_lattice_expanded = tg . to_lattice ( roof_lattice_expanded , roof_lattice . minbound - roof_lattice . unit , roof_lattice . unit ) cube_roof_lattice = roof_lattice . boolean_marching_cubes ()","title":"Creating the roof lattice"},{"location":"notebooks/8_polygonization/#selecting-singular-facade","text":"#every 2 other floor avail_index = np . array ( np . where ( new_envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , new_envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind regular_facade = new_envelope_lattice * 0 regular_facade [ 1 ,:,:] = 1 regular_facade [ 2 , 15 : 50 ,:] = 1 regular_facade [ 3 , 31 : 50 ,:] = 1 regular_facade [ 83 ,:,:] = 1 regular_facade *= new_envelope_lattice regular_facade_expanded = np . pad ( regular_facade , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) regular_facade_expanded = tg . to_lattice ( regular_facade_expanded , regular_facade . minbound - regular_facade . unit , regular_facade . unit )","title":"Selecting singular facade"},{"location":"notebooks/8_polygonization/#selecting-ground-floor","text":"# Finding the index of the available voxels in avail_lattice avail_index = np . array ( np . where ( new_envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , new_envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind # Ground Floor ground_floor_lattice = new_envelope_lattice * 0 ground_floor_lattice [:,:,: 4 ] = 1 ground_floor_lattice *= new_envelope_lattice ground_floor_lattice_expanded = np . pad ( ground_floor_lattice , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) ground_floor_lattice_expanded = tg . to_lattice ( ground_floor_lattice_expanded , ground_floor_lattice . minbound - ground_floor_lattice . unit , ground_floor_lattice . unit ) envelope_lattice = new_envelope_lattice_expanded - ground_floor_lattice_expanded - regular_facade_expanded - roof_lattice_expanded regular_facade_expanded = regular_facade_expanded - ground_floor_lattice_expanded ground_floor_cube_lattice = ground_floor_lattice_expanded . boolean_marching_cubes () regular_facade_cube = regular_facade_expanded . boolean_marching_cubes ()","title":"Selecting Ground Floor"},{"location":"notebooks/8_polygonization/#32-extract-the-cube-lattice-from-the-envelope-lattice","text":"","title":"3.2. Extract the cube lattice from the envelope lattice"},{"location":"notebooks/8_polygonization/#facade-part-1","text":"","title":"Facade part 1"},{"location":"notebooks/8_polygonization/#repeats-on-the-1st-4-and-2nd4-floor-and-in-the-x-direction-as-23","text":"","title":"repeats on the 1st ::4 and 2nd::4 floor and in the x  direction as 2::3"},{"location":"notebooks/8_polygonization/#repeats-on-the-3rd4-and-4th4-floor-and-in-the-x-direction-as-03","text":"avail_index = np . array ( np . where ( envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind facade_part_1 = envelope_lattice * 0 facade_part_1 [ 2 :: 3 ,:, 1 :: 4 ] = 1 facade_part_1 [ 2 :: 3 ,:, 2 :: 4 ] = 1 facade_part_1 [ 0 :: 3 ,:, 3 :: 4 ] = 1 facade_part_1 [ 0 :: 3 ,:, 4 :: 4 ] = 1 facade_part_1 *= envelope_lattice facade_part_1_expanded = np . pad ( facade_part_1 , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) facade_part_1_expanded = tg . to_lattice ( facade_part_1_expanded , facade_part_1 . minbound - facade_part_1 . unit , facade_part_1 . unit ) facade_1_cube = facade_part_1_expanded . boolean_marching_cubes ()","title":"repeats on the 3rd::4 and 4th::4 floor and in the x  direction as 0::3"},{"location":"notebooks/8_polygonization/#facade-part-2","text":"","title":"Facade part 2"},{"location":"notebooks/8_polygonization/#repeats-on-the-3st-4-floor-and-in-the-x-direction-as-13","text":"","title":"repeats on the 3st ::4 floor and in the x  direction as 1::3"},{"location":"notebooks/8_polygonization/#repeats-on-the-1st4-floor-and-in-the-x-direction-as-33","text":"avail_index = np . array ( np . where ( envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind facade_part_2 = envelope_lattice * 0 facade_part_2 [ 3 :: 3 ,:, 1 :: 4 ] = 1 facade_part_2 [ 1 :: 3 ,:, 3 :: 4 ] = 1 facade_part_2 *= envelope_lattice facade_part_2_expanded = np . pad ( facade_part_2 , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) facade_part_2_expanded = tg . to_lattice ( facade_part_2_expanded , facade_part_2 . minbound - facade_part_2 . unit , facade_part_2 . unit ) facade_2_cube = facade_part_2_expanded . boolean_marching_cubes ()","title":"repeats on the 1st::4 floor and in the x  direction as 3::3"},{"location":"notebooks/8_polygonization/#facade-part-3","text":"","title":"Facade part 3"},{"location":"notebooks/8_polygonization/#repeats-on-the-4rd-4-floor-and-in-the-x-direction-as-13","text":"","title":"repeats on the 4rd ::4 floor and in the x  direction as 1::3"},{"location":"notebooks/8_polygonization/#repeats-on-the-2nd4-floor-and-in-the-x-direction-as-33","text":"avail_index = np . array ( np . where ( envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind facade_part_3 = envelope_lattice * 0 facade_part_3 [ 1 :: 3 ,:, 4 :: 4 ] = 1 facade_part_3 [ 3 :: 3 ,:, 2 :: 4 ] = 1 facade_part_3 *= envelope_lattice facade_part_3_expanded = np . pad ( facade_part_3 , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) facade_part_3_expanded = tg . to_lattice ( facade_part_3_expanded , facade_part_3 . minbound - facade_part_3 . unit , facade_part_3 . unit ) facade_3_cube = facade_part_3_expanded . boolean_marching_cubes ()","title":"repeats on the 2nd::4 floor and in the x  direction as 3::3"},{"location":"notebooks/8_polygonization/#facade-part-4","text":"","title":"Facade part 4"},{"location":"notebooks/8_polygonization/#repeats-on-the-1st4-and-2nd4-floor-and-in-the-x-direction-as-13","text":"","title":"repeats on the 1st::4 and 2nd::4 floor and in the x  direction as 1::3"},{"location":"notebooks/8_polygonization/#repeats-on-the-3rd4-and-4th4-floor-and-in-the-x-direction-as-23","text":"avail_index = np . array ( np . where ( envelope_lattice == 1 )) . T for vox_1d_ind in avail_index : vox_3d_ind = np . unravel_index ( vox_1d_ind , envelope_lattice . shape ) VX , VY , VZ = vox_3d_ind facade_part_4 = envelope_lattice * 0 facade_part_4 [ 1 :: 3 ,:, 1 :: 4 ] = 1 facade_part_4 [ 1 :: 3 ,:, 2 :: 4 ] = 1 facade_part_4 [ 2 :: 3 ,:, 3 :: 4 ] = 1 facade_part_4 [ 2 :: 3 ,:, 4 :: 4 ] = 1 facade_part_4 *= envelope_lattice facade_part_4_expanded = np . pad ( facade_part_4 , (( 1 , 1 ),( 1 , 1 ),( 1 , 1 )), 'constant' , constant_values = 0 ) facade_part_4_expanded = tg . to_lattice ( facade_part_4_expanded , facade_part_4 . minbound - facade_part_4 . unit , facade_part_4 . unit ) facade_4_cube = facade_part_4_expanded . boolean_marching_cubes ()","title":"repeats on the 3rd::4 and 4th::4 floor and in the x  direction as 2::3"},{"location":"notebooks/8_polygonization/#33-tile-the-cube-lattice-with-a-tileset","text":"#loading the tilepaths groundfloor_tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_groundfloor' ) roof_tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_roof' ) doublewindow_tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_doublewindow' ) balconybottom_tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_balconybottom' ) balconytop_tiles_path = os . path . relpath ( '../data/bmc/bmc_tiles_balconytop' ) flat_tiles_path = os . path . relpath ( '../data/bmc/bmc_flat_tiles' ) regular_facade_path = os . path . relpath ( '../data/bmc/bmc_tiles_regular_facade' ) #doing the boolean marching cube algorithm per building part with its desired tilepath #these are split, to save RAM. bmc_mesh_1 = bmc . marching_cube_mesh ( ground_floor_cube_lattice , groundfloor_tiles_path ) bmc_mesh_2 = bmc . marching_cube_mesh ( cube_roof_lattice , roof_tiles_path ) bmc_mesh_3 = bmc . marching_cube_mesh ( facade_1_cube , doublewindow_tiles_path ) bmc_mesh_4 = bmc . marching_cube_mesh ( facade_2_cube , balconybottom_tiles_path ) bmc_mesh_5 = bmc . marching_cube_mesh ( facade_3_cube , balconytop_tiles_path ) bmc_mesh_6 = bmc . marching_cube_mesh ( facade_4_cube , flat_tiles_path ) bmc_mesh_7 = bmc . marching_cube_mesh ( regular_facade_cube , regular_facade_path ) #adding the boolean marching cubes together bmc_mesh = bmc_mesh_1 + bmc_mesh_2 + bmc_mesh_3 + bmc_mesh_4 + bmc_mesh_5 + bmc_mesh_6 + bmc_mesh_7","title":"3.3. tile the cube lattice with a tileset"},{"location":"notebooks/8_polygonization/#34-visualize-the-final-mesh","text":"# convert mesh to pv_mesh def tri_to_pv ( tri_mesh ): faces = np . pad ( tri_mesh . faces , (( 0 , 0 ),( 1 , 0 )), 'constant' , constant_values = 3 ) pv_mesh = pv . PolyData ( tri_mesh . vertices , faces ) return pv_mesh # initiating the plotter p = pv . Plotter ( notebook = True ) # adding the meshes p . add_mesh ( tri_to_pv ( bmc_mesh ), color = 'white' , opacity = 1 , name = \"sphere\" ) # adding axes p . add_axes () p . show_bounds ( grid = \"back\" , location = \"back\" , color = \"#aaaaaa\" ) # fast visualization of the lattice p = envelope_lattice_0 . fast_vis ( p ) # plotting p . show ( use_ipyvtk = True ) # png_path = os.path.relpath('../screen/finalmodel.png') # p.show(screenshot = png_path)","title":"3.4. Visualize the final mesh"},{"location":"notebooks/8_polygonization/#35-save-the-final-mesh","text":"#Saving the generated geometry as a mesh. final_mesh_path = os . path . relpath ( '../data/final_mesh.obj' ) with open ( final_mesh_path , 'w' ) as file : file . write ( tm . exchange . obj . export_obj ( bmc_mesh ))","title":"3.5. Save the final mesh"},{"location":"notebooks/8_polygonization/#credits","text":"__author__ = \"Shervin Azadi\" __editro__ = 'Siebren Meines' __license__ = \"MIT\" __version__ = \"1.0\" __url__ = \"https://github.com/shervinazadi/spatial_computing_workshops\" __summary__ = \"Spatial Computing Design Studio Workshop on Polygonization\"","title":"Credits"}]}